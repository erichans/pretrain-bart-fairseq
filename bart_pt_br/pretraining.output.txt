erichm@E-122501:~$ HYDRA_FULL_ERROR=1 cd ~/projetos/pretrain-bart-fairseq/bart && source ../.venv/bin/activate && torchrun --nnodes=1:10 --max_restarts=30 --nproc_per_node=1 --rdzv_id=666 --rdzv_backend=c10d --rdzv_endpoint="E-122505:29400" `pwd`/../../fairseq/fairseq_cli/hydra_train.py --config-dir config/pretraining --config-name base task.data=/home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/data-bin/brwac
[2022-11-12 12:23:46,539][fairseq.distributed.utils][INFO] - distributed init (rank 0): env://
[2022-11-12 12:23:47,539][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2022-11-12 12:23:47,540][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
[2022-11-12 12:23:47,540][fairseq.distributed.utils][INFO] - initialized host E-122501.tcu.gov.br as rank 0
[2022-11-12 12:23:48,656][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 40, 'log_format': 'tqdm', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': 'bart_large_pt', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 4, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 3200, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': 'mmap', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3200, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 44500, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [48], 'lr': [0.0004], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': '/home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/original_bart_large/bart_large.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 200, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'bart_large', 'max_positions': 512, 'dropout': 0.1, 'attention_dropout': 0.1, 'arch': 'bart_large', 'short_seq_prob': 0, 'share_all_embeddings': True, 'encoder_learned_pos': True, 'decoder_learned_pos': True}, 'task': {'_name': 'denoising', 'data': '/home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/data-bin/brwac', 'bpe': None, 'tokens_per_sample': 512, 'sample_break_mode': eos, 'replace_length': 1, 'mask': 0.3, 'mask_random': 0.1, 'insert': 0.0, 'permute': 0.0, 'rotate': 0.0, 'poisson_lambda': 3.5, 'shuffle_instance': 0.0, 'mask_length': span-poisson, 'permute_sentences': 1, 'seed': 42, 'shorten_method': truncate, 'shorten_data_split_list': '', 'max_source_positions': 1024, 'max_target_positions': 1024, 'dataset_impl': mmap}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0004]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 900, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 44500.0, 'lr': [0.0004]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': '/home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': '/home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2022-11-12 12:23:48,692][fairseq.tasks.denoising][INFO] - dictionary: 50264 types
[2022-11-12 12:23:53,323][fairseq_cli.train][INFO] - BARTModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50265, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50265, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1024, out_features=50265, bias=False)
  )
  (classification_heads): ModuleDict()
)
[2022-11-12 12:23:53,325][fairseq_cli.train][INFO] - task: DenoisingTask
[2022-11-12 12:23:53,326][fairseq_cli.train][INFO] - model: BARTModel
[2022-11-12 12:23:53,326][fairseq_cli.train][INFO] - criterion: CrossEntropyCriterion
[2022-11-12 12:23:53,327][fairseq_cli.train][INFO] - num. shared model params: 406,291,456 (num. trained: 406,291,456)
[2022-11-12 12:23:53,328][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2022-11-12 12:23:53,329][fairseq.data.data_utils][INFO] - loaded 4,096 examples from: /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/data-bin/brwac/valid
[2022-11-12 12:23:53,329][fairseq.tasks.denoising][INFO] - loaded 4096 blocks from: /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/data-bin/brwac/valid
[2022-11-12 12:23:53,330][fairseq.tasks.denoising][INFO] - Split: valid, Loaded 4096 samples of denoising_dataset
[2022-11-12 12:23:53,449][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:2 to store for rank: 0
[2022-11-12 12:23:53,593][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2022-11-12 12:23:53,594][fairseq.trainer][INFO] - detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
[2022-11-12 12:23:53,594][fairseq.trainer][INFO] - detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
[2022-11-12 12:23:53,873][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2022-11-12 12:23:53,874][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 23.697 GB ; name = NVIDIA GeForce RTX 3090                 
[2022-11-12 12:23:53,874][fairseq.utils][INFO] - rank   1: capabilities =  8.6  ; total memory = 23.697 GB ; name = NVIDIA GeForce RTX 3090                 
[2022-11-12 12:23:53,874][fairseq.utils][INFO] - rank   2: capabilities =  8.6  ; total memory = 23.697 GB ; name = NVIDIA GeForce RTX 3090                 
[2022-11-12 12:23:53,874][fairseq.utils][INFO] - rank   3: capabilities =  8.6  ; total memory = 23.697 GB ; name = NVIDIA GeForce RTX 3090                 
[2022-11-12 12:23:53,874][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2022-11-12 12:23:53,874][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2022-11-12 12:23:53,874][fairseq_cli.train][INFO] - max tokens per device = 3200 and max sentences per device = None
[2022-11-12 12:23:53,874][fairseq.trainer][INFO] - Preparing to load checkpoint /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/original_bart_large/bart_large.pt
[2022-11-12 12:24:41,817][fairseq.optim.adam][INFO] - using FusedAdam
[2022-11-12 12:24:41,820][fairseq.trainer][INFO] - Loaded checkpoint /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/original_bart_large/bart_large.pt (epoch 41 @ 0 updates)
[2022-11-12 12:24:41,820][fairseq.trainer][INFO] - loading train data for epoch 1
[2022-11-12 12:24:43,939][fairseq.data.data_utils][INFO] - loaded 48,558,657 examples from: /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/data-bin/brwac/train
[2022-11-12 12:24:45,051][fairseq.tasks.denoising][INFO] - loaded 48558657 blocks from: /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/data-bin/brwac/train
[2022-11-12 12:24:45,095][fairseq.tasks.denoising][INFO] - Split: train, Loaded 48558657 samples of denoising_dataset
[2022-11-12 12:27:06,232][fairseq.data.iterators][INFO] - grouped total_num_itrs = 5551
epoch 001:   0%|                                                                                                                                                                          | 0/5551 [00:00<?, ?it/s]wandb: Currently logged in as: erichans (sesin). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.13.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.13.4
wandb: Run data is saved locally in /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/wandb/run-20221112_122707-rgpbx2sz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run checkpoints
wandb: â­ï¸ View project at https://wandb.ai/sesin/bart_large_pt
wandb: ðŸš€ View run at https://wandb.ai/sesin/bart_large_pt/runs/rgpbx2sz
[2022-11-12 12:27:08,671][fairseq.trainer][INFO] - begin training epoch 1
[2022-11-12 12:27:08,672][fairseq_cli.train][INFO] - Start iterating over samples
[2022-11-12 12:27:32,549][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
epoch 001:   0%|                                                                                                                                                               | 1/5551 [00:26<40:34:22, 26.32s/it][2022-11-12 12:27:33,063][torch.nn.parallel.distributed][INFO] - Reducer buckets have been rebuilt in this iteration.
[2022-11-12 12:27:55,543][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
epoch 001:   0%|                                                                                                                                                               | 2/5551 [00:49<37:33:06, 24.36s/it][2022-11-12 12:28:18,148][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
epoch 001:   0%|                                                                                                                                                               | 3/5551 [01:11<36:18:30, 23.56s/it][2022-11-12 12:28:40,816][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 001:   0%|                                                                                                                                                               | 4/5551 [01:34<35:45:32, 23.21s/it][2022-11-12 12:29:03,039][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 001:   0%|â–                                                                                                                                                              | 5/5551 [01:56<35:12:21, 22.85s/it][2022-11-12 12:29:25,404][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 001:   0%|â–                                                                                                                                                              | 6/5551 [02:19<34:56:38, 22.69s/it][2022-11-12 12:29:47,364][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 001:   0%|â–                                                                                                                                                              | 7/5551 [02:41<34:34:19, 22.45s/it][2022-11-12 12:30:09,783][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 001:   0%|â–                                                                                                                                                              | 8/5551 [03:03<34:33:02, 22.44s/it][2022-11-12 12:30:32,084][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 001:   0%|â–Ž                                                                                                                                                              | 9/5551 [03:25<34:28:40, 22.40s/it][2022-11-12 12:30:54,385][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:   0%|â–Ž                                                                                                                                                             | 10/5551 [03:48<34:25:34, 22.37s/it][2022-11-12 12:31:17,271][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:   0%|â–Ž                                                                                                                                                             | 11/5551 [04:11<34:39:53, 22.53s/it][2022-11-12 12:31:40,428][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 001:   4%| | 211/5551 [1:08:21<28:31:16, 19.23s/it, loss=2.947, ppl=7.71, wps=27260.8, ups=0.05, wpb=522518, bsz=8522.6, num_updates=160, lr=7.11111e-05, gnorm=0.759, clip=100, loss_scale=0.0625, train_wal[2022-11-12 13:35:47,663][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-12 13:35:49,696][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 2.863 | ppl 7.28 | wps 167737 | wpb 10521.6 | bsz 178.1 | num_updates 200                                                       
[2022-11-12 13:35:49,696][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 200 updates
[2022-11-12 13:35:49,697][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_200.pt
[2022-11-12 13:35:54,321][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_200.pt
[2022-11-12 13:35:59,257][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_200.pt (epoch 1 @ 200 updates, score 2.863) (writing took 9.560732251033187 seconds)
epoch 001:   7%| | 371/5551 [1:59:55<27:45:18, 19.29s/it, loss=2.554, ppl=5.87, wps=27157.3, ups=0.05, wpb=522286, bsz=8793.1, num_updates=320, lr=0.000142222, gnorm=0.698, clip=100, loss_scale=0.25, train_wall=[2022-11-12 14:27:20,468][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 001:   7%| | 377/5551 [2:01:50<27:34:36, 19.19s/it, loss=2.461, ppl=5.51, wps=26415.7, ups=0.05, wpb=521497, bsz=8833.7, num_updates=360, lr=0.00016, gnorm=0.687, clip=100, loss_scale=0.25, train_wall=773,[2022-11-12 14:29:15,542][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:   7%| | 378/5551 [2:02:09<27:33:12, 19.18s/it, loss=2.461, ppl=5.51, wps=26415.7, ups=0.05, wpb=521497, bsz=8833.7, num_updates=360, lr=0.00016, gnorm=0.687, clip=100, loss_scale=0.25, train_wall=773,[2022-11-12 14:29:35,060][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:   7%| | 383/5551 [2:03:45<27:44:15, 19.32s/it, loss=2.461, ppl=5.51, wps=26415.7, ups=0.05, wpb=521497, bsz=8833.7, num_updates=360, lr=0.00016, gnorm=0.687, clip=100, loss_scale=0.25, train_wall=773,[2022-11-12 14:31:11,244][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 001:   7%| | 415/5551 [2:14:00<27:20:45, 19.17s/it, loss=2.461, ppl=5.51, wps=26415.7, ups=0.05, wpb=521497, bsz=8833.7, num_updates=360, lr=0.00016, gnorm=0.687, clip=100, loss_scale=0.25, train_wall=773,[2022-11-12 14:41:25,676][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-12 14:41:27,686][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 2.602 | ppl 6.07 | wps 168078 | wpb 10521.6 | bsz 178.1 | num_updates 400 | best_loss 2.602                                     
[2022-11-12 14:41:27,687][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 400 updates
[2022-11-12 14:41:27,687][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_400.pt
[2022-11-12 14:41:32,295][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_400.pt
[2022-11-12 14:41:43,193][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_400.pt (epoch 1 @ 400 updates, score 2.602) (writing took 15.506497802678496 seconds)
epoch 001:  11%| | 615/5551 [3:18:26<26:30:16, 19.33s/it, loss=2.198, ppl=4.59, wps=27196.3, ups=0.05, wpb=523467, bsz=8764.6, num_updates=560, lr=0.000248889, gnorm=0.647, clip=100, loss_scale=0.125, train_wall[2022-11-12 15:45:51,882][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-12 15:45:53,872][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 2.297 | ppl 4.92 | wps 169119 | wpb 10521.6 | bsz 178.1 | num_updates 600 | best_loss 2.297                                     
[2022-11-12 15:45:53,872][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 600 updates
[2022-11-12 15:45:53,873][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_600.pt
[2022-11-12 15:45:58,443][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_600.pt
[2022-11-12 15:46:08,218][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_600.pt (epoch 1 @ 600 updates, score 2.297) (writing took 14.345727385021746 seconds)
epoch 001:  13%|â–| 737/5551 [3:57:53<25:49:48, 19.32s/it, loss=2.023, ppl=4.06, wps=27108.2, ups=0.05, wpb=522536, bsz=8785.7, num_updates=720, lr=0.00032, gnorm=0.489, clip=100, loss_scale=0.5, train_wall=756, [2022-11-12 16:25:19,617][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 001:  14%|â–| 792/5551 [4:15:32<25:16:01, 19.11s/it, loss=1.982, ppl=3.95, wps=26527.6, ups=0.05, wpb=524380, bsz=8799.8, num_updates=760, lr=0.000337778, gnorm=0.564, clip=100, loss_scale=0.25, train_wall=[2022-11-12 16:42:58,571][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:  15%|â–| 817/5551 [4:23:34<25:31:32, 19.41s/it, loss=1.982, ppl=3.95, wps=26527.6, ups=0.05, wpb=524380, bsz=8799.8, num_updates=760, lr=0.000337778, gnorm=0.564, clip=100, loss_scale=0.25, train_wall=[2022-11-12 16:50:59,850][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-12 16:51:01,867][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 2.205 | ppl 4.61 | wps 167749 | wpb 10521.6 | bsz 178.1 | num_updates 800 | best_loss 2.205                                     
[2022-11-12 16:51:01,867][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 800 updates
[2022-11-12 16:51:01,868][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_800.pt
[2022-11-12 16:51:06,351][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_800.pt
[2022-11-12 16:51:17,099][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_800.pt (epoch 1 @ 800 updates, score 2.205) (writing took 15.231449810322374 seconds)
epoch 001:  15%|â–| 857/5551 [4:36:42<25:06:31, 19.26s/it, loss=1.94, ppl=3.84, wps=26562.5, ups=0.05, wpb=523576, bsz=8609.5, num_updates=800, lr=0.000355556, gnorm=0.643, clip=100, loss_scale=0.125, train_wall=[2022-11-12 17:04:07,292][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:  15%|â–| 858/5551 [4:37:01<24:59:41, 19.17s/it, loss=1.94, ppl=3.84, wps=26562.5, ups=0.05, wpb=523576, bsz=8609.5, num_updates=800, lr=0.000355556, gnorm=0.643, clip=100, loss_scale=0.125, train_wall=[2022-11-12 17:04:26,627][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 001:  18%|â–| 1019/5551 [5:28:34<24:18:24, 19.31s/it, loss=1.852, ppl=3.61, wps=27202.3, ups=0.05, wpb=523141, bsz=8646.5, num_updates=960, lr=0.00039945, gnorm=0.715, clip=100, loss_scale=0.0625, train_wal[2022-11-12 17:55:59,524][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-12 17:56:01,541][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.85 | ppl 3.6 | wps 167746 | wpb 10521.6 | bsz 178.1 | num_updates 1000 | best_loss 1.85                                       
[2022-11-12 17:56:01,542][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 1000 updates
[2022-11-12 17:56:01,542][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_1000.pt
[2022-11-12 17:56:05,979][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_1000.pt
[2022-11-12 17:56:15,799][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 1.85) (writing took 14.257421530783176 seconds)
epoch 001:  19%|â–| 1037/5551 [5:34:37<24:13:35, 19.32s/it, loss=1.826, ppl=3.55, wps=27225.9, ups=0.05, wpb=523371, bsz=8684.4, num_updates=1000, lr=0.000399083, gnorm=0.985, clip=100, loss_scale=0.0625, train_w[2022-11-12 18:02:02,523][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:  22%|â–| 1220/5551 [6:33:17<23:13:52, 19.31s/it, loss=1.739, ppl=3.34, wps=27222.7, ups=0.05, wpb=522915, bsz=8489.8, num_updates=1160, lr=0.000397615, gnorm=0.578, clip=100, loss_scale=0.125, train_wa[2022-11-12 19:00:42,926][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-12 19:00:44,937][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 2.015 | ppl 4.04 | wps 167423 | wpb 10521.6 | bsz 178.1 | num_updates 1200 | best_loss 1.85                                     
[2022-11-12 19:00:44,937][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 1200 updates
[2022-11-12 19:00:44,938][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_1200.pt
[2022-11-12 19:00:49,445][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_1200.pt
[2022-11-12 19:00:54,026][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_1200.pt (epoch 1 @ 1200 updates, score 2.015) (writing took 9.088225959800184 seconds)
epoch 001:  23%|â–| 1301/5551 [6:59:27<22:48:34, 19.32s/it, loss=1.706, ppl=3.26, wps=27164, ups=0.05, wpb=522248, bsz=8664.2, num_updates=1280, lr=0.000396514, gnorm=0.612, clip=100, loss_scale=0.5, train_wall=7[2022-11-12 19:26:53,168][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 001:  26%|â–Ž| 1421/5551 [7:37:57<22:07:40, 19.29s/it, loss=1.672, ppl=3.19, wps=27167.6, ups=0.05, wpb=523664, bsz=8946.1, num_updates=1360, lr=0.00039578, gnorm=0.341, clip=100, loss_scale=0.25, train_wall[2022-11-12 20:05:23,178][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-12 20:05:25,188][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 2 | ppl 4 | wps 168270 | wpb 10521.6 | bsz 178.1 | num_updates 1400 | best_loss 1.85                                            
[2022-11-12 20:05:25,189][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 1400 updates
[2022-11-12 20:05:25,189][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_1400.pt
[2022-11-12 20:05:29,657][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_1400.pt
[2022-11-12 20:05:34,816][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_1400.pt (epoch 1 @ 1400 updates, score 2.0) (writing took 9.62664184672758 seconds)
epoch 001:  29%|â–Ž| 1595/5551 [8:33:57<21:04:35, 19.18s/it, loss=1.599, ppl=3.03, wps=27178, ups=0.05, wpb=522476, bsz=8701.6, num_updates=1560, lr=0.000393945, gnorm=0.289, clip=100, loss_scale=2, train_wall=755[2022-11-12 21:01:23,156][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 001:  29%|â–Ž| 1600/5551 [8:35:33<21:04:33, 19.20s/it, loss=1.599, ppl=3.03, wps=27178, ups=0.05, wpb=522476, bsz=8701.6, num_updates=1560, lr=0.000393945, gnorm=0.289, clip=100, loss_scale=2, train_wall=755[2022-11-12 21:02:59,368][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 001:  29%|â–Ž| 1601/5551 [8:35:53<21:05:50, 19.23s/it, loss=1.599, ppl=3.03, wps=27178, ups=0.05, wpb=522476, bsz=8701.6, num_updates=1560, lr=0.000393945, gnorm=0.289, clip=100, loss_scale=2, train_wall=755[2022-11-12 21:03:18,625][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 001:  29%|â–Ž| 1624/5551 [8:43:17<21:03:24, 19.30s/it, loss=1.599, ppl=3.03, wps=27178, ups=0.05, wpb=522476, bsz=8701.6, num_updates=1560, lr=0.000393945, gnorm=0.289, clip=100, loss_scale=2, train_wall=755[2022-11-12 21:10:42,872][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-12 21:10:44,879][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.952 | ppl 3.87 | wps 168139 | wpb 10521.6 | bsz 178.1 | num_updates 1600 | best_loss 1.85                                     
[2022-11-12 21:10:44,880][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 1600 updates
[2022-11-12 21:10:44,880][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_1600.pt
[2022-11-12 21:10:49,361][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_1600.pt
[2022-11-12 21:10:54,641][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_1600.pt (epoch 1 @ 1600 updates, score 1.952) (writing took 9.760683001950383 seconds)
epoch 001:  32%|â–Ž| 1790/5551 [9:36:39<20:03:03, 19.19s/it, loss=1.543, ppl=2.91, wps=27157.4, ups=0.05, wpb=521227, bsz=8711.8, num_updates=1760, lr=0.00039211, gnorm=0.276, clip=100, loss_scale=1, train_wall=75[2022-11-12 22:04:04,613][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 001:  33%|â–Ž| 1819/5551 [9:45:57<19:55:41, 19.22s/it, loss=1.543, ppl=2.91, wps=27157.4, ups=0.05, wpb=521227, bsz=8711.8, num_updates=1760, lr=0.00039211, gnorm=0.276, clip=100, loss_scale=1, train_wall=75[2022-11-12 22:13:22,837][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 001:  33%|â–Ž| 1820/5551 [9:46:16<20:00:26, 19.30s/it, loss=1.543, ppl=2.91, wps=27157.4, ups=0.05, wpb=521227, bsz=8711.8, num_updates=1760, lr=0.00039211, gnorm=0.276, clip=100, loss_scale=1, train_wall=75[2022-11-12 22:13:41,879][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:  33%|â–Ž| 1827/5551 [9:48:31<19:51:48, 19.20s/it, loss=1.543, ppl=2.91, wps=27157.4, ups=0.05, wpb=521227, bsz=8711.8, num_updates=1760, lr=0.00039211, gnorm=0.276, clip=100, loss_scale=1, train_wall=75[2022-11-12 22:15:56,584][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-12 22:15:58,605][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.749 | ppl 3.36 | wps 167108 | wpb 10521.6 | bsz 178.1 | num_updates 1800 | best_loss 1.749                                    
[2022-11-12 22:15:58,605][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 1800 updates
[2022-11-12 22:15:58,606][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_1800.pt
[2022-11-12 22:16:03,090][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_1800.pt
[2022-11-12 22:16:12,908][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_1800.pt (epoch 1 @ 1800 updates, score 1.749) (writing took 14.302125310059637 seconds)
epoch 001:  35%|â–Ž| 1922/5551 [10:19:13<19:24:08, 19.25s/it, loss=1.517, ppl=2.86, wps=27137, ups=0.05, wpb=521851, bsz=8814.9, num_updates=1880, lr=0.000391009, gnorm=0.244, clip=100, loss_scale=0.25, train_wall[2022-11-12 22:46:38,841][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:  35%|â–Ž| 1946/5551 [10:26:54<19:11:34, 19.17s/it, loss=1.517, ppl=2.86, wps=27137, ups=0.05, wpb=521851, bsz=8814.9, num_updates=1880, lr=0.000391009, gnorm=0.244, clip=100, loss_scale=0.25, train_wall[2022-11-12 22:54:20,382][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:  35%|â–Ž| 1947/5551 [10:27:14<19:15:18, 19.23s/it, loss=1.517, ppl=2.86, wps=27137, ups=0.05, wpb=521851, bsz=8814.9, num_updates=1880, lr=0.000391009, gnorm=0.244, clip=100, loss_scale=0.25, train_wall[2022-11-12 22:54:39,387][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 001:  37%|â–Ž| 2030/5551 [10:53:49<18:46:56, 19.20s/it, loss=1.574, ppl=2.98, wps=27182.9, ups=0.05, wpb=522045, bsz=8663.7, num_updates=1960, lr=0.000390275, gnorm=0.891, clip=100, loss_scale=0.0312, train_[2022-11-12 23:21:14,410][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-12 23:21:16,445][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.943 | ppl 3.85 | wps 167777 | wpb 10521.6 | bsz 178.1 | num_updates 2000 | best_loss 1.749                                    
[2022-11-12 23:21:16,446][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 2000 updates
[2022-11-12 23:21:16,446][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_2000.pt
[2022-11-12 23:21:20,926][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_2000.pt
[2022-11-12 23:21:25,743][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 1.943) (writing took 9.296689467970282 seconds)
epoch 001:  37%|â–Ž| 2081/5551 [11:10:22<18:25:10, 19.11s/it, loss=1.516, ppl=2.86, wps=26689.8, ups=0.05, wpb=521651, bsz=8716.8, num_updates=2040, lr=0.000389541, gnorm=0.785, clip=100, loss_scale=0.0625, train_[2022-11-12 23:37:47,604][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 001:  39%|â–| 2152/5551 [11:33:06<17:58:56, 19.05s/it, loss=1.53, ppl=2.89, wps=27198.4, ups=0.05, wpb=521916, bsz=8612.6, num_updates=2120, lr=0.000388807, gnorm=0.972, clip=100, loss_scale=0.0312, train_wwandb: Network error (ReadTimeout), entering retry loop.
epoch 001:  40%|â–| 2231/5551 [11:58:26<17:41:26, 19.18s/it, loss=1.512, ppl=2.85, wps=27149.1, ups=0.05, wpb=522666, bsz=8703.9, num_updates=2160, lr=0.00038844, gnorm=0.583, clip=100, loss_scale=0.0625, train_w[2022-11-13 00:25:52,269][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 00:25:54,275][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.806 | ppl 3.5 | wps 168185 | wpb 10521.6 | bsz 178.1 | num_updates 2200 | best_loss 1.749                                     
[2022-11-13 00:25:54,275][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 2200 updates
[2022-11-13 00:25:54,276][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_2200.pt
[2022-11-13 00:25:58,746][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_2200.pt
[2022-11-13 00:26:03,356][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_2200.pt (epoch 1 @ 2200 updates, score 1.806) (writing took 9.08122907904908 seconds)
epoch 001:  43%|â–| 2363/5551 [12:40:55<16:58:26, 19.17s/it, loss=1.459, ppl=2.75, wps=27185, ups=0.05, wpb=521893, bsz=8558.4, num_updates=2320, lr=0.000386972, gnorm=0.221, clip=100, loss_scale=0.25, train_wall[2022-11-13 01:08:21,198][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:  43%|â–| 2404/5551 [12:54:05<16:51:54, 19.29s/it, loss=1.457, ppl=2.75, wps=26478.8, ups=0.05, wpb=522146, bsz=8622.9, num_updates=2360, lr=0.000386606, gnorm=0.253, clip=100, loss_scale=0.125, train_w[2022-11-13 01:21:31,038][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:  44%|â–| 2433/5551 [13:03:23<16:39:32, 19.23s/it, loss=1.457, ppl=2.75, wps=26478.8, ups=0.05, wpb=522146, bsz=8622.9, num_updates=2360, lr=0.000386606, gnorm=0.253, clip=100, loss_scale=0.125, train_w[2022-11-13 01:30:48,491][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 01:30:50,494][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.681 | ppl 3.21 | wps 168543 | wpb 10521.6 | bsz 178.1 | num_updates 2400 | best_loss 1.681                                    
[2022-11-13 01:30:50,494][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 2400 updates
[2022-11-13 01:30:50,495][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_2400.pt
[2022-11-13 01:30:54,976][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_2400.pt
[2022-11-13 01:31:06,600][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_2400.pt (epoch 1 @ 2400 updates, score 1.681) (writing took 16.10574711114168 seconds)
epoch 001:  46%|â–| 2579/5551 [13:50:27<15:54:47, 19.28s/it, loss=1.44, ppl=2.71, wps=27159.6, ups=0.05, wpb=522395, bsz=8892.4, num_updates=2520, lr=0.000385138, gnorm=0.263, clip=100, loss_scale=0.125, train_wa[2022-11-13 02:17:53,434][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:  47%|â–| 2609/5551 [14:00:04<15:45:11, 19.28s/it, loss=1.439, ppl=2.71, wps=26485.1, ups=0.05, wpb=522992, bsz=8789.5, num_updates=2560, lr=0.000384771, gnorm=0.319, clip=100, loss_scale=0.125, train_w[2022-11-13 02:27:30,356][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:  47%|â–| 2635/5551 [14:08:24<15:27:16, 19.08s/it, loss=1.439, ppl=2.71, wps=26485.1, ups=0.05, wpb=522992, bsz=8789.5, num_updates=2560, lr=0.000384771, gnorm=0.319, clip=100, loss_scale=0.125, train_w[2022-11-13 02:35:49,590][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 02:35:51,601][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.888 | ppl 3.7 | wps 168467 | wpb 10521.6 | bsz 178.1 | num_updates 2600 | best_loss 1.681                                     
[2022-11-13 02:35:51,601][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 2600 updates
[2022-11-13 02:35:51,602][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_2600.pt
[2022-11-13 02:35:56,080][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_2600.pt
[2022-11-13 02:36:01,173][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_2600.pt (epoch 1 @ 2600 updates, score 1.888) (writing took 9.571112330071628 seconds)
epoch 001:  51%|â–Œ| 2804/5551 [15:02:45<14:43:01, 19.29s/it, loss=1.422, ppl=2.68, wps=27208.8, ups=0.05, wpb=522650, bsz=8559, num_updates=2760, lr=0.000382936, gnorm=0.396, clip=100, loss_scale=0.25, train_wall[2022-11-13 03:30:11,215][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:  51%|â–Œ| 2836/5551 [15:13:01<14:40:52, 19.47s/it, loss=1.422, ppl=2.68, wps=27208.8, ups=0.05, wpb=522650, bsz=8559, num_updates=2760, lr=0.000382936, gnorm=0.396, clip=100, loss_scale=0.25, train_wall[2022-11-13 03:40:27,589][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 03:40:29,631][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.797 | ppl 3.47 | wps 167344 | wpb 10521.6 | bsz 178.1 | num_updates 2800 | best_loss 1.681                                    
[2022-11-13 03:40:29,631][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 2800 updates
[2022-11-13 03:40:29,632][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_2800.pt
[2022-11-13 03:40:34,082][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_2800.pt
[2022-11-13 03:40:38,712][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_2800.pt (epoch 1 @ 2800 updates, score 1.797) (writing took 9.08076487109065 seconds)
epoch 001:  53%|â–Œ| 2922/5551 [15:40:47<14:01:30, 19.21s/it, loss=1.411, ppl=2.66, wps=27144.5, ups=0.05, wpb=523152, bsz=8845, num_updates=2880, lr=0.000381835, gnorm=0.293, clip=100, loss_scale=0.25, train_wall[2022-11-13 04:08:13,428][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:  53%|â–Œ| 2936/5551 [15:45:17<13:57:06, 19.21s/it, loss=1.411, ppl=2.66, wps=27144.5, ups=0.05, wpb=523152, bsz=8845, num_updates=2880, lr=0.000381835, gnorm=0.293, clip=100, loss_scale=0.25, train_wall[2022-11-13 04:12:42,580][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:  53%|â–Œ| 2938/5551 [15:45:55<13:56:03, 19.20s/it, loss=1.411, ppl=2.66, wps=27144.5, ups=0.05, wpb=523152, bsz=8845, num_updates=2880, lr=0.000381835, gnorm=0.293, clip=100, loss_scale=0.25, train_wall[2022-11-13 04:13:21,021][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 001:  53%|â–Œ| 2942/5551 [15:47:12<13:55:18, 19.21s/it, loss=1.411, ppl=2.66, wps=27144.5, ups=0.05, wpb=523152, bsz=8845, num_updates=2880, lr=0.000381835, gnorm=0.293, clip=100, loss_scale=0.25, train_wall[2022-11-13 04:14:38,074][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
epoch 001:  55%|â–Œ| 3040/5551 [16:18:35<13:28:00, 19.31s/it, loss=1.486, ppl=2.8, wps=27229, ups=0.05, wpb=523223, bsz=8626.4, num_updates=2960, lr=0.000381101, gnorm=1.305, clip=100, loss_scale=0.0156, train_wal[2022-11-13 04:46:00,717][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 04:46:02,757][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.671 | ppl 3.18 | wps 167037 | wpb 10521.6 | bsz 178.1 | num_updates 3000 | best_loss 1.671                                    
[2022-11-13 04:46:02,757][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 3000 updates
[2022-11-13 04:46:02,758][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_3000.pt
[2022-11-13 04:46:07,214][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_3000.pt
[2022-11-13 04:46:17,638][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 1.671) (writing took 14.88042294420302 seconds)
epoch 001:  57%|â–Œ| 3184/5551 [17:04:56<12:36:36, 19.18s/it, loss=1.381, ppl=2.6, wps=27198.5, ups=0.05, wpb=522459, bsz=8640.5, num_updates=3120, lr=0.000379633, gnorm=0.219, clip=100, loss_scale=0.0625, train_w[2022-11-13 05:32:22,280][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 001:  58%|â–Œ| 3241/5551 [17:23:10<12:19:23, 19.21s/it, loss=1.382, ppl=2.61, wps=26545.3, ups=0.05, wpb=522465, bsz=8784.7, num_updates=3160, lr=0.000379266, gnorm=0.199, clip=100, loss_scale=0.0312, train_[2022-11-13 05:50:36,083][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 05:50:38,107][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.738 | ppl 3.34 | wps 168517 | wpb 10521.6 | bsz 178.1 | num_updates 3200 | best_loss 1.671                                    
[2022-11-13 05:50:38,107][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 3200 updates
[2022-11-13 05:50:38,108][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_3200.pt
[2022-11-13 05:50:42,583][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_3200.pt
[2022-11-13 05:50:48,656][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_3200.pt (epoch 1 @ 3200 updates, score 1.738) (writing took 10.548544272780418 seconds)
epoch 001:  62%|â–Œ| 3441/5551 [18:27:27<11:18:03, 19.28s/it, loss=1.37, ppl=2.59, wps=27096.9, ups=0.05, wpb=521095, bsz=8939.8, num_updates=3360, lr=0.000377431, gnorm=0.24, clip=100, loss_scale=0.125, train_wal[2022-11-13 06:54:53,418][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 06:54:55,505][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.816 | ppl 3.52 | wps 161088 | wpb 10521.6 | bsz 178.1 | num_updates 3400 | best_loss 1.671                                    
[2022-11-13 06:54:55,505][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 3400 updates
[2022-11-13 06:54:55,506][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_3400.pt
[2022-11-13 06:54:59,989][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_3400.pt
[2022-11-13 06:55:04,465][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_3400.pt (epoch 1 @ 3400 updates, score 1.816) (writing took 8.959972734097391 seconds)
epoch 001:  63%|â–‹| 3487/5551 [18:42:25<11:00:22, 19.20s/it, loss=1.363, ppl=2.57, wps=26757.6, ups=0.05, wpb=523117, bsz=8755.5, num_updates=3440, lr=0.000376697, gnorm=0.227, clip=100, loss_scale=0.25, train_wa[2022-11-13 07:09:50,435][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:  63%|â–‹| 3488/5551 [18:42:44<10:59:20, 19.18s/it, loss=1.363, ppl=2.57, wps=26757.6, ups=0.05, wpb=523117, bsz=8755.5, num_updates=3440, lr=0.000376697, gnorm=0.227, clip=100, loss_scale=0.25, train_wa[2022-11-13 07:10:09,519][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:  63%|â–‹| 3489/5551 [18:43:03<10:58:04, 19.15s/it, loss=1.363, ppl=2.57, wps=26757.6, ups=0.05, wpb=523117, bsz=8755.5, num_updates=3440, lr=0.000376697, gnorm=0.227, clip=100, loss_scale=0.25, train_wa[2022-11-13 07:10:28,715][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 001:  63%|â–‹| 3493/5551 [18:44:19<10:57:42, 19.18s/it, loss=1.363, ppl=2.57, wps=26757.6, ups=0.05, wpb=523117, bsz=8755.5, num_updates=3440, lr=0.000376697, gnorm=0.227, clip=100, loss_scale=0.25, train_wa[2022-11-13 07:11:45,263][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
epoch 001:  63%|â–‹| 3494/5551 [18:44:39<10:56:52, 19.16s/it, loss=1.363, ppl=2.57, wps=26757.6, ups=0.05, wpb=523117, bsz=8755.5, num_updates=3440, lr=0.000376697, gnorm=0.227, clip=100, loss_scale=0.25, train_wa[2022-11-13 07:12:04,524][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0078125
epoch 001:  66%|â–‹| 3646/5551 [19:33:14<10:08:27, 19.16s/it, loss=1.404, ppl=2.65, wps=27247.1, ups=0.05, wpb=521931, bsz=8516.7, num_updates=3560, lr=0.000375596, gnorm=1.574, clip=100, loss_scale=0.0156, train_[2022-11-13 08:00:39,650][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 08:00:41,681][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.819 | ppl 3.53 | wps 168281 | wpb 10521.6 | bsz 178.1 | num_updates 3600 | best_loss 1.671                                    
[2022-11-13 08:00:41,682][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 3600 updates
[2022-11-13 08:00:41,682][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_3600.pt
[2022-11-13 08:00:46,141][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_3600.pt
[2022-11-13 08:00:51,054][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_3600.pt (epoch 1 @ 3600 updates, score 1.819) (writing took 9.371888531837612 seconds)
epoch 001:  69%|â–‹| 3809/5551 [20:25:35<9:15:57, 19.15s/it, loss=1.347, ppl=2.54, wps=27210.8, ups=0.05, wpb=522088, bsz=8685.1, num_updates=3760, lr=0.000373761, gnorm=0.248, clip=100, loss_scale=0.0625, train_w[2022-11-13 08:53:00,785][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 001:  69%|â–‹| 3847/5551 [20:37:46<9:05:04, 19.19s/it, loss=1.347, ppl=2.54, wps=27210.8, ups=0.05, wpb=522088, bsz=8685.1, num_updates=3760, lr=0.000373761, gnorm=0.248, clip=100, loss_scale=0.0625, train_w[2022-11-13 09:05:11,970][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 09:05:14,006][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.735 | ppl 3.33 | wps 167929 | wpb 10521.6 | bsz 178.1 | num_updates 3800 | best_loss 1.671                                    
[2022-11-13 09:05:14,007][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 3800 updates
[2022-11-13 09:05:14,007][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_3800.pt
[2022-11-13 09:05:18,424][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_3800.pt
[2022-11-13 09:05:22,859][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_3800.pt (epoch 1 @ 3800 updates, score 1.735) (writing took 8.85224489774555 seconds)
epoch 001:  73%|â–‹| 4047/5551 [21:42:04<8:03:40, 19.30s/it, loss=1.338, ppl=2.53, wps=27186.7, ups=0.05, wpb=522925, bsz=8781.1, num_updates=3960, lr=0.000371927, gnorm=0.234, clip=100, loss_scale=0.125, train_wa[2022-11-13 10:09:30,407][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 10:09:32,444][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.759 | ppl 3.38 | wps 167593 | wpb 10521.6 | bsz 178.1 | num_updates 4000 | best_loss 1.671                                    
[2022-11-13 10:09:32,444][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 4000 updates
[2022-11-13 10:09:32,445][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_4000.pt
[2022-11-13 10:09:36,903][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_4000.pt
[2022-11-13 10:09:41,392][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 1.759) (writing took 8.947762230876833 seconds)
epoch 001:  75%|â–‹| 4152/5551 [22:15:55<7:23:35, 19.02s/it, loss=1.324, ppl=2.5, wps=27156, ups=0.05, wpb=522840, bsz=8863.6, num_updates=4080, lr=0.000370826, gnorm=0.275, clip=100, loss_scale=0.25, train_wall=7[2022-11-13 10:43:20,968][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 001:  75%|â–‹| 4160/5551 [22:18:29<7:24:50, 19.19s/it, loss=1.324, ppl=2.5, wps=27156, ups=0.05, wpb=522840, bsz=8863.6, num_updates=4080, lr=0.000370826, gnorm=0.275, clip=100, loss_scale=0.25, train_wall=7[2022-11-13 10:45:54,545][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:  76%|â–Š| 4199/5551 [22:30:57<7:14:29, 19.28s/it, loss=1.354, ppl=2.56, wps=25922.1, ups=0.05, wpb=522203, bsz=8557, num_updates=4120, lr=0.000370459, gnorm=0.637, clip=100, loss_scale=0.125, train_wall[2022-11-13 10:58:23,367][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:  77%|â–Š| 4250/5551 [22:47:18<6:58:50, 19.32s/it, loss=1.329, ppl=2.51, wps=26566, ups=0.05, wpb=522926, bsz=8878.4, num_updates=4160, lr=0.000370092, gnorm=0.214, clip=100, loss_scale=0.0625, train_wal[2022-11-13 11:14:44,150][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 11:14:46,176][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.742 | ppl 3.35 | wps 168138 | wpb 10521.6 | bsz 178.1 | num_updates 4200 | best_loss 1.671                                    
[2022-11-13 11:14:46,177][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 4200 updates
[2022-11-13 11:14:46,177][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_4200.pt
[2022-11-13 11:14:50,604][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_4200.pt
[2022-11-13 11:14:55,210][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_4200.pt (epoch 1 @ 4200 updates, score 1.742) (writing took 9.033573559019715 seconds)
epoch 001:  78%|â–Š| 4319/5551 [23:09:36<6:33:46, 19.18s/it, loss=1.322, ppl=2.5, wps=26823.1, ups=0.05, wpb=522712, bsz=8653.4, num_updates=4240, lr=0.000369358, gnorm=0.214, clip=100, loss_scale=0.125, train_wal[2022-11-13 11:37:02,441][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:  80%|â–Š| 4451/5551 [23:51:54<5:53:14, 19.27s/it, loss=1.314, ppl=2.49, wps=27208.4, ups=0.05, wpb=522563, bsz=8591.5, num_updates=4360, lr=0.000368257, gnorm=0.189, clip=100, loss_scale=0.125, train_wa[2022-11-13 12:19:20,227][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 12:19:22,248][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.591 | ppl 3.01 | wps 168013 | wpb 10521.6 | bsz 178.1 | num_updates 4400 | best_loss 1.591                                    
[2022-11-13 12:19:22,249][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 4400 updates
[2022-11-13 12:19:22,249][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_4400.pt
[2022-11-13 12:19:26,707][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_4400.pt
[2022-11-13 12:19:38,046][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_4400.pt (epoch 1 @ 4400 updates, score 1.591) (writing took 15.797564046923071 seconds)
epoch 001:  84%|â–Š| 4651/5551 [24:56:18<4:49:18, 19.29s/it, loss=1.306, ppl=2.47, wps=27171.2, ups=0.05, wpb=522390, bsz=8889.4, num_updates=4560, lr=0.000366422, gnorm=0.195, clip=100, loss_scale=0.5, train_wall[2022-11-13 13:23:43,840][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 13:23:45,865][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.708 | ppl 3.27 | wps 168600 | wpb 10521.6 | bsz 178.1 | num_updates 4600 | best_loss 1.591                                    
[2022-11-13 13:23:45,865][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 4600 updates
[2022-11-13 13:23:45,866][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_4600.pt
[2022-11-13 13:23:50,336][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_4600.pt
[2022-11-13 13:23:55,293][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_4600.pt (epoch 1 @ 4600 updates, score 1.708) (writing took 9.427194362971932 seconds)
epoch 001:  84%|â–Š| 4669/5551 [25:02:15<4:42:16, 19.20s/it, loss=1.309, ppl=2.48, wps=27141.4, ups=0.05, wpb=522550, bsz=8998, num_updates=4600, lr=0.000366055, gnorm=0.252, clip=100, loss_scale=0.5, train_wall=7[2022-11-13 13:29:40,619][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 001:  84%|â–Š| 4679/5551 [25:05:27<4:38:23, 19.16s/it, loss=1.309, ppl=2.48, wps=27141.4, ups=0.05, wpb=522550, bsz=8998, num_updates=4600, lr=0.000366055, gnorm=0.252, clip=100, loss_scale=0.5, train_wall=7[2022-11-13 13:32:52,889][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 001:  85%|â–Š| 4691/5551 [25:09:18<4:37:06, 19.33s/it, loss=1.309, ppl=2.48, wps=27141.4, ups=0.05, wpb=522550, bsz=8998, num_updates=4600, lr=0.000366055, gnorm=0.252, clip=100, loss_scale=0.5, train_wall=7[2022-11-13 13:36:44,318][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:  86%|â–Š| 4774/5551 [25:35:56<4:10:17, 19.33s/it, loss=1.328, ppl=2.51, wps=27138.4, ups=0.05, wpb=521113, bsz=8457, num_updates=4680, lr=0.000365321, gnorm=0.401, clip=100, loss_scale=0.125, train_wall[2022-11-13 14:03:21,942][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:  87%|â–Š| 4855/5551 [26:01:54<3:42:59, 19.22s/it, loss=1.316, ppl=2.49, wps=27161.7, ups=0.05, wpb=522465, bsz=8960.7, num_updates=4760, lr=0.000364587, gnorm=0.388, clip=100, loss_scale=0.0625, train_w[2022-11-13 14:29:20,344][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 14:29:22,373][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.729 | ppl 3.31 | wps 167577 | wpb 10521.6 | bsz 178.1 | num_updates 4800 | best_loss 1.591                                    
[2022-11-13 14:29:22,373][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 4800 updates
[2022-11-13 14:29:22,374][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_4800.pt
[2022-11-13 14:29:26,839][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_4800.pt
[2022-11-13 14:29:31,172][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_4800.pt (epoch 1 @ 4800 updates, score 1.729) (writing took 8.798192664049566 seconds)
epoch 001:  91%|â–‰| 5041/5551 [27:01:50<2:44:57, 19.41s/it, loss=1.303, ppl=2.47, wps=27171.9, ups=0.05, wpb=524027, bsz=8894.8, num_updates=4960, lr=0.000362752, gnorm=0.219, clip=100, loss_scale=0.25, train_wal[2022-11-13 15:29:15,771][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 001:  91%|â–‰| 5056/5551 [27:06:38<2:39:13, 19.30s/it, loss=1.303, ppl=2.47, wps=27171.9, ups=0.05, wpb=524027, bsz=8894.8, num_updates=4960, lr=0.000362752, gnorm=0.219, clip=100, loss_scale=0.25, train_wal[2022-11-13 15:34:04,115][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 15:34:06,149][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.601 | ppl 3.03 | wps 166648 | wpb 10521.6 | bsz 178.1 | num_updates 5000 | best_loss 1.591                                    
[2022-11-13 15:34:06,149][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 5000 updates
[2022-11-13 15:34:06,150][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_5000.pt
[2022-11-13 15:34:10,618][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_5000.pt
[2022-11-13 15:34:15,058][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 1.601) (writing took 8.908761600032449 seconds)
epoch 001:  91%|â–‰| 5061/5551 [27:08:25<2:43:18, 20.00s/it, loss=1.292, ppl=2.45, wps=26458.4, ups=0.05, wpb=523042, bsz=9105.7, num_updates=5000, lr=0.000362385, gnorm=0.173, clip=100, loss_scale=0.25, train_wal[2022-11-13 15:35:50,771][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 001:  91%|â–‰| 5062/5551 [27:08:44<2:40:30, 19.69s/it, loss=1.292, ppl=2.45, wps=26458.4, ups=0.05, wpb=523042, bsz=9105.7, num_updates=5000, lr=0.000362385, gnorm=0.173, clip=100, loss_scale=0.25, train_wal[2022-11-13 15:36:09,805][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 001:  91%|â–‰| 5063/5551 [27:09:03<2:38:33, 19.50s/it, loss=1.292, ppl=2.45, wps=26458.4, ups=0.05, wpb=523042, bsz=9105.7, num_updates=5000, lr=0.000362385, gnorm=0.173, clip=100, loss_scale=0.25, train_wal[2022-11-13 15:36:29,067][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 001:  91%|â–‰| 5067/5551 [27:10:20<2:35:46, 19.31s/it, loss=1.292, ppl=2.45, wps=26458.4, ups=0.05, wpb=523042, bsz=9105.7, num_updates=5000, lr=0.000362385, gnorm=0.173, clip=100, loss_scale=0.25, train_wal[2022-11-13 15:37:46,064][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
epoch 001:  92%|â–‰| 5080/5551 [27:14:30<2:30:13, 19.14s/it, loss=1.292, ppl=2.45, wps=26458.4, ups=0.05, wpb=523042, bsz=9105.7, num_updates=5000, lr=0.000362385, gnorm=0.173, clip=100, loss_scale=0.25, train_wal[2022-11-13 15:41:55,541][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0078125
epoch 001:  95%|â–‰| 5261/5551 [28:12:29<1:33:29, 19.34s/it, loss=1.283, ppl=2.43, wps=27204.5, ups=0.05, wpb=523265, bsz=8701.5, num_updates=5160, lr=0.000360917, gnorm=0.259, clip=100, loss_scale=0.0156, train_w[2022-11-13 16:39:54,937][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 16:39:57,007][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.419 | ppl 2.67 | wps 161075 | wpb 10521.6 | bsz 178.1 | num_updates 5200 | best_loss 1.419                                    
[2022-11-13 16:39:57,008][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 5200 updates
[2022-11-13 16:39:57,008][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_5200.pt
[2022-11-13 16:40:01,478][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_5200.pt
[2022-11-13 16:40:10,881][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_5200.pt (epoch 1 @ 5200 updates, score 1.419) (writing took 13.873036990873516 seconds)
epoch 001:  97%|â–‰| 5381/5551 [28:51:14<54:38, 19.29s/it, loss=1.281, ppl=2.43, wps=27138.3, ups=0.05, wpb=521429, bsz=8503.3, num_updates=5280, lr=0.000359817, gnorm=0.192, clip=100, loss_scale=0.0625, train_wal[2022-11-13 17:18:40,218][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 001:  98%|â–‰| 5462/5551 [29:17:12<28:31, 19.23s/it, loss=1.36, ppl=2.57, wps=27169.9, ups=0.05, wpb=522361, bsz=8749.8, num_updates=5360, lr=0.000359083, gnorm=2.216, clip=100, loss_scale=0.0312, train_wall[2022-11-13 17:44:37,809][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 17:44:39,837][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.69 | ppl 3.23 | wps 165719 | wpb 10521.6 | bsz 178.1 | num_updates 5400 | best_loss 1.419                                     
[2022-11-13 17:44:39,838][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 5400 updates
[2022-11-13 17:44:39,838][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_5400.pt
[2022-11-13 17:44:44,301][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_1_5400.pt
[2022-11-13 17:44:49,796][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_1_5400.pt (epoch 1 @ 5400 updates, score 1.69) (writing took 9.958366909995675 seconds)
epoch 001: 100%|â–‰| 5550/5551 [29:45:38<00:19, 19.18s/it, loss=1.277, ppl=2.42, wps=27150.3, ups=0.05, wpb=523257, bsz=8811.4, num_updates=5480, lr=0.000357982, gnorm=0.295, clip=100, loss_scale=0.0625, train_wal[2022-11-13 18:13:01,642][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 18:13:03,649][valid][INFO] - epoch 001 | valid on 'valid' subset | loss 1.493 | ppl 2.81 | wps 168121 | wpb 10521.6 | bsz 178.1 | num_updates 5488 | best_loss 1.419                                    
[2022-11-13 18:13:03,650][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 5488 updates
[2022-11-13 18:13:03,650][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint1.pt
[2022-11-13 18:13:08,126][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint1.pt
[2022-11-13 18:13:12,759][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint1.pt (epoch 1 @ 5488 updates, score 1.493) (writing took 9.109624829608947 seconds)
[2022-11-13 18:13:12,760][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)                                                                                                                    
[2022-11-13 18:13:12,761][train][INFO] - epoch 001 | loss 1.607 | ppl 3.05 | wps 26832.9 | ups 0.05 | wpb 522624 | bsz 8746.3 | num_updates 5488 | lr 0.000357908 | gnorm 0.637 | clip 100 | loss_scale 0.0625 | train_wall 104695 | gb_free 6.7 | wall 107359
[2022-11-13 18:13:13,261][fairseq.data.iterators][INFO] - grouped total_num_itrs = 5551
epoch 002:   0%|                                                                                                                                                                          | 0/5551 [00:00<?, ?it/s][2022-11-13 18:13:13,277][fairseq.trainer][INFO] - begin training epoch 2
[2022-11-13 18:13:13,278][fairseq_cli.train][INFO] - Start iterating over samples
epoch 002:   2%| | 111/5551 [35:39<29:00:12, 19.19s/it, loss=1.27, ppl=2.41, wps=27133.8, ups=0.05, wpb=523512, bsz=9100.8, num_updates=5560, lr=0.000357248, gnorm=0.182, clip=100, loss_scale=0.125, train_wall=7[2022-11-13 18:49:11,451][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 18:49:13,470][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.651 | ppl 3.14 | wps 166806 | wpb 10521.6 | bsz 178.1 | num_updates 5600 | best_loss 1.419                                    
[2022-11-13 18:49:13,471][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 5600 updates
[2022-11-13 18:49:13,472][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_5600.pt
[2022-11-13 18:49:18,012][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_5600.pt
[2022-11-13 18:49:21,517][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_5600.pt (epoch 2 @ 5600 updates, score 1.651) (writing took 8.045935076195747 seconds)
epoch 002:   3%| | 186/5551 [59:53<28:40:53, 19.25s/it, loss=1.264, ppl=2.4, wps=26810.7, ups=0.05, wpb=522504, bsz=8773.6, num_updates=5640, lr=0.000356514, gnorm=0.164, clip=100, loss_scale=0.25, train_wall=75[2022-11-13 19:13:25,947][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 002:   5%| | 264/5551 [1:24:55<28:20:05, 19.29s/it, loss=1.263, ppl=2.4, wps=27102.6, ups=0.05, wpb=522065, bsz=8585.5, num_updates=5720, lr=0.00035578, gnorm=0.209, clip=100, loss_scale=0.25, train_wall=7[2022-11-13 19:38:28,153][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 002:   5%| | 267/5551 [1:25:53<28:17:58, 19.28s/it, loss=1.263, ppl=2.4, wps=27102.6, ups=0.05, wpb=522065, bsz=8585.5, num_updates=5720, lr=0.00035578, gnorm=0.209, clip=100, loss_scale=0.25, train_wall=7[2022-11-13 19:39:25,908][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 002:   6%| | 314/5551 [1:40:57<27:51:50, 19.15s/it, loss=1.334, ppl=2.52, wps=25822.6, ups=0.05, wpb=522032, bsz=8743.3, num_updates=5760, lr=0.000355413, gnorm=0.493, clip=100, loss_scale=0.0625, train_wa[2022-11-13 19:54:29,795][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 19:54:31,812][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.44 | ppl 2.71 | wps 167545 | wpb 10521.6 | bsz 178.1 | num_updates 5800 | best_loss 1.419                                     
[2022-11-13 19:54:31,813][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 5800 updates
[2022-11-13 19:54:31,813][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_5800.pt
[2022-11-13 19:54:36,269][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_5800.pt
[2022-11-13 19:54:40,524][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_5800.pt (epoch 2 @ 5800 updates, score 1.44) (writing took 8.710805618204176 seconds)
epoch 002:   7%| | 400/5551 [2:08:43<27:35:47, 19.29s/it, loss=1.263, ppl=2.4, wps=27134.9, ups=0.05, wpb=522190, bsz=8791.6, num_updates=5880, lr=0.000354312, gnorm=0.198, clip=100, loss_scale=0.125, train_wall[2022-11-13 20:22:15,846][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 002:   7%| | 401/5551 [2:09:02<27:41:24, 19.36s/it, loss=1.263, ppl=2.4, wps=27134.9, ups=0.05, wpb=522190, bsz=8791.6, num_updates=5880, lr=0.000354312, gnorm=0.198, clip=100, loss_scale=0.125, train_wall[2022-11-13 20:22:35,115][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 002:   7%| | 404/5551 [2:10:00<27:36:56, 19.32s/it, loss=1.263, ppl=2.4, wps=27134.9, ups=0.05, wpb=522190, bsz=8791.6, num_updates=5880, lr=0.000354312, gnorm=0.198, clip=100, loss_scale=0.125, train_wall[2022-11-13 20:23:32,892][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
epoch 002:   9%| | 502/5551 [2:41:21<27:01:58, 19.27s/it, loss=1.284, ppl=2.44, wps=27152.1, ups=0.05, wpb=520933, bsz=8590.1, num_updates=5960, lr=0.000353578, gnorm=0.575, clip=100, loss_scale=0.0156, train_wa[2022-11-13 20:54:54,356][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
epoch 002:   9%| | 510/5551 [2:43:55<26:53:43, 19.21s/it, loss=1.284, ppl=2.44, wps=27152.1, ups=0.05, wpb=520933, bsz=8590.1, num_updates=5960, lr=0.000353578, gnorm=0.575, clip=100, loss_scale=0.0156, train_wa[2022-11-13 20:57:28,350][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0078125
epoch 002:   9%| | 512/5551 [2:44:34<26:51:54, 19.19s/it, loss=1.284, ppl=2.44, wps=27152.1, ups=0.05, wpb=520933, bsz=8590.1, num_updates=5960, lr=0.000353578, gnorm=0.575, clip=100, loss_scale=0.0156, train_wa[2022-11-13 20:58:06,516][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.00390625
epoch 002:   9%| | 520/5551 [2:47:07<26:51:41, 19.22s/it, loss=1.284, ppl=2.44, wps=27152.1, ups=0.05, wpb=520933, bsz=8590.1, num_updates=5960, lr=0.000353578, gnorm=0.575, clip=100, loss_scale=0.0156, train_wa[2022-11-13 21:00:40,223][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 21:00:42,245][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 2.575 | ppl 5.96 | wps 167525 | wpb 10521.6 | bsz 178.1 | num_updates 6000 | best_loss 1.419                                    
[2022-11-13 21:00:42,245][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 6000 updates
[2022-11-13 21:00:42,246][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_6000.pt
[2022-11-13 21:00:46,699][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_6000.pt
[2022-11-13 21:00:50,881][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_6000.pt (epoch 2 @ 6000 updates, score 2.575) (writing took 8.635560696013272 seconds)
epoch 002:  13%|â–| 720/5551 [3:51:22<25:55:19, 19.32s/it, loss=1.282, ppl=2.43, wps=27137, ups=0.05, wpb=521662, bsz=8929.3, num_updates=6160, lr=0.000351743, gnorm=0.649, clip=100, loss_scale=0.0078, train_wall[2022-11-13 22:04:54,916][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 22:04:56,926][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.672 | ppl 3.19 | wps 168244 | wpb 10521.6 | bsz 178.1 | num_updates 6200 | best_loss 1.419                                    
[2022-11-13 22:04:56,927][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 6200 updates
[2022-11-13 22:04:56,927][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_6200.pt
[2022-11-13 22:05:01,397][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_6200.pt
[2022-11-13 22:05:05,203][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_6200.pt (epoch 2 @ 6200 updates, score 1.672) (writing took 8.275668530724943 seconds)
epoch 002:  13%|â–| 745/5551 [3:59:32<25:31:48, 19.12s/it, loss=1.289, ppl=2.44, wps=27145.5, ups=0.05, wpb=521971, bsz=8726.5, num_updates=6200, lr=0.000351376, gnorm=0.686, clip=100, loss_scale=0.0156, train_wa[2022-11-13 22:13:04,507][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0078125
epoch 002:  16%|â–| 876/5551 [4:41:29<24:52:19, 19.15s/it, loss=1.323, ppl=2.5, wps=27246.8, ups=0.05, wpb=524218, bsz=9077.9, num_updates=6320, lr=0.000350275, gnorm=1.358, clip=100, loss_scale=0.0156, train_wal[2022-11-13 22:55:02,587][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0078125
epoch 002:  16%|â–| 879/5551 [4:42:27<24:58:54, 19.25s/it, loss=1.323, ppl=2.5, wps=27246.8, ups=0.05, wpb=524218, bsz=9077.9, num_updates=6320, lr=0.000350275, gnorm=1.358, clip=100, loss_scale=0.0156, train_wal[2022-11-13 22:55:59,971][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.00390625
epoch 002:  16%|â–| 884/5551 [4:44:03<24:55:25, 19.23s/it, loss=1.3, ppl=2.46, wps=25835.8, ups=0.05, wpb=521747, bsz=8684.7, num_updates=6360, lr=0.000349908, gnorm=1.153, clip=100, loss_scale=0.0039, train_wall[2022-11-13 22:57:36,280][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.001953125
epoch 002:  17%|â–| 924/5551 [4:56:50<24:40:30, 19.20s/it, loss=1.3, ppl=2.46, wps=25835.8, ups=0.05, wpb=521747, bsz=8684.7, num_updates=6360, lr=0.000349908, gnorm=1.153, clip=100, loss_scale=0.0039, train_wall[2022-11-13 23:10:22,833][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-13 23:10:24,841][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.785 | ppl 3.45 | wps 167689 | wpb 10521.6 | bsz 178.1 | num_updates 6400 | best_loss 1.419                                    
[2022-11-13 23:10:24,841][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 6400 updates
[2022-11-13 23:10:24,842][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_6400.pt
[2022-11-13 23:10:29,296][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_6400.pt
[2022-11-13 23:10:33,814][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_6400.pt (epoch 2 @ 6400 updates, score 1.785) (writing took 8.972751889377832 seconds)
epoch 002:  20%|â–| 1124/5551 [6:00:59<23:38:34, 19.23s/it, loss=1.262, ppl=2.4, wps=27223.3, ups=0.05, wpb=522288, bsz=8799.8, num_updates=6560, lr=0.000348073, gnorm=0.629, clip=100, loss_scale=0.0078, train_wa[2022-11-14 00:14:32,046][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 00:14:34,059][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.78 | ppl 3.43 | wps 168090 | wpb 10521.6 | bsz 178.1 | num_updates 6600 | best_loss 1.419                                     
[2022-11-14 00:14:34,060][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 6600 updates
[2022-11-14 00:14:34,060][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_6600.pt
[2022-11-14 00:14:38,526][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_6600.pt
[2022-11-14 00:14:42,046][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_6600.pt (epoch 2 @ 6600 updates, score 1.78) (writing took 7.986006205901504 seconds)
epoch 002:  22%|â–| 1234/5551 [6:36:24<23:00:17, 19.18s/it, loss=1.29, ppl=2.44, wps=27173.2, ups=0.05, wpb=521508, bsz=8747.4, num_updates=6680, lr=0.000346972, gnorm=1.267, clip=100, loss_scale=0.0156, train_wa[2022-11-14 00:49:56,867][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
epoch 002:  24%|â–| 1324/5551 [7:05:14<22:37:11, 19.26s/it, loss=1.263, ppl=2.4, wps=27239.1, ups=0.05, wpb=522855, bsz=8649.6, num_updates=6760, lr=0.000346239, gnorm=0.307, clip=100, loss_scale=0.0156, train_wa[2022-11-14 01:18:46,957][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
epoch 002:  24%|â–| 1326/5551 [7:05:53<22:41:37, 19.34s/it, loss=1.263, ppl=2.4, wps=27239.1, ups=0.05, wpb=522855, bsz=8649.6, num_updates=6760, lr=0.000346239, gnorm=0.307, clip=100, loss_scale=0.0156, train_wa[2022-11-14 01:19:25,518][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 01:19:27,533][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.756 | ppl 3.38 | wps 168114 | wpb 10521.6 | bsz 178.1 | num_updates 6800 | best_loss 1.419                                    
[2022-11-14 01:19:27,534][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 6800 updates
[2022-11-14 01:19:27,535][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_6800.pt
[2022-11-14 01:19:31,981][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_6800.pt
[2022-11-14 01:19:35,171][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_6800.pt (epoch 2 @ 6800 updates, score 1.756) (writing took 7.6364148408174515 seconds)
epoch 002:  27%|â–Ž| 1526/5551 [8:10:04<21:25:38, 19.16s/it, loss=1.263, ppl=2.4, wps=27234, ups=0.05, wpb=523147, bsz=8692.4, num_updates=6960, lr=0.000344404, gnorm=0.956, clip=100, loss_scale=0.0312, train_wall[2022-11-14 02:23:37,402][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 02:23:39,421][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.442 | ppl 2.72 | wps 168070 | wpb 10521.6 | bsz 178.1 | num_updates 7000 | best_loss 1.419                                    
[2022-11-14 02:23:39,422][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 7000 updates
[2022-11-14 02:23:39,422][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_7000.pt
[2022-11-14 02:23:43,879][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_7000.pt
[2022-11-14 02:23:47,720][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_7000.pt (epoch 2 @ 7000 updates, score 1.442) (writing took 8.297774530015886 seconds)
epoch 002:  29%|â–Ž| 1591/5551 [8:31:05<21:02:45, 19.13s/it, loss=1.252, ppl=2.38, wps=26848.5, ups=0.05, wpb=523434, bsz=8889.4, num_updates=7040, lr=0.00034367, gnorm=0.221, clip=100, loss_scale=0.0625, train_wa[2022-11-14 02:44:38,070][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 002:  31%|â–Ž| 1719/5551 [9:12:07<20:20:40, 19.11s/it, loss=1.264, ppl=2.4, wps=27232.8, ups=0.05, wpb=523686, bsz=8864.4, num_updates=7160, lr=0.000342569, gnorm=0.392, clip=100, loss_scale=0.125, train_wal[2022-11-14 03:25:39,686][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 002:  31%|â–Ž| 1725/5551 [9:14:02<20:27:27, 19.25s/it, loss=1.264, ppl=2.4, wps=27232.8, ups=0.05, wpb=523686, bsz=8864.4, num_updates=7160, lr=0.000342569, gnorm=0.392, clip=100, loss_scale=0.125, train_wal[2022-11-14 03:27:35,249][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 002:  31%|â–Ž| 1729/5551 [9:15:19<20:27:35, 19.27s/it, loss=1.264, ppl=2.4, wps=27232.8, ups=0.05, wpb=523686, bsz=8864.4, num_updates=7160, lr=0.000342569, gnorm=0.392, clip=100, loss_scale=0.125, train_wal[2022-11-14 03:28:52,118][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 03:28:54,131][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.682 | ppl 3.21 | wps 167839 | wpb 10521.6 | bsz 178.1 | num_updates 7200 | best_loss 1.419                                    
[2022-11-14 03:28:54,132][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 7200 updates
[2022-11-14 03:28:54,132][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_7200.pt
[2022-11-14 03:28:58,584][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_7200.pt
[2022-11-14 03:29:01,688][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_7200.pt (epoch 2 @ 7200 updates, score 1.682) (writing took 7.555413180962205 seconds)
epoch 002:  32%|â–Ž| 1768/5551 [9:27:59<20:09:46, 19.19s/it, loss=1.315, ppl=2.49, wps=25876.2, ups=0.05, wpb=522352, bsz=8583.4, num_updates=7200, lr=0.000342202, gnorm=1.326, clip=100, loss_scale=0.0312, train_w[2022-11-14 03:41:31,519][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
epoch 002:  35%|â–Ž| 1930/5551 [10:19:53<19:22:27, 19.26s/it, loss=1.242, ppl=2.37, wps=27184.3, ups=0.05, wpb=522694, bsz=8777.4, num_updates=7360, lr=0.000340734, gnorm=0.613, clip=100, loss_scale=0.0312, train_[2022-11-14 04:33:25,606][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 04:33:27,642][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.532 | ppl 2.89 | wps 166624 | wpb 10521.6 | bsz 178.1 | num_updates 7400 | best_loss 1.419                                    
[2022-11-14 04:33:27,643][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 7400 updates
[2022-11-14 04:33:27,644][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_7400.pt
[2022-11-14 04:33:32,092][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_7400.pt
[2022-11-14 04:33:35,195][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_7400.pt (epoch 2 @ 7400 updates, score 1.532) (writing took 7.552136744372547 seconds)
epoch 002:  36%|â–Ž| 2020/5551 [10:48:54<18:58:54, 19.35s/it, loss=1.24, ppl=2.36, wps=27132.4, ups=0.05, wpb=522479, bsz=8841.1, num_updates=7480, lr=0.000339633, gnorm=0.409, clip=100, loss_scale=0.0625, train_w[2022-11-14 05:02:26,585][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 002:  37%|â–Ž| 2051/5551 [10:58:48<18:42:09, 19.24s/it, loss=1.24, ppl=2.36, wps=27132.4, ups=0.05, wpb=522479, bsz=8841.1, num_updates=7480, lr=0.000339633, gnorm=0.409, clip=100, loss_scale=0.0625, train_w[2022-11-14 05:12:21,327][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
epoch 002:  38%|â–| 2132/5551 [11:24:47<18:11:10, 19.15s/it, loss=1.239, ppl=2.36, wps=27188.9, ups=0.05, wpb=524069, bsz=9065.3, num_updates=7560, lr=0.000338899, gnorm=0.302, clip=100, loss_scale=0.0156, train_[2022-11-14 05:38:20,467][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 05:38:22,489][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.578 | ppl 2.99 | wps 167010 | wpb 10521.6 | bsz 178.1 | num_updates 7600 | best_loss 1.419                                    
[2022-11-14 05:38:22,490][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 7600 updates
[2022-11-14 05:38:22,490][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_7600.pt
[2022-11-14 05:38:26,943][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_7600.pt
[2022-11-14 05:38:30,049][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_7600.pt (epoch 2 @ 7600 updates, score 1.578) (writing took 7.558882465586066 seconds)
epoch 002:  42%|â–| 2332/5551 [12:28:59<17:14:05, 19.27s/it, loss=1.232, ppl=2.35, wps=27239.2, ups=0.05, wpb=523775, bsz=8812.3, num_updates=7760, lr=0.000337064, gnorm=0.297, clip=100, loss_scale=0.0625, train_[2022-11-14 06:42:32,350][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 06:42:34,374][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.614 | ppl 3.06 | wps 167127 | wpb 10521.6 | bsz 178.1 | num_updates 7800 | best_loss 1.419                                    
[2022-11-14 06:42:34,374][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 7800 updates
[2022-11-14 06:42:34,375][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_7800.pt
[2022-11-14 06:42:38,836][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_7800.pt
[2022-11-14 06:42:41,828][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_7800.pt (epoch 2 @ 7800 updates, score 1.614) (writing took 7.453888684511185 seconds)
epoch 002:  46%|â–| 2532/5551 [13:33:19<16:12:39, 19.33s/it, loss=1.231, ppl=2.35, wps=27206.9, ups=0.05, wpb=523662, bsz=8833, num_updates=7960, lr=0.000335229, gnorm=0.173, clip=100, loss_scale=0.5, train_wall=[2022-11-14 07:46:51,824][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 07:46:53,848][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.742 | ppl 3.34 | wps 167213 | wpb 10521.6 | bsz 178.1 | num_updates 8000 | best_loss 1.419                                    
[2022-11-14 07:46:53,848][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 8000 updates
[2022-11-14 07:46:53,849][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_8000.pt
[2022-11-14 07:46:58,305][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_8000.pt
[2022-11-14 07:47:01,420][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_8000.pt (epoch 2 @ 8000 updates, score 1.742) (writing took 7.572134912014008 seconds)
epoch 002:  46%|â–| 2575/5551 [13:47:16<15:53:01, 19.21s/it, loss=1.227, ppl=2.34, wps=26793.1, ups=0.05, wpb=522238, bsz=8632.8, num_updates=8040, lr=0.000334495, gnorm=0.183, clip=100, loss_scale=1, train_wall=[2022-11-14 08:00:48,961][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 002:  47%|â–| 2589/5551 [13:51:46<15:54:59, 19.34s/it, loss=1.227, ppl=2.34, wps=26793.1, ups=0.05, wpb=522238, bsz=8632.8, num_updates=8040, lr=0.000334495, gnorm=0.183, clip=100, loss_scale=1, train_wall=[2022-11-14 08:05:18,764][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 002:  47%|â–| 2599/5551 [13:54:58<15:45:10, 19.21s/it, loss=1.227, ppl=2.34, wps=26793.1, ups=0.05, wpb=522238, bsz=8632.8, num_updates=8040, lr=0.000334495, gnorm=0.183, clip=100, loss_scale=1, train_wall=[2022-11-14 08:08:31,419][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 002:  49%|â–| 2735/5551 [14:38:44<15:10:49, 19.41s/it, loss=1.228, ppl=2.34, wps=27193.1, ups=0.05, wpb=523388, bsz=8760.5, num_updates=8160, lr=0.000333394, gnorm=0.242, clip=100, loss_scale=0.25, train_wa[2022-11-14 08:52:16,762][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 08:52:18,784][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.592 | ppl 3.01 | wps 166966 | wpb 10521.6 | bsz 178.1 | num_updates 8200 | best_loss 1.419                                    
[2022-11-14 08:52:18,784][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 8200 updates
[2022-11-14 08:52:18,785][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_8200.pt
[2022-11-14 08:52:23,239][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_8200.pt
[2022-11-14 08:52:26,405][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_8200.pt (epoch 2 @ 8200 updates, score 1.592) (writing took 7.620386118069291 seconds)
epoch 002:  50%|â–Œ| 2781/5551 [14:53:40<14:49:17, 19.26s/it, loss=1.225, ppl=2.34, wps=26820.2, ups=0.05, wpb=523647, bsz=8888, num_updates=8240, lr=0.000332661, gnorm=0.166, clip=100, loss_scale=0.5, train_wall=[2022-11-14 09:07:13,508][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 002:  50%|â–Œ| 2782/5551 [14:54:00<14:50:13, 19.29s/it, loss=1.225, ppl=2.34, wps=26820.2, ups=0.05, wpb=523647, bsz=8888, num_updates=8240, lr=0.000332661, gnorm=0.166, clip=100, loss_scale=0.5, train_wall=[2022-11-14 09:07:32,891][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 002:  50%|â–Œ| 2784/5551 [14:54:38<14:47:45, 19.25s/it, loss=1.225, ppl=2.34, wps=26820.2, ups=0.05, wpb=523647, bsz=8888, num_updates=8240, lr=0.000332661, gnorm=0.166, clip=100, loss_scale=0.5, train_wall=[2022-11-14 09:08:10,915][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 002:  51%|â–Œ| 2819/5551 [15:05:51<14:35:08, 19.22s/it, loss=1.237, ppl=2.36, wps=25281.4, ups=0.05, wpb=522867, bsz=8749.2, num_updates=8280, lr=0.000332294, gnorm=0.328, clip=100, loss_scale=0.0625, train_[2022-11-14 09:19:24,211][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 002:  53%|â–Œ| 2939/5551 [15:44:17<13:56:25, 19.21s/it, loss=1.224, ppl=2.34, wps=27235.3, ups=0.05, wpb=523429, bsz=8648.4, num_updates=8360, lr=0.00033156, gnorm=0.201, clip=100, loss_scale=0.0312, train_w[2022-11-14 09:57:49,571][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 09:57:51,597][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.559 | ppl 2.95 | wps 166960 | wpb 10521.6 | bsz 178.1 | num_updates 8400 | best_loss 1.419                                    
[2022-11-14 09:57:51,598][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 8400 updates
[2022-11-14 09:57:51,598][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_8400.pt
[2022-11-14 09:57:56,089][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_8400.pt
[2022-11-14 09:57:59,913][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_8400.pt (epoch 2 @ 8400 updates, score 1.559) (writing took 8.315558969974518 seconds)
epoch 002:  56%|â–Œ| 3084/5551 [16:30:56<13:09:05, 19.19s/it, loss=1.223, ppl=2.33, wps=27146.6, ups=0.05, wpb=521864, bsz=8610.3, num_updates=8520, lr=0.000330092, gnorm=0.17, clip=100, loss_scale=0.125, train_wa[2022-11-14 10:44:28,869][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 002:  57%|â–Œ| 3140/5551 [16:48:53<12:54:09, 19.27s/it, loss=1.218, ppl=2.33, wps=26528.7, ups=0.05, wpb=522914, bsz=8855.3, num_updates=8560, lr=0.000329725, gnorm=0.184, clip=100, loss_scale=0.125, train_w[2022-11-14 11:02:26,213][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 11:02:28,231][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.579 | ppl 2.99 | wps 167978 | wpb 10521.6 | bsz 178.1 | num_updates 8600 | best_loss 1.419                                    
[2022-11-14 11:02:28,231][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 8600 updates
[2022-11-14 11:02:28,232][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_8600.pt
[2022-11-14 11:02:32,694][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_8600.pt
[2022-11-14 11:02:35,832][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_8600.pt (epoch 2 @ 8600 updates, score 1.579) (writing took 7.600443477742374 seconds)
epoch 002:  59%|â–Œ| 3271/5551 [17:31:01<12:11:11, 19.24s/it, loss=1.212, ppl=2.32, wps=27199.2, ups=0.05, wpb=522834, bsz=8708.7, num_updates=8720, lr=0.000328257, gnorm=0.176, clip=100, loss_scale=0.5, train_wal[2022-11-14 11:44:34,371][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 002:  60%|â–Œ| 3341/5551 [17:53:27<11:47:51, 19.22s/it, loss=1.216, ppl=2.32, wps=26544.8, ups=0.05, wpb=522494, bsz=8596.2, num_updates=8760, lr=0.00032789, gnorm=0.226, clip=100, loss_scale=0.25, train_wal[2022-11-14 12:06:59,704][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 12:07:01,739][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.702 | ppl 3.25 | wps 166269 | wpb 10521.6 | bsz 178.1 | num_updates 8800 | best_loss 1.419                                    
[2022-11-14 12:07:01,739][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 8800 updates
[2022-11-14 12:07:01,740][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_8800.pt
[2022-11-14 12:07:06,207][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_8800.pt
[2022-11-14 12:07:09,075][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_8800.pt (epoch 2 @ 8800 updates, score 1.702) (writing took 7.335616911761463 seconds)
epoch 002:  62%|â–Œ| 3442/5551 [18:26:01<11:12:32, 19.13s/it, loss=1.209, ppl=2.31, wps=27122.8, ups=0.05, wpb=522007, bsz=8549.8, num_updates=8880, lr=0.000326789, gnorm=0.182, clip=100, loss_scale=0.5, train_wal[2022-11-14 12:39:34,004][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 002:  64%|â–‹| 3542/5551 [18:58:06<10:42:26, 19.19s/it, loss=1.203, ppl=2.3, wps=27080.9, ups=0.05, wpb=522027, bsz=8862.5, num_updates=8960, lr=0.000326055, gnorm=0.186, clip=100, loss_scale=0.5, train_wall[2022-11-14 13:11:38,620][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 13:11:40,653][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.588 | ppl 3.01 | wps 166969 | wpb 10521.6 | bsz 178.1 | num_updates 9000 | best_loss 1.419                                    
[2022-11-14 13:11:40,654][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 9000 updates
[2022-11-14 13:11:40,654][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_9000.pt
[2022-11-14 13:11:45,123][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_9000.pt
[2022-11-14 13:11:48,079][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_9000.pt (epoch 2 @ 9000 updates, score 1.588) (writing took 7.4247994888573885 seconds)
epoch 002:  65%|â–‹| 3612/5551 [19:20:44<10:21:37, 19.24s/it, loss=1.207, ppl=2.31, wps=26775, ups=0.05, wpb=522479, bsz=9019.9, num_updates=9040, lr=0.000325321, gnorm=0.165, clip=100, loss_scale=1, train_wall=75[2022-11-14 13:34:16,452][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 002:  65%|â–‹| 3613/5551 [19:21:03<10:20:52, 19.22s/it, loss=1.207, ppl=2.31, wps=26775, ups=0.05, wpb=522479, bsz=9019.9, num_updates=9040, lr=0.000325321, gnorm=0.165, clip=100, loss_scale=1, train_wall=75[2022-11-14 13:34:35,842][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 002:  65%|â–‹| 3620/5551 [19:23:18<10:24:26, 19.40s/it, loss=1.207, ppl=2.31, wps=26775, ups=0.05, wpb=522479, bsz=9019.9, num_updates=9040, lr=0.000325321, gnorm=0.165, clip=100, loss_scale=1, train_wall=75[2022-11-14 13:36:51,149][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 002:  67%|â–‹| 3725/5551 [19:57:03<9:47:18, 19.30s/it, loss=1.204, ppl=2.3, wps=27112.5, ups=0.05, wpb=523523, bsz=8789.5, num_updates=9160, lr=0.00032422, gnorm=0.23, clip=100, loss_scale=0.25, train_wall=7[2022-11-14 14:10:36,681][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 002:  67%|â–‹| 3746/5551 [20:03:47<9:38:27, 19.23s/it, loss=1.204, ppl=2.3, wps=27112.5, ups=0.05, wpb=523523, bsz=8789.5, num_updates=9160, lr=0.00032422, gnorm=0.23, clip=100, loss_scale=0.25, train_wall=7[2022-11-14 14:17:20,138][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 14:17:22,172][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.706 | ppl 3.26 | wps 166237 | wpb 10521.6 | bsz 178.1 | num_updates 9200 | best_loss 1.419                                    
[2022-11-14 14:17:22,173][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 9200 updates
[2022-11-14 14:17:22,173][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_9200.pt
[2022-11-14 14:17:26,631][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_9200.pt
[2022-11-14 14:17:29,602][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_9200.pt (epoch 2 @ 9200 updates, score 1.706) (writing took 7.428990243002772 seconds)
epoch 002:  71%|â–‹| 3925/5551 [21:01:24<8:41:06, 19.23s/it, loss=1.196, ppl=2.29, wps=27131.7, ups=0.05, wpb=523662, bsz=8834.2, num_updates=9360, lr=0.000322385, gnorm=0.166, clip=100, loss_scale=0.5, train_wall[2022-11-14 15:14:56,976][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 002:  71%|â–‹| 3947/5551 [21:08:28<8:36:25, 19.32s/it, loss=1.196, ppl=2.29, wps=27131.7, ups=0.05, wpb=523662, bsz=8834.2, num_updates=9360, lr=0.000322385, gnorm=0.166, clip=100, loss_scale=0.5, train_wall[2022-11-14 15:22:01,418][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 15:22:03,438][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.672 | ppl 3.19 | wps 167212 | wpb 10521.6 | bsz 178.1 | num_updates 9400 | best_loss 1.419                                    
[2022-11-14 15:22:03,439][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 9400 updates
[2022-11-14 15:22:03,440][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_9400.pt
[2022-11-14 15:22:07,887][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_9400.pt
[2022-11-14 15:22:10,804][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_9400.pt (epoch 2 @ 9400 updates, score 1.672) (writing took 7.365084365941584 seconds)
epoch 002:  75%|â–‹| 4147/5551 [22:12:53<7:31:28, 19.29s/it, loss=1.198, ppl=2.29, wps=27146.9, ups=0.05, wpb=523674, bsz=8708.2, num_updates=9560, lr=0.00032055, gnorm=0.152, clip=100, loss_scale=1, train_wall=75[2022-11-14 16:26:25,776][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 16:26:27,789][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.665 | ppl 3.17 | wps 168604 | wpb 10521.6 | bsz 178.1 | num_updates 9600 | best_loss 1.419                                    
[2022-11-14 16:26:27,790][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 9600 updates
[2022-11-14 16:26:27,790][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_9600.pt
[2022-11-14 16:26:32,307][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_9600.pt
[2022-11-14 16:26:35,275][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_9600.pt (epoch 2 @ 9600 updates, score 1.665) (writing took 7.485843524336815 seconds)
epoch 002:  76%|â–Š| 4195/5551 [22:28:27<7:17:02, 19.34s/it, loss=1.199, ppl=2.3, wps=26812.7, ups=0.05, wpb=522882, bsz=8599, num_updates=9640, lr=0.000319817, gnorm=0.184, clip=100, loss_scale=2, train_wall=755,[2022-11-14 16:42:00,127][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 002:  77%|â–Š| 4293/5551 [22:59:51<6:42:32, 19.20s/it, loss=1.192, ppl=2.29, wps=27138.3, ups=0.05, wpb=521529, bsz=8467.1, num_updates=9720, lr=0.000319083, gnorm=0.14, clip=100, loss_scale=1, train_wall=75[2022-11-14 17:13:24,413][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 002:  78%|â–Š| 4349/5551 [23:17:50<6:24:35, 19.20s/it, loss=1.193, ppl=2.29, wps=26489.4, ups=0.05, wpb=522191, bsz=8569.9, num_updates=9760, lr=0.000318716, gnorm=0.149, clip=100, loss_scale=1, train_wall=7[2022-11-14 17:31:23,091][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 17:31:25,111][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.683 | ppl 3.21 | wps 167713 | wpb 10521.6 | bsz 178.1 | num_updates 9800 | best_loss 1.419                                    
[2022-11-14 17:31:25,112][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 9800 updates
[2022-11-14 17:31:25,112][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_9800.pt
[2022-11-14 17:31:29,572][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_9800.pt
[2022-11-14 17:31:32,489][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_9800.pt (epoch 2 @ 9800 updates, score 1.683) (writing took 7.377161378972232 seconds)
epoch 002:  80%|â–Š| 4420/5551 [23:40:48<6:03:30, 19.28s/it, loss=1.192, ppl=2.28, wps=26795.7, ups=0.05, wpb=523364, bsz=8650.8, num_updates=9840, lr=0.000317982, gnorm=0.147, clip=100, loss_scale=2, train_wall=7[2022-11-14 17:54:20,947][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 002:  80%|â–Š| 4465/5551 [23:55:16<5:49:34, 19.31s/it, loss=1.192, ppl=2.28, wps=26498.7, ups=0.05, wpb=522598, bsz=8707.4, num_updates=9880, lr=0.000317615, gnorm=0.132, clip=100, loss_scale=1, train_wall=7[2022-11-14 18:08:48,748][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 002:  81%|â–Š| 4471/5551 [23:57:12<5:46:45, 19.26s/it, loss=1.192, ppl=2.28, wps=26498.7, ups=0.05, wpb=522598, bsz=8707.4, num_updates=9880, lr=0.000317615, gnorm=0.132, clip=100, loss_scale=1, train_wall=7[2022-11-14 18:10:44,402][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 002:  81%|â–Š| 4487/5551 [24:02:19<5:39:39, 19.15s/it, loss=1.192, ppl=2.29, wps=25825.4, ups=0.05, wpb=523119, bsz=8679.7, num_updates=9920, lr=0.000317248, gnorm=0.2, clip=100, loss_scale=0.25, train_wall=[2022-11-14 18:15:51,417][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 002:  81%|â–Š| 4488/5551 [24:02:38<5:38:43, 19.12s/it, loss=1.192, ppl=2.29, wps=25825.4, ups=0.05, wpb=523119, bsz=8679.7, num_updates=9920, lr=0.000317248, gnorm=0.2, clip=100, loss_scale=0.25, train_wall=[2022-11-14 18:16:10,805][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 002:  82%|â–Š| 4554/5551 [24:23:49<5:20:34, 19.29s/it, loss=1.209, ppl=2.31, wps=25868.8, ups=0.05, wpb=522650, bsz=8995.2, num_updates=9960, lr=0.000316881, gnorm=0.575, clip=100, loss_scale=0.0625, train_w[2022-11-14 18:37:22,381][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 18:37:24,428][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.555 | ppl 2.94 | wps 165503 | wpb 10521.6 | bsz 178.1 | num_updates 10000 | best_loss 1.419                                   
[2022-11-14 18:37:24,428][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 10000 updates
[2022-11-14 18:37:24,429][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10000.pt
[2022-11-14 18:37:28,893][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10000.pt
[2022-11-14 18:37:31,844][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_10000.pt (epoch 2 @ 10000 updates, score 1.555) (writing took 7.415754331275821 seconds)
epoch 002:  86%|â–Š| 4754/5551 [25:28:09<4:15:34, 19.24s/it, loss=1.186, ppl=2.28, wps=27073.4, ups=0.05, wpb=520185, bsz=8467.5, num_updates=10160, lr=0.000315046, gnorm=0.134, clip=100, loss_scale=0.25, train_wa[2022-11-14 19:41:41,662][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 19:41:43,692][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.664 | ppl 3.17 | wps 167125 | wpb 10521.6 | bsz 178.1 | num_updates 10200 | best_loss 1.419                                   
[2022-11-14 19:41:43,693][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 10200 updates
[2022-11-14 19:41:43,693][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10200.pt
[2022-11-14 19:41:48,160][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10200.pt
[2022-11-14 19:41:51,092][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_10200.pt (epoch 2 @ 10200 updates, score 1.664) (writing took 7.399552962742746 seconds)
epoch 002:  89%|â–‰| 4954/5551 [26:32:32<3:11:33, 19.25s/it, loss=1.184, ppl=2.27, wps=27091, ups=0.05, wpb=522306, bsz=8911.7, num_updates=10360, lr=0.000313211, gnorm=0.126, clip=100, loss_scale=2, train_wall=75[2022-11-14 20:46:04,881][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 20:46:06,908][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.553 | ppl 2.93 | wps 167143 | wpb 10521.6 | bsz 178.1 | num_updates 10400 | best_loss 1.419                                   
[2022-11-14 20:46:06,908][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 10400 updates
[2022-11-14 20:46:06,909][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10400.pt
[2022-11-14 20:46:11,380][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10400.pt
[2022-11-14 20:46:14,721][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_10400.pt (epoch 2 @ 10400 updates, score 1.553) (writing took 7.812723457813263 seconds)
epoch 002:  89%|â–‰| 4955/5551 [26:33:01<3:41:41, 22.32s/it, loss=1.184, ppl=2.27, wps=27045.3, ups=0.05, wpb=521724, bsz=8718, num_updates=10400, lr=0.000312844, gnorm=0.158, clip=100, loss_scale=2, train_wall=75[2022-11-14 20:46:34,607][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2022-11-14 20:46:34,608][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 20:46:36,628][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.551 | ppl 2.93 | wps 167938 | wpb 10521.6 | bsz 178.1 | num_updates 10400 | best_loss 1.419                                   
[2022-11-14 20:46:36,628][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 10400 updates
[2022-11-14 20:46:36,629][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10400.pt
[2022-11-14 20:46:43,251][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10400.pt
[2022-11-14 20:46:46,128][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_10400.pt (epoch 2 @ 10400 updates, score 1.551) (writing took 9.50010996311903 seconds)
epoch 002:  90%|â–‰| 5010/5551 [26:50:51<2:54:26, 19.35s/it, loss=1.183, ppl=2.27, wps=25745.3, ups=0.05, wpb=520877, bsz=8882.9, num_updates=10440, lr=0.000312477, gnorm=0.137, clip=100, loss_scale=1, train_wall=[2022-11-14 21:04:24,047][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 002:  93%|â–‰| 5156/5551 [27:37:47<2:06:51, 19.27s/it, loss=1.18, ppl=2.27, wps=27187, ups=0.05, wpb=524587, bsz=8953.7, num_updates=10560, lr=0.000311376, gnorm=0.133, clip=100, loss_scale=1, train_wall=756[2022-11-14 21:51:19,651][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 21:51:21,668][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.644 | ppl 3.13 | wps 167323 | wpb 10521.6 | bsz 178.1 | num_updates 10600 | best_loss 1.419                                   
[2022-11-14 21:51:21,669][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 10600 updates
[2022-11-14 21:51:21,669][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10600.pt
[2022-11-14 21:51:26,160][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10600.pt
[2022-11-14 21:51:29,219][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_10600.pt (epoch 2 @ 10600 updates, score 1.644) (writing took 7.550373123027384 seconds)
epoch 002:  95%|â–‰| 5257/5551 [28:10:25<1:34:28, 19.28s/it, loss=1.174, ppl=2.26, wps=27153.7, ups=0.05, wpb=523430, bsz=8782.8, num_updates=10680, lr=0.000310275, gnorm=0.129, clip=100, loss_scale=2, train_wall=[2022-11-14 22:23:57,730][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 002:  97%|â–‰| 5357/5551 [28:42:32<1:02:32, 19.35s/it, loss=1.175, ppl=2.26, wps=27127.7, ups=0.05, wpb=522899, bsz=8496.2, num_updates=10760, lr=0.000309541, gnorm=0.153, clip=100, loss_scale=1, train_wall=[2022-11-14 22:56:05,719][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 22:56:07,754][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.55 | ppl 2.93 | wps 166694 | wpb 10521.6 | bsz 178.1 | num_updates 10800 | best_loss 1.419                                    
[2022-11-14 22:56:07,755][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 10800 updates
[2022-11-14 22:56:07,755][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10800.pt
[2022-11-14 22:56:12,220][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_2_10800.pt
[2022-11-14 22:56:15,115][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_2_10800.pt (epoch 2 @ 10800 updates, score 1.55) (writing took 7.360417109914124 seconds)
epoch 002:  97%|â–‰| 5403/5551 [28:57:27<47:29, 19.25s/it, loss=1.173, ppl=2.26, wps=26860.7, ups=0.05, wpb=522792, bsz=8649.5, num_updates=10840, lr=0.000308807, gnorm=0.161, clip=100, loss_scale=2, train_wall=75[2022-11-14 23:11:00,111][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 002: 100%|â–‰| 5550/5551 [29:44:41<00:19, 19.25s/it, loss=1.171, ppl=2.25, wps=27138.4, ups=0.05, wpb=522553, bsz=8746.6, num_updates=10960, lr=0.000307706, gnorm=0.163, clip=100, loss_scale=2, train_wall=75[2022-11-14 23:58:11,145][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-14 23:58:13,156][valid][INFO] - epoch 002 | valid on 'valid' subset | loss 1.615 | ppl 3.06 | wps 167973 | wpb 10521.6 | bsz 178.1 | num_updates 10992 | best_loss 1.419                                   
[2022-11-14 23:58:13,157][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 10992 updates
[2022-11-14 23:58:13,157][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint2.pt
[2022-11-14 23:58:17,612][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint2.pt
[2022-11-14 23:58:20,477][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint2.pt (epoch 2 @ 10992 updates, score 1.615) (writing took 7.320487369783223 seconds)
[2022-11-14 23:58:20,478][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)                                                                                                                    
[2022-11-14 23:58:20,479][train][INFO] - epoch 002 | loss 1.239 | ppl 2.36 | wps 26855.9 | ups 0.05 | wpb 522614 | bsz 8746 | num_updates 10992 | lr 0.000307413 | gnorm 0.466 | clip 100 | loss_scale 2 | train_wall 104709 | gb_free 6.6 | wall 214467
[2022-11-14 23:58:20,996][fairseq.data.iterators][INFO] - grouped total_num_itrs = 5551
epoch 003:   0%|                                                                                                                                                                          | 0/5551 [00:00<?, ?it/s][2022-11-14 23:58:21,016][fairseq.trainer][INFO] - begin training epoch 3
[2022-11-14 23:58:21,016][fairseq_cli.train][INFO] - Start iterating over samples
epoch 003:   0%|â–                                                                                                                                                              | 7/5551 [02:15<29:40:41, 19.27s/it][2022-11-15 00:00:55,715][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 00:00:57,733][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.659 | ppl 3.16 | wps 166440 | wpb 10521.6 | bsz 178.1 | num_updates 11000 | best_loss 1.419                                   
[2022-11-15 00:00:57,734][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 11000 updates
[2022-11-15 00:00:57,734][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_11000.pt
[2022-11-15 00:01:02,283][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_11000.pt
[2022-11-15 00:01:05,345][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_11000.pt (epoch 3 @ 11000 updates, score 1.659) (writing took 7.611059287562966 seconds)
epoch 003:   2%| | 89/5551 [28:47<29:19:08, 19.32s/it, loss=1.168, ppl=2.25, wps=27119, ups=0.05, wpb=523703, bsz=8827.2, num_updates=11080, lr=0.000306606, gnorm=0.128, clip=100, loss_scale=4, train_wall=757, g[2022-11-15 00:27:27,704][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:   2%| | 116/5551 [37:29<29:09:33, 19.31s/it, loss=1.168, ppl=2.25, wps=27119, ups=0.05, wpb=523703, bsz=8827.2, num_updates=11080, lr=0.000306606, gnorm=0.128, clip=100, loss_scale=4, train_wall=757, [2022-11-15 00:36:09,427][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 003:   4%| | 209/5551 [1:07:24<28:35:58, 19.27s/it, loss=1.168, ppl=2.25, wps=27018.6, ups=0.05, wpb=522832, bsz=9021.1, num_updates=11160, lr=0.000305872, gnorm=0.131, clip=100, loss_scale=1, train_wall=7[2022-11-15 01:06:05,081][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 01:06:07,089][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.674 | ppl 3.19 | wps 168114 | wpb 10521.6 | bsz 178.1 | num_updates 11200 | best_loss 1.419                                   
[2022-11-15 01:06:07,090][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 11200 updates
[2022-11-15 01:06:07,090][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_11200.pt
[2022-11-15 01:06:11,579][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_11200.pt
[2022-11-15 01:06:14,533][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_11200.pt (epoch 3 @ 11200 updates, score 1.674) (writing took 7.442957712337375 seconds)
epoch 003:   6%| | 328/5551 [1:45:52<28:03:31, 19.34s/it, loss=1.165, ppl=2.24, wps=27074.5, ups=0.05, wpb=521846, bsz=8824.4, num_updates=11280, lr=0.000304771, gnorm=0.143, clip=97.5, loss_scale=4, train_wall=[2022-11-15 01:44:32,342][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:   7%| | 410/5551 [2:12:13<27:37:09, 19.34s/it, loss=1.161, ppl=2.24, wps=27132, ups=0.05, wpb=523296, bsz=8692.2, num_updates=11360, lr=0.000304037, gnorm=0.14, clip=100, loss_scale=2, train_wall=756,[2022-11-15 02:10:53,247][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 02:10:55,262][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.569 | ppl 2.97 | wps 167444 | wpb 10521.6 | bsz 178.1 | num_updates 11400 | best_loss 1.419                                   
[2022-11-15 02:10:55,262][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 11400 updates
[2022-11-15 02:10:55,263][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_11400.pt
[2022-11-15 02:10:59,687][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_11400.pt
[2022-11-15 02:11:02,591][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_11400.pt (epoch 3 @ 11400 updates, score 1.569) (writing took 7.329082886688411 seconds)
epoch 003:   8%| | 427/5551 [2:17:50<27:26:26, 19.28s/it, loss=1.161, ppl=2.24, wps=27121.2, ups=0.05, wpb=522726, bsz=8549.4, num_updates=11400, lr=0.00030367, gnorm=0.133, clip=100, loss_scale=2, train_wall=75[2022-11-15 02:16:30,601][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:   8%| | 468/5551 [2:31:00<27:11:48, 19.26s/it, loss=1.161, ppl=2.24, wps=26141.5, ups=0.05, wpb=522732, bsz=8747.9, num_updates=11440, lr=0.000303303, gnorm=0.134, clip=100, loss_scale=2, train_wall=7[2022-11-15 02:29:40,127][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 003:   9%| | 473/5551 [2:32:36<27:14:12, 19.31s/it, loss=1.161, ppl=2.24, wps=26141.5, ups=0.05, wpb=522732, bsz=8747.9, num_updates=11440, lr=0.000303303, gnorm=0.134, clip=100, loss_scale=2, train_wall=7[2022-11-15 02:31:16,152][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 003:   9%| | 474/5551 [2:32:55<27:07:18, 19.23s/it, loss=1.161, ppl=2.24, wps=26141.5, ups=0.05, wpb=522732, bsz=8747.9, num_updates=11440, lr=0.000303303, gnorm=0.134, clip=100, loss_scale=2, train_wall=7[2022-11-15 02:31:35,257][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 003:   9%| | 477/5551 [2:33:52<27:05:43, 19.22s/it, loss=1.161, ppl=2.24, wps=26141.5, ups=0.05, wpb=522732, bsz=8747.9, num_updates=11440, lr=0.000303303, gnorm=0.134, clip=100, loss_scale=2, train_wall=7[2022-11-15 02:32:32,867][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 003:  11%| | 615/5551 [3:18:09<26:30:39, 19.34s/it, loss=1.162, ppl=2.24, wps=27106.4, ups=0.05, wpb=521657, bsz=8665, num_updates=11560, lr=0.000302202, gnorm=0.138, clip=100, loss_scale=0.25, train_wall=[2022-11-15 03:16:50,152][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 03:16:52,185][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.51 | ppl 2.85 | wps 165827 | wpb 10521.6 | bsz 178.1 | num_updates 11600 | best_loss 1.419                                    
[2022-11-15 03:16:52,186][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 11600 updates
[2022-11-15 03:16:52,186][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_11600.pt
[2022-11-15 03:16:56,599][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_11600.pt
[2022-11-15 03:17:01,487][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_11600.pt (epoch 3 @ 11600 updates, score 1.51) (writing took 9.300919244997203 seconds)
epoch 003:  15%|â–| 815/5551 [4:22:37<25:18:57, 19.24s/it, loss=1.163, ppl=2.24, wps=27147.6, ups=0.05, wpb=522689, bsz=8837.6, num_updates=11760, lr=0.000300367, gnorm=0.13, clip=100, loss_scale=1, train_wall=75[2022-11-15 04:21:18,068][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 04:21:20,087][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.687 | ppl 3.22 | wps 167139 | wpb 10521.6 | bsz 178.1 | num_updates 11800 | best_loss 1.419                                   
[2022-11-15 04:21:20,088][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 11800 updates
[2022-11-15 04:21:20,088][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_11800.pt
[2022-11-15 04:21:24,543][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_11800.pt
[2022-11-15 04:21:27,506][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_11800.pt (epoch 3 @ 11800 updates, score 1.687) (writing took 7.418167056515813 seconds)
epoch 003:  16%|â–| 911/5551 [4:53:41<24:57:27, 19.36s/it, loss=1.156, ppl=2.23, wps=27063.8, ups=0.05, wpb=522698, bsz=8991.2, num_updates=11880, lr=0.000299266, gnorm=0.15, clip=100, loss_scale=2, train_wall=75[2022-11-15 04:52:22,019][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:  17%|â–| 958/5551 [5:08:47<24:34:44, 19.26s/it, loss=1.158, ppl=2.23, wps=26393.2, ups=0.05, wpb=521642, bsz=8743.2, num_updates=11920, lr=0.000298899, gnorm=0.141, clip=100, loss_scale=2, train_wall=7[2022-11-15 05:07:27,783][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 003:  17%|â–| 961/5551 [5:09:45<24:36:48, 19.30s/it, loss=1.158, ppl=2.23, wps=26393.2, ups=0.05, wpb=521642, bsz=8743.2, num_updates=11920, lr=0.000298899, gnorm=0.141, clip=100, loss_scale=2, train_wall=7[2022-11-15 05:08:25,589][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 003:  17%|â–| 970/5551 [5:12:38<24:29:33, 19.25s/it, loss=1.158, ppl=2.23, wps=26393.2, ups=0.05, wpb=521642, bsz=8743.2, num_updates=11920, lr=0.000298899, gnorm=0.141, clip=100, loss_scale=2, train_wall=7[2022-11-15 05:11:18,964][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 003:  18%|â–| 978/5551 [5:15:13<24:36:05, 19.37s/it, loss=1.158, ppl=2.23, wps=26393.2, ups=0.05, wpb=521642, bsz=8743.2, num_updates=11920, lr=0.000298899, gnorm=0.141, clip=100, loss_scale=2, train_wall=7[2022-11-15 05:13:53,685][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 003:  18%|â–| 1020/5551 [5:28:42<24:11:39, 19.22s/it, loss=1.157, ppl=2.23, wps=24672.8, ups=0.05, wpb=523631, bsz=8762, num_updates=11960, lr=0.000298532, gnorm=0.143, clip=100, loss_scale=0.125, train_wal[2022-11-15 05:27:22,068][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 05:27:24,084][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.635 | ppl 3.11 | wps 166741 | wpb 10521.6 | bsz 178.1 | num_updates 12000 | best_loss 1.419                                   
[2022-11-15 05:27:24,084][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 12000 updates
[2022-11-15 05:27:24,085][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_12000.pt
[2022-11-15 05:27:28,538][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_12000.pt
[2022-11-15 05:27:31,656][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_12000.pt (epoch 3 @ 12000 updates, score 1.635) (writing took 7.571930040605366 seconds)
epoch 003:  22%|â–| 1220/5551 [6:33:09<23:11:50, 19.28s/it, loss=1.154, ppl=2.23, wps=27074.8, ups=0.05, wpb=522293, bsz=8814, num_updates=12160, lr=0.000296697, gnorm=0.192, clip=100, loss_scale=0.5, train_wall=[2022-11-15 06:31:49,986][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 06:31:52,004][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.753 | ppl 3.37 | wps 168111 | wpb 10521.6 | bsz 178.1 | num_updates 12200 | best_loss 1.419                                   
[2022-11-15 06:31:52,005][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 12200 updates
[2022-11-15 06:31:52,005][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_12200.pt
[2022-11-15 06:31:56,442][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_12200.pt
[2022-11-15 06:32:02,065][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_12200.pt (epoch 3 @ 12200 updates, score 1.753) (writing took 10.060003367252648 seconds)
epoch 003:  25%|â–Ž| 1404/5551 [7:32:27<22:07:21, 19.20s/it, loss=1.153, ppl=2.22, wps=27013, ups=0.05, wpb=521789, bsz=8807.4, num_updates=12360, lr=0.000294862, gnorm=0.146, clip=100, loss_scale=2, train_wall=75[2022-11-15 07:31:07,971][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:  26%|â–Ž| 1421/5551 [7:37:55<22:04:55, 19.25s/it, loss=1.153, ppl=2.22, wps=27013, ups=0.05, wpb=521789, bsz=8807.4, num_updates=12360, lr=0.000294862, gnorm=0.146, clip=100, loss_scale=2, train_wall=75[2022-11-15 07:36:35,946][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 07:36:37,978][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.643 | ppl 3.12 | wps 166933 | wpb 10521.6 | bsz 178.1 | num_updates 12400 | best_loss 1.419                                   
[2022-11-15 07:36:37,979][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 12400 updates
[2022-11-15 07:36:37,979][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_12400.pt
[2022-11-15 07:36:42,401][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_12400.pt
[2022-11-15 07:36:46,976][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_12400.pt (epoch 3 @ 12400 updates, score 1.643) (writing took 8.997778818011284 seconds)
epoch 003:  26%|â–Ž| 1456/5551 [7:49:21<21:56:38, 19.29s/it, loss=1.152, ppl=2.22, wps=26467.3, ups=0.05, wpb=522835, bsz=8813.5, num_updates=12400, lr=0.000294495, gnorm=0.157, clip=100, loss_scale=2, train_wall=[2022-11-15 07:48:01,406][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 003:  27%|â–Ž| 1508/5551 [8:06:03<21:55:56, 19.53s/it, loss=1.153, ppl=2.22, wps=27099.3, ups=0.05, wpb=521935, bsz=8976.2, num_updates=12480, lr=0.000293761, gnorm=0.147, clip=100, loss_scale=1, train_wall=[2022-11-15 08:04:43,590][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 003:  29%|â–Ž| 1623/5551 [8:43:00<21:05:36, 19.33s/it, loss=1.149, ppl=2.22, wps=27157.7, ups=0.05, wpb=524171, bsz=8929.2, num_updates=12560, lr=0.000293028, gnorm=0.144, clip=100, loss_scale=0.5, train_wal[2022-11-15 08:41:40,389][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 08:41:42,416][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.572 | ppl 2.97 | wps 167487 | wpb 10521.6 | bsz 178.1 | num_updates 12600 | best_loss 1.419                                   
[2022-11-15 08:41:42,417][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 12600 updates
[2022-11-15 08:41:42,418][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_12600.pt
[2022-11-15 08:41:46,874][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_12600.pt
[2022-11-15 08:41:49,844][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_12600.pt (epoch 3 @ 12600 updates, score 1.572) (writing took 7.426722783595324 seconds)
epoch 003:  33%|â–Ž| 1823/5551 [9:47:26<20:03:33, 19.37s/it, loss=1.15, ppl=2.22, wps=27139.4, ups=0.05, wpb=522514, bsz=8648.9, num_updates=12760, lr=0.000291193, gnorm=0.122, clip=100, loss_scale=4, train_wall=7[2022-11-15 09:46:06,576][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 09:46:08,604][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.566 | ppl 2.96 | wps 165819 | wpb 10521.6 | bsz 178.1 | num_updates 12800 | best_loss 1.419                                   
[2022-11-15 09:46:08,604][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 12800 updates
[2022-11-15 09:46:08,605][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_12800.pt
[2022-11-15 09:46:13,059][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_12800.pt
[2022-11-15 09:46:16,950][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_12800.pt (epoch 3 @ 12800 updates, score 1.566) (writing took 8.345818267203867 seconds)
epoch 003:  33%|â–Ž| 1843/5551 [9:54:04<19:54:00, 19.32s/it, loss=1.151, ppl=2.22, wps=27085.7, ups=0.05, wpb=523200, bsz=8689.3, num_updates=12800, lr=0.000290826, gnorm=0.129, clip=100, loss_scale=4, train_wall=[2022-11-15 09:52:44,437][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:  33%|â–Ž| 1844/5551 [9:54:23<19:49:06, 19.25s/it, loss=1.151, ppl=2.22, wps=27085.7, ups=0.05, wpb=523200, bsz=8689.3, num_updates=12800, lr=0.000290826, gnorm=0.129, clip=100, loss_scale=4, train_wall=[2022-11-15 09:53:03,799][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 003:  36%|â–Ž| 2025/5551 [10:52:33<18:57:46, 19.36s/it, loss=1.146, ppl=2.21, wps=27107.8, ups=0.05, wpb=522301, bsz=8738.4, num_updates=12960, lr=0.000289358, gnorm=0.146, clip=100, loss_scale=2, train_wall[2022-11-15 10:51:14,369][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 10:51:16,376][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.616 | ppl 3.07 | wps 167789 | wpb 10521.6 | bsz 178.1 | num_updates 13000 | best_loss 1.419                                   
[2022-11-15 10:51:16,376][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 13000 updates
[2022-11-15 10:51:16,377][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_13000.pt
[2022-11-15 10:51:20,840][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_13000.pt
[2022-11-15 10:51:24,864][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_13000.pt (epoch 3 @ 13000 updates, score 1.616) (writing took 8.487811133265495 seconds)
epoch 003:  38%|â–| 2087/5551 [11:12:42<18:38:50, 19.38s/it, loss=1.144, ppl=2.21, wps=26656.1, ups=0.05, wpb=521915, bsz=8700.3, num_updates=13040, lr=0.000288624, gnorm=0.141, clip=100, loss_scale=4, train_wall[2022-11-15 11:11:22,490][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:  40%|â–| 2226/5551 [11:57:24<17:55:42, 19.41s/it, loss=1.144, ppl=2.21, wps=27079.7, ups=0.05, wpb=522026, bsz=8628.9, num_updates=13160, lr=0.000287523, gnorm=0.142, clip=100, loss_scale=4, train_wall[2022-11-15 11:56:04,635][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 11:56:06,636][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.65 | ppl 3.14 | wps 168116 | wpb 10521.6 | bsz 178.1 | num_updates 13200 | best_loss 1.419                                    
[2022-11-15 11:56:06,637][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 13200 updates
[2022-11-15 11:56:06,637][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_13200.pt
[2022-11-15 11:56:11,173][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_13200.pt
[2022-11-15 11:56:13,924][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_13200.pt (epoch 3 @ 13200 updates, score 1.65) (writing took 7.287141841836274 seconds)
epoch 003:  41%|â–| 2298/5551 [12:20:43<17:26:47, 19.31s/it, loss=1.144, ppl=2.21, wps=26770.3, ups=0.05, wpb=522906, bsz=8907.8, num_updates=13240, lr=0.000286789, gnorm=0.143, clip=100, loss_scale=8, train_wall[2022-11-15 12:19:23,565][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 003:  43%|â–| 2389/5551 [12:50:00<16:59:04, 19.34s/it, loss=1.142, ppl=2.21, wps=27167.9, ups=0.05, wpb=524222, bsz=8959.2, num_updates=13360, lr=0.000285688, gnorm=0.135, clip=100, loss_scale=8, train_wall[2022-11-15 12:48:40,588][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 003:  44%|â–| 2428/5551 [13:02:33<16:40:47, 19.23s/it, loss=1.142, ppl=2.21, wps=27167.9, ups=0.05, wpb=524222, bsz=8959.2, num_updates=13360, lr=0.000285688, gnorm=0.135, clip=100, loss_scale=8, train_wall[2022-11-15 13:01:13,677][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 13:01:15,703][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.746 | ppl 3.35 | wps 167117 | wpb 10521.6 | bsz 178.1 | num_updates 13400 | best_loss 1.419                                   
[2022-11-15 13:01:15,704][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 13400 updates
[2022-11-15 13:01:15,705][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_13400.pt
[2022-11-15 13:01:20,280][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_13400.pt
[2022-11-15 13:01:23,002][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_13400.pt (epoch 3 @ 13400 updates, score 1.746) (writing took 7.29750235658139 seconds)
epoch 003:  45%|â–| 2482/5551 [13:20:04<16:27:46, 19.31s/it, loss=1.139, ppl=2.2, wps=26756.1, ups=0.05, wpb=522718, bsz=8616.2, num_updates=13440, lr=0.000284954, gnorm=0.14, clip=100, loss_scale=4, train_wall=7[2022-11-15 13:18:44,784][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 003:  45%|â–| 2506/5551 [13:27:48<16:24:26, 19.40s/it, loss=1.139, ppl=2.2, wps=26756.1, ups=0.05, wpb=522718, bsz=8616.2, num_updates=13440, lr=0.000284954, gnorm=0.14, clip=100, loss_scale=4, train_wall=7[2022-11-15 13:26:28,604][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:  47%|â–| 2630/5551 [14:07:42<15:43:43, 19.38s/it, loss=1.143, ppl=2.21, wps=27102.1, ups=0.05, wpb=522586, bsz=8775.2, num_updates=13560, lr=0.000283853, gnorm=0.122, clip=100, loss_scale=2, train_wall[2022-11-15 14:06:22,230][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 14:06:24,256][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.605 | ppl 3.04 | wps 166390 | wpb 10521.6 | bsz 178.1 | num_updates 13600 | best_loss 1.419                                   
[2022-11-15 14:06:24,257][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 13600 updates
[2022-11-15 14:06:24,257][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_13600.pt
[2022-11-15 14:06:28,988][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_13600.pt
[2022-11-15 14:06:31,909][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_13600.pt (epoch 3 @ 13600 updates, score 1.605) (writing took 7.652764373458922 seconds)
epoch 003:  50%|â–| 2764/5551 [14:50:53<14:56:51, 19.31s/it, loss=1.14, ppl=2.2, wps=27140, ups=0.05, wpb=523531, bsz=8894, num_updates=13720, lr=0.000282385, gnorm=0.127, clip=100, loss_scale=8, train_wall=757, [2022-11-15 14:49:33,439][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 003:  50%|â–Œ| 2778/5551 [14:55:23<14:52:04, 19.30s/it, loss=1.14, ppl=2.2, wps=27140, ups=0.05, wpb=523531, bsz=8894, num_updates=13720, lr=0.000282385, gnorm=0.127, clip=100, loss_scale=8, train_wall=757, [2022-11-15 14:54:03,382][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 003:  51%|â–Œ| 2832/5551 [15:12:43<14:34:51, 19.31s/it, loss=1.141, ppl=2.21, wps=25847, ups=0.05, wpb=524023, bsz=8915, num_updates=13760, lr=0.000282018, gnorm=0.145, clip=100, loss_scale=4, train_wall=794[2022-11-15 15:11:23,366][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 15:11:25,394][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.668 | ppl 3.18 | wps 166715 | wpb 10521.6 | bsz 178.1 | num_updates 13800 | best_loss 1.419                                   
[2022-11-15 15:11:25,395][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 13800 updates
[2022-11-15 15:11:25,395][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_13800.pt
[2022-11-15 15:11:29,932][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_13800.pt
[2022-11-15 15:11:34,123][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_13800.pt (epoch 3 @ 13800 updates, score 1.668) (writing took 8.727842002175748 seconds)
epoch 003:  52%|â–Œ| 2866/5551 [15:23:48<14:24:32, 19.32s/it, loss=1.136, ppl=2.2, wps=27091.6, ups=0.05, wpb=521372, bsz=8626.5, num_updates=13800, lr=0.000281651, gnorm=0.14, clip=100, loss_scale=4, train_wall=7[2022-11-15 15:22:28,921][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 003:  53%|â–Œ| 2955/5551 [15:52:22<13:52:51, 19.25s/it, loss=1.137, ppl=2.2, wps=27133.2, ups=0.05, wpb=522769, bsz=8822.1, num_updates=13920, lr=0.00028055, gnorm=0.127, clip=97.5, loss_scale=8, train_wall=[2022-11-15 15:51:03,190][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 003:  55%|â–Œ| 3034/5551 [16:17:49<13:29:12, 19.29s/it, loss=1.139, ppl=2.2, wps=26425.1, ups=0.05, wpb=523359, bsz=8904.5, num_updates=13960, lr=0.000280183, gnorm=0.138, clip=97.5, loss_scale=4, train_wall[2022-11-15 16:16:29,758][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 16:16:31,795][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.741 | ppl 3.34 | wps 167137 | wpb 10521.6 | bsz 178.1 | num_updates 14000 | best_loss 1.419                                   
[2022-11-15 16:16:31,796][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 14000 updates
[2022-11-15 16:16:31,796][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_14000.pt
[2022-11-15 16:16:36,379][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_14000.pt
[2022-11-15 16:16:39,378][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_14000.pt (epoch 3 @ 14000 updates, score 1.741) (writing took 7.582032276317477 seconds)
epoch 003:  55%|â–Œ| 3044/5551 [16:21:11<13:30:00, 19.39s/it, loss=1.136, ppl=2.2, wps=27081.9, ups=0.05, wpb=523266, bsz=9022.7, num_updates=14000, lr=0.000279817, gnorm=0.132, clip=100, loss_scale=4, train_wall=[2022-11-15 16:19:51,897][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 003:  57%|â–Œ| 3173/5551 [17:02:38<12:45:15, 19.31s/it, loss=1.137, ppl=2.2, wps=27134.2, ups=0.05, wpb=523087, bsz=8658.4, num_updates=14120, lr=0.000278716, gnorm=0.119, clip=100, loss_scale=8, train_wall=[2022-11-15 17:01:18,895][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 003:  58%|â–Œ| 3236/5551 [17:22:55<12:24:21, 19.29s/it, loss=1.137, ppl=2.2, wps=26308.7, ups=0.05, wpb=520024, bsz=8589.9, num_updates=14160, lr=0.000278349, gnorm=0.129, clip=100, loss_scale=4, train_wall=[2022-11-15 17:21:35,371][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 17:21:37,390][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.54 | ppl 2.91 | wps 166347 | wpb 10521.6 | bsz 178.1 | num_updates 14200 | best_loss 1.419                                    
[2022-11-15 17:21:37,390][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 14200 updates
[2022-11-15 17:21:37,391][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_14200.pt
[2022-11-15 17:21:41,845][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_14200.pt
[2022-11-15 17:21:45,018][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_14200.pt (epoch 3 @ 14200 updates, score 1.54) (writing took 7.6279309038072824 seconds)
epoch 003:  59%|â–Œ| 3290/5551 [17:40:26<12:08:10, 19.32s/it, loss=1.135, ppl=2.2, wps=26790.7, ups=0.05, wpb=523081, bsz=8819, num_updates=14240, lr=0.000277615, gnorm=0.124, clip=100, loss_scale=8, train_wall=75[2022-11-15 17:39:06,956][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 003:  61%|â–Œ| 3360/5551 [18:02:55<11:41:23, 19.21s/it, loss=1.132, ppl=2.19, wps=27078.6, ups=0.05, wpb=522640, bsz=8745.8, num_updates=14320, lr=0.000276881, gnorm=0.148, clip=100, loss_scale=4, train_wall[2022-11-15 18:01:36,264][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:  62%|â–Œ| 3438/5551 [18:28:02<11:22:04, 19.37s/it, loss=1.133, ppl=2.19, wps=26413.6, ups=0.05, wpb=522532, bsz=8793.1, num_updates=14360, lr=0.000276514, gnorm=0.123, clip=97.5, loss_scale=2, train_wal[2022-11-15 18:26:42,753][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 18:26:44,778][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.737 | ppl 3.33 | wps 167313 | wpb 10521.6 | bsz 178.1 | num_updates 14400 | best_loss 1.419                                   
[2022-11-15 18:26:44,778][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 14400 updates
[2022-11-15 18:26:44,779][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_14400.pt
[2022-11-15 18:26:49,264][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_14400.pt
[2022-11-15 18:26:52,114][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_14400.pt (epoch 3 @ 14400 updates, score 1.737) (writing took 7.335139960050583 seconds)
epoch 003:  64%|â–‹| 3532/5551 [18:58:26<10:47:43, 19.25s/it, loss=1.13, ppl=2.19, wps=27065.1, ups=0.05, wpb=522463, bsz=8866.1, num_updates=14480, lr=0.000275413, gnorm=0.123, clip=100, loss_scale=4, train_wall=[2022-11-15 18:57:06,343][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 003:  64%|â–‹| 3549/5551 [19:03:55<10:46:24, 19.37s/it, loss=1.13, ppl=2.19, wps=27065.1, ups=0.05, wpb=522463, bsz=8866.1, num_updates=14480, lr=0.000275413, gnorm=0.123, clip=100, loss_scale=4, train_wall=[2022-11-15 19:02:35,262][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:  66%|â–‹| 3640/5551 [19:33:10<10:16:04, 19.34s/it, loss=1.132, ppl=2.19, wps=27047.5, ups=0.05, wpb=522189, bsz=8811.8, num_updates=14560, lr=0.000274679, gnorm=0.124, clip=97.5, loss_scale=2, train_wal[2022-11-15 19:31:50,872][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 19:31:52,903][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.665 | ppl 3.17 | wps 166014 | wpb 10521.6 | bsz 178.1 | num_updates 14600 | best_loss 1.419                                   
[2022-11-15 19:31:52,904][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 14600 updates
[2022-11-15 19:31:52,904][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_14600.pt
[2022-11-15 19:31:57,361][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_14600.pt
[2022-11-15 19:32:03,835][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_14600.pt (epoch 3 @ 14600 updates, score 1.665) (writing took 10.93045474588871 seconds)
epoch 003:  66%|â–‹| 3648/5551 [19:35:57<10:19:35, 19.54s/it, loss=1.132, ppl=2.19, wps=27131.8, ups=0.05, wpb=523326, bsz=8499.1, num_updates=14600, lr=0.000274312, gnorm=0.125, clip=97.5, loss_scale=4, train_wal[2022-11-15 19:34:37,410][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:  66%|â–‹| 3651/5551 [19:36:55<10:12:44, 19.35s/it, loss=1.132, ppl=2.19, wps=27131.8, ups=0.05, wpb=523326, bsz=8499.1, num_updates=14600, lr=0.000274312, gnorm=0.125, clip=97.5, loss_scale=4, train_wal[2022-11-15 19:35:34,984][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 003:  69%|â–‹| 3842/5551 [20:38:18<9:09:19, 19.29s/it, loss=1.129, ppl=2.19, wps=27194.7, ups=0.05, wpb=522988, bsz=8661, num_updates=14760, lr=0.000272844, gnorm=0.121, clip=95, loss_scale=2, train_wall=754[2022-11-15 20:36:58,818][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 20:37:00,848][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.529 | ppl 2.89 | wps 166542 | wpb 10521.6 | bsz 178.1 | num_updates 14800 | best_loss 1.419                                   
[2022-11-15 20:37:00,849][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 14800 updates
[2022-11-15 20:37:00,849][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_14800.pt
[2022-11-15 20:37:05,325][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_14800.pt
[2022-11-15 20:37:08,396][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_14800.pt (epoch 3 @ 14800 updates, score 1.529) (writing took 7.54724099021405 seconds)
epoch 003:  69%|â–‹| 3851/5551 [20:41:21<9:13:24, 19.53s/it, loss=1.131, ppl=2.19, wps=27084.8, ups=0.05, wpb=521501, bsz=9015.8, num_updates=14800, lr=0.000272477, gnorm=0.127, clip=100, loss_scale=4, train_wall=[2022-11-15 20:40:02,345][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:  72%|â–‹| 3999/5551 [21:28:58<8:19:46, 19.32s/it, loss=1.127, ppl=2.18, wps=27113, ups=0.05, wpb=523256, bsz=8609, num_updates=14920, lr=0.000271376, gnorm=0.154, clip=100, loss_scale=4, train_wall=757,[2022-11-15 21:27:38,188][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 003:  72%|â–‹| 4014/5551 [21:33:45<8:12:30, 19.23s/it, loss=1.126, ppl=2.18, wps=26422.8, ups=0.05, wpb=522731, bsz=8560.3, num_updates=14960, lr=0.000271009, gnorm=0.147, clip=100, loss_scale=2, train_wall=[2022-11-15 21:32:26,266][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 003:  72%|â–‹| 4016/5551 [21:34:24<8:12:35, 19.25s/it, loss=1.126, ppl=2.18, wps=26422.8, ups=0.05, wpb=522731, bsz=8560.3, num_updates=14960, lr=0.000271009, gnorm=0.147, clip=100, loss_scale=2, train_wall=[2022-11-15 21:33:04,853][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 003:  73%|â–‹| 4038/5551 [21:41:28<8:06:38, 19.30s/it, loss=1.126, ppl=2.18, wps=26422.8, ups=0.05, wpb=522731, bsz=8560.3, num_updates=14960, lr=0.000271009, gnorm=0.147, clip=100, loss_scale=2, train_wall=[2022-11-15 21:40:08,565][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 003:  73%|â–‹| 4040/5551 [21:42:06<8:02:12, 19.15s/it, loss=1.126, ppl=2.18, wps=26422.8, ups=0.05, wpb=522731, bsz=8560.3, num_updates=14960, lr=0.000271009, gnorm=0.147, clip=100, loss_scale=2, train_wall=[2022-11-15 21:40:46,419][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 003:  73%|â–‹| 4041/5551 [21:42:25<8:00:04, 19.08s/it, loss=1.126, ppl=2.18, wps=26422.8, ups=0.05, wpb=522731, bsz=8560.3, num_updates=14960, lr=0.000271009, gnorm=0.147, clip=100, loss_scale=2, train_wall=[2022-11-15 21:41:05,480][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 003:  73%|â–‹| 4045/5551 [21:43:42<8:00:44, 19.15s/it, loss=1.126, ppl=2.18, wps=26422.8, ups=0.05, wpb=522731, bsz=8560.3, num_updates=14960, lr=0.000271009, gnorm=0.147, clip=100, loss_scale=2, train_wall=[2022-11-15 21:42:22,362][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 003:  73%|â–‹| 4047/5551 [21:44:20<8:01:19, 19.20s/it, loss=1.126, ppl=2.18, wps=26422.8, ups=0.05, wpb=522731, bsz=8560.3, num_updates=14960, lr=0.000271009, gnorm=0.147, clip=100, loss_scale=2, train_wall=[2022-11-15 21:43:00,874][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
epoch 003:  73%|â–‹| 4051/5551 [21:45:37<7:58:43, 19.15s/it, loss=1.126, ppl=2.18, wps=26422.8, ups=0.05, wpb=522731, bsz=8560.3, num_updates=14960, lr=0.000271009, gnorm=0.147, clip=100, loss_scale=2, train_wall=[2022-11-15 21:44:17,086][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 21:44:19,114][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.617 | ppl 3.07 | wps 166609 | wpb 10521.6 | bsz 178.1 | num_updates 15000 | best_loss 1.419                                   
[2022-11-15 21:44:19,115][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 15000 updates
[2022-11-15 21:44:19,115][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15000.pt
[2022-11-15 21:44:23,587][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15000.pt
[2022-11-15 21:44:28,087][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_15000.pt (epoch 3 @ 15000 updates, score 1.617) (writing took 8.972378006204963 seconds)
epoch 003:  77%|â–Š| 4251/5551 [22:50:00<7:00:04, 19.39s/it, loss=1.131, ppl=2.19, wps=27060.1, ups=0.05, wpb=520839, bsz=8470.8, num_updates=15160, lr=0.000269174, gnorm=0.163, clip=100, loss_scale=0.0312, train_[2022-11-15 22:48:40,436][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 22:48:42,458][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.568 | ppl 2.97 | wps 167739 | wpb 10521.6 | bsz 178.1 | num_updates 15200 | best_loss 1.419                                   
[2022-11-15 22:48:42,458][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 15200 updates
[2022-11-15 22:48:42,459][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15200.pt
[2022-11-15 22:48:46,930][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15200.pt
[2022-11-15 22:48:49,883][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_15200.pt (epoch 3 @ 15200 updates, score 1.568) (writing took 7.424506231211126 seconds)
epoch 003:  80%|â–Š| 4451/5551 [23:54:20<5:52:56, 19.25s/it, loss=1.125, ppl=2.18, wps=27176.7, ups=0.05, wpb=523106, bsz=8736.2, num_updates=15360, lr=0.000267339, gnorm=0.133, clip=97.5, loss_scale=0.25, train_w[2022-11-15 23:53:00,778][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 23:53:02,815][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.693 | ppl 3.23 | wps 167076 | wpb 10521.6 | bsz 178.1 | num_updates 15400 | best_loss 1.419                                   
[2022-11-15 23:53:02,816][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 15400 updates
[2022-11-15 23:53:02,816][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15400.pt
[2022-11-15 23:53:07,281][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15400.pt
[2022-11-15 23:53:11,660][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_15400.pt (epoch 3 @ 15400 updates, score 1.693) (writing took 8.843920038081706 seconds)
epoch 003:  80%|â–Š| 4452/5551 [23:54:51<6:57:00, 22.77s/it, loss=1.132, ppl=2.19, wps=27171.5, ups=0.05, wpb=523886, bsz=8778.5, num_updates=15400, lr=0.000266972, gnorm=0.214, clip=100, loss_scale=0.25, train_wa[2022-11-15 23:53:31,118][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2022-11-15 23:53:31,119][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-15 23:53:33,135][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.697 | ppl 3.24 | wps 168380 | wpb 10521.6 | bsz 178.1 | num_updates 15400 | best_loss 1.419                                   
[2022-11-15 23:53:33,136][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 15400 updates
[2022-11-15 23:53:33,136][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15400.pt
[2022-11-15 23:53:38,188][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15400.pt
[2022-11-15 23:53:42,539][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_15400.pt (epoch 3 @ 15400 updates, score 1.697) (writing took 9.40290634892881 seconds)
epoch 003:  80%|â–Š| 4454/5551 [23:55:40<7:03:47, 23.18s/it, loss=1.132, ppl=2.19, wps=27171.5, ups=0.05, wpb=523886, bsz=8778.5, num_updates=15400, lr=0.000266972, gnorm=0.214, clip=100, loss_scale=0.25, train_wa[2022-11-15 23:54:20,527][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 003:  80%|â–Š| 4455/5551 [23:55:59<6:41:54, 22.00s/it, loss=1.132, ppl=2.19, wps=27171.5, ups=0.05, wpb=523886, bsz=8778.5, num_updates=15400, lr=0.000266972, gnorm=0.214, clip=100, loss_scale=0.25, train_wa[2022-11-15 23:54:39,673][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 003:  82%|â–Š| 4525/5551 [24:18:28<5:29:07, 19.25s/it, loss=1.193, ppl=2.29, wps=24510.4, ups=0.05, wpb=521495, bsz=8687.2, num_updates=15440, lr=0.000266606, gnorm=0.952, clip=100, loss_scale=0.0312, train_[2022-11-16 00:17:08,567][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
epoch 003:  84%|â–Š| 4655/5551 [25:00:12<4:46:29, 19.18s/it, loss=1.125, ppl=2.18, wps=27175.2, ups=0.05, wpb=523039, bsz=8764.9, num_updates=15560, lr=0.000265505, gnorm=0.151, clip=100, loss_scale=0.0312, train_[2022-11-16 00:58:52,517][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 00:58:54,553][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.503 | ppl 2.84 | wps 166105 | wpb 10521.6 | bsz 178.1 | num_updates 15600 | best_loss 1.419                                   
[2022-11-16 00:58:54,554][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 15600 updates
[2022-11-16 00:58:54,554][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15600.pt
[2022-11-16 00:58:59,034][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15600.pt
[2022-11-16 00:59:02,071][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_15600.pt (epoch 3 @ 15600 updates, score 1.503) (writing took 7.516987239941955 seconds)
epoch 003:  87%|â–Š| 4855/5551 [26:04:30<3:43:22, 19.26s/it, loss=1.124, ppl=2.18, wps=27169.1, ups=0.05, wpb=522511, bsz=8613.1, num_updates=15760, lr=0.00026367, gnorm=0.139, clip=100, loss_scale=0.125, train_wa[2022-11-16 02:03:10,781][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 02:03:12,792][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.549 | ppl 2.93 | wps 167702 | wpb 10521.6 | bsz 178.1 | num_updates 15800 | best_loss 1.419                                   
[2022-11-16 02:03:12,793][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 15800 updates
[2022-11-16 02:03:12,793][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15800.pt
[2022-11-16 02:03:18,340][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_15800.pt
[2022-11-16 02:03:21,321][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_15800.pt (epoch 3 @ 15800 updates, score 1.549) (writing took 8.528040810488164 seconds)
epoch 003:  89%|â–‰| 4941/5551 [26:32:15<3:16:01, 19.28s/it, loss=1.121, ppl=2.18, wps=27110.9, ups=0.05, wpb=522610, bsz=8704.5, num_updates=15880, lr=0.000262569, gnorm=0.113, clip=95, loss_scale=0.25, train_wal[2022-11-16 02:30:56,200][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 003:  91%|â–‰| 5056/5551 [27:09:08<2:38:10, 19.17s/it, loss=1.12, ppl=2.17, wps=27075.2, ups=0.05, wpb=521534, bsz=8635.5, num_updates=15960, lr=0.000261835, gnorm=0.136, clip=100, loss_scale=0.125, train_wa[2022-11-16 03:07:49,495][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 03:07:51,503][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.615 | ppl 3.06 | wps 168498 | wpb 10521.6 | bsz 178.1 | num_updates 16000 | best_loss 1.419                                   
[2022-11-16 03:07:51,504][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 16000 updates
[2022-11-16 03:07:51,504][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_16000.pt
[2022-11-16 03:07:55,959][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_16000.pt
[2022-11-16 03:07:58,860][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_16000.pt (epoch 3 @ 16000 updates, score 1.615) (writing took 7.355773735791445 seconds)
epoch 003:  95%|â–‰| 5256/5551 [28:13:31<1:35:04, 19.34s/it, loss=1.119, ppl=2.17, wps=27207.1, ups=0.05, wpb=523914, bsz=8656.9, num_updates=16160, lr=0.00026, gnorm=0.136, clip=100, loss_scale=1, train_wall=756,[2022-11-16 04:12:11,967][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 04:12:13,987][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.589 | ppl 3.01 | wps 167689 | wpb 10521.6 | bsz 178.1 | num_updates 16200 | best_loss 1.419                                   
[2022-11-16 04:12:13,988][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 16200 updates
[2022-11-16 04:12:13,989][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_16200.pt
[2022-11-16 04:12:18,458][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_16200.pt
[2022-11-16 04:12:22,136][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_16200.pt (epoch 3 @ 16200 updates, score 1.589) (writing took 8.14810471702367 seconds)
epoch 003:  96%|â–‰| 5316/5551 [28:32:57<1:15:18, 19.23s/it, loss=1.118, ppl=2.17, wps=26787.7, ups=0.05, wpb=522673, bsz=8673.5, num_updates=16240, lr=0.000259266, gnorm=0.139, clip=97.5, loss_scale=2, train_wall[2022-11-16 04:31:37,459][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 003:  98%|â–‰| 5457/5551 [29:18:12<30:18, 19.35s/it, loss=1.117, ppl=2.17, wps=27129.4, ups=0.05, wpb=522522, bsz=8656, num_updates=16360, lr=0.000258165, gnorm=0.134, clip=95, loss_scale=2, train_wall=755, [2022-11-16 05:16:52,608][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 05:16:54,621][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.614 | ppl 3.06 | wps 167214 | wpb 10521.6 | bsz 178.1 | num_updates 16400 | best_loss 1.419                                   
[2022-11-16 05:16:54,622][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 16400 updates
[2022-11-16 05:16:54,622][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_16400.pt
[2022-11-16 05:16:59,217][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_3_16400.pt
[2022-11-16 05:17:04,614][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_16400.pt (epoch 3 @ 16400 updates, score 1.614) (writing took 9.992300612851977 seconds)
epoch 003: 100%|â–‰| 5550/5551 [29:48:19<00:19, 19.39s/it, loss=1.118, ppl=2.17, wps=27100.8, ups=0.05, wpb=523218, bsz=8914.2, num_updates=16480, lr=0.000257064, gnorm=0.133, clip=100, loss_scale=4, train_wall=75[2022-11-16 05:46:56,527][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 05:46:58,554][valid][INFO] - epoch 003 | valid on 'valid' subset | loss 1.678 | ppl 3.2 | wps 166997 | wpb 10521.6 | bsz 178.1 | num_updates 16493 | best_loss 1.419                                    
[2022-11-16 05:46:58,554][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 16493 updates
[2022-11-16 05:46:58,555][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint3.pt
[2022-11-16 05:47:03,012][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint3.pt
[2022-11-16 05:47:05,961][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint3.pt (epoch 3 @ 16493 updates, score 1.678) (writing took 7.406166194938123 seconds)
[2022-11-16 05:47:05,962][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)                                                                                                                    
[2022-11-16 05:47:05,963][train][INFO] - epoch 003 | loss 1.141 | ppl 2.21 | wps 26787.4 | ups 0.05 | wpb 522627 | bsz 8747.5 | num_updates 16493 | lr 0.000256945 | gnorm 0.152 | clip 99.5 | loss_scale 4 | train_wall 104909 | gb_free 6.7 | wall 321792
[2022-11-16 05:47:06,473][fairseq.data.iterators][INFO] - grouped total_num_itrs = 5551
epoch 004:   0%|                                                                                                                                                                          | 0/5551 [00:00<?, ?it/s][2022-11-16 05:47:06,497][fairseq.trainer][INFO] - begin training epoch 4
[2022-11-16 05:47:06,498][fairseq_cli.train][INFO] - Start iterating over samples
epoch 004:   0%|â–‹                                                                                                                                                             | 24/5551 [07:41<29:21:39, 19.12s/it][2022-11-16 05:55:06,996][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 004:   1%| | 39/5551 [12:31<29:35:58, 19.33s/it, loss=1.114, ppl=2.17, wps=25701.1, ups=0.05, wpb=512099, bsz=8447.5, num_updates=16520, lr=0.000256697, gnorm=0.136, clip=100, loss_scale=4, train_wall=774,[2022-11-16 05:59:56,735][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:   2%| | 108/5551 [34:44<29:20:28, 19.41s/it, loss=1.115, ppl=2.17, wps=26464.8, ups=0.05, wpb=523622, bsz=8877.5, num_updates=16560, lr=0.00025633, gnorm=0.135, clip=100, loss_scale=2, train_wall=775,[2022-11-16 06:22:09,643][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 06:22:11,659][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.663 | ppl 3.17 | wps 167325 | wpb 10521.6 | bsz 178.1 | num_updates 16600 | best_loss 1.419                                   
[2022-11-16 06:22:11,659][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 16600 updates
[2022-11-16 06:22:11,660][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_16600.pt
[2022-11-16 06:22:16,229][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_16600.pt
[2022-11-16 06:22:20,263][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_16600.pt (epoch 4 @ 16600 updates, score 1.663) (writing took 8.60390037856996 seconds)
epoch 004:   4%| | 211/5551 [1:08:01<28:51:00, 19.45s/it, loss=1.113, ppl=2.16, wps=27133.9, ups=0.05, wpb=524167, bsz=8964.2, num_updates=16680, lr=0.000255229, gnorm=0.136, clip=97.5, loss_scale=4, train_wall=[2022-11-16 06:55:27,280][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 004:   4%| | 212/5551 [1:08:20<28:49:17, 19.43s/it, loss=1.113, ppl=2.16, wps=27133.9, ups=0.05, wpb=524167, bsz=8964.2, num_updates=16680, lr=0.000255229, gnorm=0.136, clip=97.5, loss_scale=4, train_wall=[2022-11-16 06:55:46,527][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:   4%| | 225/5551 [1:12:31<28:33:03, 19.30s/it, loss=1.113, ppl=2.16, wps=27133.9, ups=0.05, wpb=524167, bsz=8964.2, num_updates=16680, lr=0.000255229, gnorm=0.136, clip=97.5, loss_scale=4, train_wall=[2022-11-16 06:59:57,398][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:   6%| | 311/5551 [1:40:06<28:04:21, 19.29s/it, loss=1.112, ppl=2.16, wps=27108.5, ups=0.05, wpb=522092, bsz=8790.1, num_updates=16760, lr=0.000254495, gnorm=0.14, clip=100, loss_scale=1, train_wall=75[2022-11-16 07:27:31,992][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 07:27:34,010][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.681 | ppl 3.21 | wps 166653 | wpb 10521.6 | bsz 178.1 | num_updates 16800 | best_loss 1.419                                   
[2022-11-16 07:27:34,011][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 16800 updates
[2022-11-16 07:27:34,012][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_16800.pt
[2022-11-16 07:27:38,509][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_16800.pt
[2022-11-16 07:27:42,524][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_16800.pt (epoch 4 @ 16800 updates, score 1.681) (writing took 8.512932329438627 seconds)
epoch 004:   9%| | 511/5551 [2:44:37<27:01:50, 19.31s/it, loss=1.111, ppl=2.16, wps=27136.8, ups=0.05, wpb=523423, bsz=8864, num_updates=16960, lr=0.000252661, gnorm=0.138, clip=100, loss_scale=4, train_wall=756[2022-11-16 08:32:03,100][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 08:32:05,105][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.72 | ppl 3.29 | wps 167624 | wpb 10521.6 | bsz 178.1 | num_updates 17000 | best_loss 1.419                                    
[2022-11-16 08:32:05,106][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 17000 updates
[2022-11-16 08:32:05,106][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_17000.pt
[2022-11-16 08:32:09,591][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_17000.pt
[2022-11-16 08:32:12,633][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_17000.pt (epoch 4 @ 17000 updates, score 1.72) (writing took 7.526819351129234 seconds)
epoch 004:   9%| | 513/5551 [2:45:25<29:46:05, 21.27s/it, loss=1.112, ppl=2.16, wps=27100.5, ups=0.05, wpb=523291, bsz=8848.2, num_updates=17000, lr=0.000252294, gnorm=0.121, clip=95, loss_scale=8, train_wall=75[2022-11-16 08:32:51,369][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 004:   9%| | 515/5551 [2:46:04<28:25:43, 20.32s/it, loss=1.112, ppl=2.16, wps=27100.5, ups=0.05, wpb=523291, bsz=8848.2, num_updates=17000, lr=0.000252294, gnorm=0.121, clip=95, loss_scale=8, train_wall=75[2022-11-16 08:33:29,930][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:   9%| | 516/5551 [2:46:23<27:55:19, 19.96s/it, loss=1.112, ppl=2.16, wps=27100.5, ups=0.05, wpb=523291, bsz=8848.2, num_updates=17000, lr=0.000252294, gnorm=0.121, clip=95, loss_scale=8, train_wall=75[2022-11-16 08:33:48,877][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:   9%| | 524/5551 [2:48:57<26:54:59, 19.28s/it, loss=1.112, ppl=2.16, wps=27100.5, ups=0.05, wpb=523291, bsz=8848.2, num_updates=17000, lr=0.000252294, gnorm=0.121, clip=95, loss_scale=8, train_wall=75[2022-11-16 08:36:22,947][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 004:  12%| | 647/5551 [3:28:56<26:07:20, 19.18s/it, loss=1.11, ppl=2.16, wps=27093.6, ups=0.05, wpb=521867, bsz=8525.7, num_updates=17120, lr=0.000251193, gnorm=0.155, clip=100, loss_scale=1, train_wall=75[2022-11-16 09:16:22,268][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 004:  12%| | 655/5551 [3:31:30<26:07:17, 19.21s/it, loss=1.11, ppl=2.16, wps=27093.6, ups=0.05, wpb=521867, bsz=8525.7, num_updates=17120, lr=0.000251193, gnorm=0.155, clip=100, loss_scale=1, train_wall=75[2022-11-16 09:18:56,377][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 004:  13%|â–| 717/5551 [3:51:26<26:00:10, 19.37s/it, loss=1.116, ppl=2.17, wps=25848, ups=0.05, wpb=522652, bsz=8692.5, num_updates=17160, lr=0.000250826, gnorm=0.197, clip=100, loss_scale=0.25, train_wall=[2022-11-16 09:38:52,424][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 09:38:54,456][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.791 | ppl 3.46 | wps 166569 | wpb 10521.6 | bsz 178.1 | num_updates 17200 | best_loss 1.419                                   
[2022-11-16 09:38:54,457][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 17200 updates
[2022-11-16 09:38:54,457][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_17200.pt
[2022-11-16 09:38:58,976][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_17200.pt
[2022-11-16 09:39:04,941][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_17200.pt (epoch 4 @ 17200 updates, score 1.791) (writing took 10.484211495146155 seconds)
epoch 004:  17%|â–| 917/5551 [4:56:48<24:42:17, 19.19s/it, loss=1.111, ppl=2.16, wps=27101.3, ups=0.05, wpb=522081, bsz=8813.6, num_updates=17360, lr=0.000248991, gnorm=0.14, clip=100, loss_scale=1, train_wall=75[2022-11-16 10:44:14,203][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 10:44:16,218][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.63 | ppl 3.09 | wps 167568 | wpb 10521.6 | bsz 178.1 | num_updates 17400 | best_loss 1.419                                    
[2022-11-16 10:44:16,219][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 17400 updates
[2022-11-16 10:44:16,220][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_17400.pt
[2022-11-16 10:44:20,724][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_17400.pt
[2022-11-16 10:44:24,266][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_17400.pt (epoch 4 @ 17400 updates, score 1.63) (writing took 8.046796048991382 seconds)
epoch 004:  17%|â–| 940/5551 [5:04:20<24:34:55, 19.19s/it, loss=1.109, ppl=2.16, wps=27190, ups=0.05, wpb=522943, bsz=8586.6, num_updates=17400, lr=0.000248624, gnorm=0.127, clip=100, loss_scale=2, train_wall=754[2022-11-16 10:51:46,156][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  20%|â–| 1118/5551 [6:01:30<23:42:24, 19.25s/it, loss=1.108, ppl=2.16, wps=27116.5, ups=0.05, wpb=523411, bsz=8850.1, num_updates=17560, lr=0.000247156, gnorm=0.128, clip=95, loss_scale=2, train_wall=7[2022-11-16 11:48:56,299][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 11:48:58,327][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.666 | ppl 3.17 | wps 167014 | wpb 10521.6 | bsz 178.1 | num_updates 17600 | best_loss 1.419                                   
[2022-11-16 11:48:58,328][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 17600 updates
[2022-11-16 11:48:58,328][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_17600.pt
[2022-11-16 11:49:02,868][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_17600.pt
[2022-11-16 11:49:05,828][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_17600.pt (epoch 4 @ 17600 updates, score 1.666) (writing took 7.500020497478545 seconds)
epoch 004:  22%|â–| 1200/5551 [6:27:54<23:13:51, 19.22s/it, loss=1.108, ppl=2.15, wps=27173.1, ups=0.05, wpb=522284, bsz=8683.8, num_updates=17680, lr=0.000246055, gnorm=0.145, clip=100, loss_scale=8, train_wall=[2022-11-16 12:15:20,580][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 004:  23%|â–| 1298/5551 [6:59:21<22:50:37, 19.34s/it, loss=1.108, ppl=2.16, wps=27116.4, ups=0.05, wpb=522587, bsz=8581.8, num_updates=17760, lr=0.000245321, gnorm=0.117, clip=97.5, loss_scale=4, train_wall[2022-11-16 12:46:47,295][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 004:  24%|â–| 1320/5551 [7:06:25<22:31:44, 19.17s/it, loss=1.108, ppl=2.16, wps=27116.4, ups=0.05, wpb=522587, bsz=8581.8, num_updates=17760, lr=0.000245321, gnorm=0.117, clip=97.5, loss_scale=4, train_wall[2022-11-16 12:53:51,511][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 12:53:53,565][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.541 | ppl 2.91 | wps 165904 | wpb 10521.6 | bsz 178.1 | num_updates 17800 | best_loss 1.419                                   
[2022-11-16 12:53:53,566][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 17800 updates
[2022-11-16 12:53:53,566][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_17800.pt
[2022-11-16 12:53:58,089][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_17800.pt
[2022-11-16 12:54:00,819][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_17800.pt (epoch 4 @ 17800 updates, score 1.541) (writing took 7.252846444956958 seconds)
epoch 004:  24%|â–| 1338/5551 [7:12:21<22:31:58, 19.25s/it, loss=1.108, ppl=2.16, wps=26497, ups=0.05, wpb=523527, bsz=8857, num_updates=17800, lr=0.000244954, gnorm=0.135, clip=100, loss_scale=4, train_wall=773,[2022-11-16 12:59:47,764][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:  25%|â–Ž| 1399/5551 [7:31:57<22:06:21, 19.17s/it, loss=1.107, ppl=2.15, wps=26155.7, ups=0.05, wpb=523253, bsz=8776.5, num_updates=17840, lr=0.000244587, gnorm=0.134, clip=100, loss_scale=2, train_wall=[2022-11-16 13:19:23,289][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  25%|â–Ž| 1410/5551 [7:35:28<22:01:53, 19.15s/it, loss=1.107, ppl=2.15, wps=26442.5, ups=0.05, wpb=521742, bsz=8862.4, num_updates=17880, lr=0.00024422, gnorm=0.132, clip=100, loss_scale=1, train_wall=7[2022-11-16 13:22:54,495][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 004:  26%|â–Ž| 1431/5551 [7:42:13<22:02:40, 19.26s/it, loss=1.107, ppl=2.15, wps=26442.5, ups=0.05, wpb=521742, bsz=8862.4, num_updates=17880, lr=0.00024422, gnorm=0.132, clip=100, loss_scale=1, train_wall=7[2022-11-16 13:29:39,610][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 004:  26%|â–Ž| 1451/5551 [7:48:38<21:56:22, 19.26s/it, loss=1.11, ppl=2.16, wps=25823, ups=0.05, wpb=522349, bsz=9009, num_updates=17920, lr=0.000243853, gnorm=0.186, clip=100, loss_scale=0.25, train_wall=79[2022-11-16 13:36:04,337][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 004:  26%|â–Ž| 1456/5551 [7:50:15<21:50:14, 19.20s/it, loss=1.11, ppl=2.16, wps=25823, ups=0.05, wpb=522349, bsz=9009, num_updates=17920, lr=0.000243853, gnorm=0.186, clip=100, loss_scale=0.25, train_wall=79[2022-11-16 13:37:40,657][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 004:  26%|â–Ž| 1457/5551 [7:50:34<21:49:16, 19.19s/it, loss=1.11, ppl=2.16, wps=25823, ups=0.05, wpb=522349, bsz=9009, num_updates=17920, lr=0.000243853, gnorm=0.186, clip=100, loss_scale=0.25, train_wall=79[2022-11-16 13:37:59,818][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 004:  28%|â–Ž| 1527/5551 [8:12:58<21:32:52, 19.28s/it, loss=1.138, ppl=2.2, wps=25337.5, ups=0.05, wpb=522959, bsz=8854.5, num_updates=17960, lr=0.000243486, gnorm=0.356, clip=100, loss_scale=0.0312, train_w[2022-11-16 14:00:24,093][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 14:00:26,132][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.663 | ppl 3.17 | wps 167452 | wpb 10521.6 | bsz 178.1 | num_updates 18000 | best_loss 1.419                                   
[2022-11-16 14:00:26,133][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 18000 updates
[2022-11-16 14:00:26,133][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_18000.pt
[2022-11-16 14:00:30,665][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_18000.pt
[2022-11-16 14:00:34,939][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_18000.pt (epoch 4 @ 18000 updates, score 1.663) (writing took 8.805913479067385 seconds)
epoch 004:  31%|â–Ž| 1727/5551 [9:17:16<20:28:34, 19.28s/it, loss=1.105, ppl=2.15, wps=27127.5, ups=0.05, wpb=521989, bsz=8889.1, num_updates=18160, lr=0.000241651, gnorm=0.129, clip=100, loss_scale=0.125, train_w[2022-11-16 15:04:41,690][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 15:04:43,733][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.706 | ppl 3.26 | wps 166534 | wpb 10521.6 | bsz 178.1 | num_updates 18200 | best_loss 1.419                                   
[2022-11-16 15:04:43,734][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 18200 updates
[2022-11-16 15:04:43,735][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_18200.pt
[2022-11-16 15:04:48,258][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_18200.pt
[2022-11-16 15:04:51,203][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_18200.pt (epoch 4 @ 18200 updates, score 1.706) (writing took 7.468518000096083 seconds)
epoch 004:  35%|â–Ž| 1927/5551 [10:21:34<19:23:06, 19.26s/it, loss=1.102, ppl=2.15, wps=27136.4, ups=0.05, wpb=522551, bsz=8783.5, num_updates=18360, lr=0.000239817, gnorm=0.138, clip=100, loss_scale=1, train_wall[2022-11-16 16:09:00,430][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 16:09:02,450][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.632 | ppl 3.1 | wps 167737 | wpb 10521.6 | bsz 178.1 | num_updates 18400 | best_loss 1.419                                    
[2022-11-16 16:09:02,450][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 18400 updates
[2022-11-16 16:09:02,451][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_18400.pt
[2022-11-16 16:09:06,949][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_18400.pt
[2022-11-16 16:09:09,977][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_18400.pt (epoch 4 @ 18400 updates, score 1.632) (writing took 7.526852653361857 seconds)
epoch 004:  38%|â–| 2097/5551 [11:16:20<18:31:13, 19.30s/it, loss=1.103, ppl=2.15, wps=27134.8, ups=0.05, wpb=522061, bsz=8639.3, num_updates=18560, lr=0.000237982, gnorm=0.119, clip=97.5, loss_scale=4, train_wal[2022-11-16 17:03:45,926][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:  38%|â–| 2128/5551 [11:26:16<18:17:45, 19.24s/it, loss=1.103, ppl=2.15, wps=27134.8, ups=0.05, wpb=522061, bsz=8639.3, num_updates=18560, lr=0.000237982, gnorm=0.119, clip=97.5, loss_scale=4, train_wal[2022-11-16 17:13:42,078][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 17:13:44,125][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.692 | ppl 3.23 | wps 166640 | wpb 10521.6 | bsz 178.1 | num_updates 18600 | best_loss 1.419                                   
[2022-11-16 17:13:44,126][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 18600 updates
[2022-11-16 17:13:44,126][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_18600.pt
[2022-11-16 17:13:48,633][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_18600.pt
[2022-11-16 17:13:53,588][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_18600.pt (epoch 4 @ 18600 updates, score 1.692) (writing took 9.462408745661378 seconds)
epoch 004:  39%|â–| 2163/5551 [11:37:41<17:59:31, 19.12s/it, loss=1.101, ppl=2.15, wps=26431.7, ups=0.05, wpb=521641, bsz=8606.7, num_updates=18600, lr=0.000237615, gnorm=0.112, clip=97.5, loss_scale=2, train_wal[2022-11-16 17:25:08,015][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  42%|â–| 2329/5551 [12:31:02<17:07:46, 19.14s/it, loss=1.103, ppl=2.15, wps=27067.3, ups=0.05, wpb=522778, bsz=9065.4, num_updates=18760, lr=0.000236147, gnorm=0.136, clip=100, loss_scale=2, train_wall[2022-11-16 18:18:28,370][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 18:18:30,397][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.743 | ppl 3.35 | wps 166789 | wpb 10521.6 | bsz 178.1 | num_updates 18800 | best_loss 1.419                                   
[2022-11-16 18:18:30,397][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 18800 updates
[2022-11-16 18:18:30,398][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_18800.pt
[2022-11-16 18:18:34,891][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_18800.pt
[2022-11-16 18:18:39,533][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_18800.pt (epoch 4 @ 18800 updates, score 1.743) (writing took 9.135031336918473 seconds)
epoch 004:  43%|â–| 2386/5551 [12:49:32<16:53:30, 19.21s/it, loss=1.1, ppl=2.14, wps=26767.7, ups=0.05, wpb=523759, bsz=8614.8, num_updates=18840, lr=0.000235413, gnorm=0.115, clip=95, loss_scale=4, train_wall=75[2022-11-16 18:36:58,168][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:  43%|â–| 2409/5551 [12:56:54<16:43:48, 19.17s/it, loss=1.1, ppl=2.14, wps=26767.7, ups=0.05, wpb=523759, bsz=8614.8, num_updates=18840, lr=0.000235413, gnorm=0.115, clip=95, loss_scale=4, train_wall=75[2022-11-16 18:44:20,164][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  46%|â–| 2531/5551 [13:36:08<16:10:34, 19.28s/it, loss=1.1, ppl=2.14, wps=27137.3, ups=0.05, wpb=524267, bsz=8791, num_updates=18960, lr=0.000234312, gnorm=0.128, clip=100, loss_scale=1, train_wall=757[2022-11-16 19:23:33,959][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 19:23:35,992][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.59 | ppl 3.01 | wps 166683 | wpb 10521.6 | bsz 178.1 | num_updates 19000 | best_loss 1.419                                    
[2022-11-16 19:23:35,993][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 19000 updates
[2022-11-16 19:23:35,993][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_19000.pt
[2022-11-16 19:23:40,679][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_19000.pt
[2022-11-16 19:23:45,423][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_19000.pt (epoch 4 @ 19000 updates, score 1.59) (writing took 9.430510431528091 seconds)
epoch 004:  47%|â–| 2603/5551 [13:59:26<15:44:02, 19.21s/it, loss=1.101, ppl=2.15, wps=26765.6, ups=0.05, wpb=523218, bsz=8657.8, num_updates=19040, lr=0.000233578, gnorm=0.127, clip=95, loss_scale=2, train_wall=[2022-11-16 19:46:52,122][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:  47%|â–| 2607/5551 [14:00:43<15:49:46, 19.36s/it, loss=1.101, ppl=2.15, wps=26765.6, ups=0.05, wpb=523218, bsz=8657.8, num_updates=19040, lr=0.000233578, gnorm=0.127, clip=95, loss_scale=2, train_wall=[2022-11-16 19:48:09,465][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  48%|â–| 2641/5551 [14:11:40<15:37:48, 19.34s/it, loss=1.101, ppl=2.15, wps=25889.7, ups=0.05, wpb=523684, bsz=8817.8, num_updates=19080, lr=0.000233211, gnorm=0.132, clip=90, loss_scale=1, train_wall=[2022-11-16 19:59:06,044][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 004:  49%|â–| 2734/5551 [14:41:32<15:04:46, 19.27s/it, loss=1.099, ppl=2.14, wps=27127.9, ups=0.05, wpb=522622, bsz=8681.7, num_updates=19160, lr=0.000232477, gnorm=0.128, clip=97.5, loss_scale=0.5, train_w[2022-11-16 20:28:57,724][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 20:28:59,778][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.554 | ppl 2.94 | wps 165849 | wpb 10521.6 | bsz 178.1 | num_updates 19200 | best_loss 1.419                                   
[2022-11-16 20:28:59,779][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 19200 updates
[2022-11-16 20:28:59,779][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_19200.pt
[2022-11-16 20:29:04,281][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_19200.pt
[2022-11-16 20:29:07,345][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_19200.pt (epoch 4 @ 19200 updates, score 1.554) (writing took 7.566027783788741 seconds)
epoch 004:  49%|â–| 2744/5551 [14:44:54<15:05:39, 19.36s/it, loss=1.097, ppl=2.14, wps=27099.5, ups=0.05, wpb=522011, bsz=8381.1, num_updates=19200, lr=0.00023211, gnorm=0.135, clip=95, loss_scale=1, train_wall=7[2022-11-16 20:32:20,169][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 004:  53%|â–Œ| 2927/5551 [15:43:48<13:58:23, 19.17s/it, loss=1.097, ppl=2.14, wps=27067, ups=0.05, wpb=521594, bsz=8476.6, num_updates=19360, lr=0.000230642, gnorm=0.131, clip=100, loss_scale=1, train_wall=7[2022-11-16 21:31:14,208][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  53%|â–Œ| 2936/5551 [15:46:42<14:03:49, 19.36s/it, loss=1.097, ppl=2.14, wps=27067, ups=0.05, wpb=521594, bsz=8476.6, num_updates=19360, lr=0.000230642, gnorm=0.131, clip=100, loss_scale=1, train_wall=7[2022-11-16 21:34:08,440][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 21:34:10,481][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.642 | ppl 3.12 | wps 166710 | wpb 10521.6 | bsz 178.1 | num_updates 19400 | best_loss 1.419                                   
[2022-11-16 21:34:10,482][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 19400 updates
[2022-11-16 21:34:10,482][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_19400.pt
[2022-11-16 21:34:14,965][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_19400.pt
[2022-11-16 21:34:19,634][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_19400.pt (epoch 4 @ 19400 updates, score 1.642) (writing took 9.152152316644788 seconds)
epoch 004:  53%|â–Œ| 2944/5551 [15:49:28<14:11:08, 19.59s/it, loss=1.102, ppl=2.15, wps=26334.1, ups=0.05, wpb=521731, bsz=8832.9, num_updates=19400, lr=0.000230275, gnorm=0.171, clip=100, loss_scale=1, train_wall[2022-11-16 21:36:54,328][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 004:  55%|â–Œ| 3041/5551 [16:20:37<13:23:58, 19.22s/it, loss=1.097, ppl=2.14, wps=27150.6, ups=0.05, wpb=523484, bsz=8665.7, num_updates=19480, lr=0.000229541, gnorm=0.129, clip=97.5, loss_scale=0.5, train_w[2022-11-16 22:08:03,254][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 004:  56%|â–Œ| 3135/5551 [16:50:51<12:53:57, 19.22s/it, loss=1.099, ppl=2.14, wps=27062.3, ups=0.05, wpb=522993, bsz=8947.4, num_updates=19560, lr=0.000228807, gnorm=0.12, clip=97.5, loss_scale=0.5, train_wa[2022-11-16 22:38:17,288][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 004:  57%|â–Œ| 3139/5551 [16:52:09<12:58:23, 19.36s/it, loss=1.099, ppl=2.14, wps=27062.3, ups=0.05, wpb=522993, bsz=8947.4, num_updates=19560, lr=0.000228807, gnorm=0.12, clip=97.5, loss_scale=0.5, train_wa[2022-11-16 22:39:34,593][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 22:39:36,616][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.652 | ppl 3.14 | wps 167788 | wpb 10521.6 | bsz 178.1 | num_updates 19600 | best_loss 1.419                                   
[2022-11-16 22:39:36,617][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 19600 updates
[2022-11-16 22:39:36,617][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_19600.pt
[2022-11-16 22:39:41,109][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_19600.pt
[2022-11-16 22:39:45,692][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_19600.pt (epoch 4 @ 19600 updates, score 1.652) (writing took 9.07537102047354 seconds)
epoch 004:  60%|â–Œ| 3339/5551 [17:56:40<11:48:58, 19.23s/it, loss=1.095, ppl=2.14, wps=27153.5, ups=0.05, wpb=523363, bsz=8595.1, num_updates=19760, lr=0.000226972, gnorm=0.117, clip=85, loss_scale=1, train_wall=[2022-11-16 23:44:05,640][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-16 23:44:07,665][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.792 | ppl 3.46 | wps 166676 | wpb 10521.6 | bsz 178.1 | num_updates 19800 | best_loss 1.419                                   
[2022-11-16 23:44:07,666][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 19800 updates
[2022-11-16 23:44:07,666][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_19800.pt
[2022-11-16 23:44:12,146][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_19800.pt
[2022-11-16 23:44:15,895][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_19800.pt (epoch 4 @ 19800 updates, score 1.792) (writing took 8.229215009137988 seconds)
epoch 004:  61%|â–Œ| 3373/5551 [18:07:46<11:40:17, 19.29s/it, loss=1.097, ppl=2.14, wps=27074.3, ups=0.05, wpb=522421, bsz=8821.5, num_updates=19800, lr=0.000226606, gnorm=0.134, clip=97.5, loss_scale=2, train_wal[2022-11-16 23:55:11,740][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  63%|â–‹| 3475/5551 [18:40:34<11:05:00, 19.22s/it, loss=1.093, ppl=2.13, wps=27063, ups=0.05, wpb=522312, bsz=8478, num_updates=19920, lr=0.000225505, gnorm=0.13, clip=97.5, loss_scale=2, train_wall=757[2022-11-17 00:28:00,476][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  64%|â–‹| 3541/5551 [19:01:47<10:46:42, 19.30s/it, loss=1.096, ppl=2.14, wps=26483.6, ups=0.05, wpb=523363, bsz=8701.9, num_updates=19960, lr=0.000225138, gnorm=0.113, clip=90, loss_scale=1, train_wall=[2022-11-17 00:49:13,208][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 00:49:15,240][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.722 | ppl 3.3 | wps 166373 | wpb 10521.6 | bsz 178.1 | num_updates 20000 | best_loss 1.419                                    
[2022-11-17 00:49:15,241][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 20000 updates
[2022-11-17 00:49:15,241][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_20000.pt
[2022-11-17 00:49:19,715][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_20000.pt
[2022-11-17 00:49:23,141][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_20000.pt (epoch 4 @ 20000 updates, score 1.722) (writing took 7.8996893567964435 seconds)
epoch 004:  67%|â–‹| 3704/5551 [19:54:24<9:56:17, 19.37s/it, loss=1.092, ppl=2.13, wps=27085.6, ups=0.05, wpb=523436, bsz=8734.8, num_updates=20160, lr=0.000223303, gnorm=0.125, clip=92.5, loss_scale=4, train_wall[2022-11-17 01:41:49,684][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:  67%|â–‹| 3742/5551 [20:06:36<9:41:00, 19.27s/it, loss=1.092, ppl=2.13, wps=27085.6, ups=0.05, wpb=523436, bsz=8734.8, num_updates=20160, lr=0.000223303, gnorm=0.125, clip=92.5, loss_scale=4, train_wall[2022-11-17 01:54:02,138][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 01:54:04,162][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.704 | ppl 3.26 | wps 167359 | wpb 10521.6 | bsz 178.1 | num_updates 20200 | best_loss 1.419                                   
[2022-11-17 01:54:04,163][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 20200 updates
[2022-11-17 01:54:04,163][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_20200.pt
[2022-11-17 01:54:08,633][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_20200.pt
[2022-11-17 01:54:11,674][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_20200.pt (epoch 4 @ 20200 updates, score 1.704) (writing took 7.510663030669093 seconds)
epoch 004:  70%|â–‹| 3875/5551 [20:49:30<8:57:44, 19.25s/it, loss=1.093, ppl=2.13, wps=27060.8, ups=0.05, wpb=522208, bsz=8670.9, num_updates=20320, lr=0.000221835, gnorm=0.125, clip=100, loss_scale=4, train_wall=[2022-11-17 02:36:56,412][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 004:  71%|â–‹| 3943/5551 [21:11:23<8:37:16, 19.30s/it, loss=1.091, ppl=2.13, wps=26425.4, ups=0.05, wpb=522445, bsz=8564.6, num_updates=20360, lr=0.000221468, gnorm=0.129, clip=100, loss_scale=4, train_wall=[2022-11-17 02:58:49,266][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 02:58:51,307][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.774 | ppl 3.42 | wps 166395 | wpb 10521.6 | bsz 178.1 | num_updates 20400 | best_loss 1.419                                   
[2022-11-17 02:58:51,307][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 20400 updates
[2022-11-17 02:58:51,308][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_20400.pt
[2022-11-17 02:58:55,821][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_20400.pt
[2022-11-17 02:59:01,303][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_20400.pt (epoch 4 @ 20400 updates, score 1.774) (writing took 9.995758147910237 seconds)
epoch 004:  72%|â–‹| 4017/5551 [21:35:24<8:15:06, 19.37s/it, loss=1.089, ppl=2.13, wps=26682.1, ups=0.05, wpb=522987, bsz=8740.8, num_updates=20440, lr=0.000220734, gnorm=0.122, clip=87.5, loss_scale=8, train_wall[2022-11-17 03:22:50,454][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 004:  73%|â–‹| 4049/5551 [21:45:41<8:05:12, 19.38s/it, loss=1.092, ppl=2.13, wps=26445, ups=0.05, wpb=523715, bsz=8778.1, num_updates=20480, lr=0.000220367, gnorm=0.113, clip=80, loss_scale=4, train_wall=776[2022-11-17 03:33:07,380][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:  73%|â–‹| 4079/5551 [21:55:20<7:53:40, 19.31s/it, loss=1.092, ppl=2.13, wps=26473, ups=0.05, wpb=523264, bsz=8812.2, num_updates=20520, lr=0.00022, gnorm=0.112, clip=95, loss_scale=2, train_wall=776, gb[2022-11-17 03:42:46,456][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  75%|â–‹| 4146/5551 [22:16:54<7:31:11, 19.27s/it, loss=1.092, ppl=2.13, wps=26477.8, ups=0.05, wpb=523615, bsz=8770.7, num_updates=20560, lr=0.000219633, gnorm=0.116, clip=97.5, loss_scale=1, train_wall[2022-11-17 04:04:19,815][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 04:04:21,855][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.719 | ppl 3.29 | wps 166680 | wpb 10521.6 | bsz 178.1 | num_updates 20600 | best_loss 1.419                                   
[2022-11-17 04:04:21,856][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 20600 updates
[2022-11-17 04:04:21,856][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_20600.pt
[2022-11-17 04:04:26,329][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_20600.pt
[2022-11-17 04:04:29,384][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_20600.pt (epoch 4 @ 20600 updates, score 1.719) (writing took 7.527892122976482 seconds)
epoch 004:  78%|â–Š| 4340/5551 [23:19:25<6:26:19, 19.14s/it, loss=1.09, ppl=2.13, wps=27065.2, ups=0.05, wpb=522598, bsz=8840.4, num_updates=20760, lr=0.000217798, gnorm=0.117, clip=90, loss_scale=4, train_wall=75[2022-11-17 05:06:51,379][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 004:  78%|â–Š| 4345/5551 [23:21:01<6:27:00, 19.25s/it, loss=1.09, ppl=2.13, wps=27065.2, ups=0.05, wpb=522598, bsz=8840.4, num_updates=20760, lr=0.000217798, gnorm=0.117, clip=90, loss_scale=4, train_wall=75[2022-11-17 05:08:27,570][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:  78%|â–Š| 4348/5551 [23:21:59<6:23:44, 19.14s/it, loss=1.09, ppl=2.13, wps=27065.2, ups=0.05, wpb=522598, bsz=8840.4, num_updates=20760, lr=0.000217798, gnorm=0.117, clip=90, loss_scale=4, train_wall=75[2022-11-17 05:09:25,042][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 05:09:27,094][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.444 | ppl 2.72 | wps 166243 | wpb 10521.6 | bsz 178.1 | num_updates 20800 | best_loss 1.419                                   
[2022-11-17 05:09:27,095][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 20800 updates
[2022-11-17 05:09:27,095][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_20800.pt
[2022-11-17 05:09:31,801][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_20800.pt
[2022-11-17 05:09:35,867][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_20800.pt (epoch 4 @ 20800 updates, score 1.444) (writing took 8.772413648664951 seconds)
epoch 004:  78%|â–Š| 4350/5551 [23:22:48<7:08:42, 21.42s/it, loss=1.09, ppl=2.13, wps=25835.3, ups=0.05, wpb=522804, bsz=8691, num_updates=20800, lr=0.000217431, gnorm=0.138, clip=95, loss_scale=2, train_wall=794,[2022-11-17 05:10:14,212][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  78%|â–Š| 4351/5551 [23:23:07<6:54:58, 20.75s/it, loss=1.09, ppl=2.13, wps=25835.3, ups=0.05, wpb=522804, bsz=8691, num_updates=20800, lr=0.000217431, gnorm=0.138, clip=95, loss_scale=2, train_wall=794,[2022-11-17 05:10:33,883][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 004:  79%|â–Š| 4380/5551 [23:32:27<6:16:15, 19.28s/it, loss=1.09, ppl=2.13, wps=25835.3, ups=0.05, wpb=522804, bsz=8691, num_updates=20800, lr=0.000217431, gnorm=0.138, clip=95, loss_scale=2, train_wall=794,[2022-11-17 05:19:53,139][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 004:  82%|â–Š| 4551/5551 [24:27:27<5:22:29, 19.35s/it, loss=1.088, ppl=2.13, wps=27107.7, ups=0.05, wpb=522612, bsz=8504.6, num_updates=20960, lr=0.000215963, gnorm=0.129, clip=100, loss_scale=0.5, train_wal[2022-11-17 06:14:53,260][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 06:14:55,290][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.567 | ppl 2.96 | wps 166780 | wpb 10521.6 | bsz 178.1 | num_updates 21000 | best_loss 1.419                                   
[2022-11-17 06:14:55,291][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 21000 updates
[2022-11-17 06:14:55,291][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_21000.pt
[2022-11-17 06:14:59,744][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_21000.pt
[2022-11-17 06:15:02,631][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_21000.pt (epoch 4 @ 21000 updates, score 1.567) (writing took 7.339898434467614 seconds)
epoch 004:  84%|â–Š| 4681/5551 [25:09:26<4:40:07, 19.32s/it, loss=1.09, ppl=2.13, wps=27017.2, ups=0.05, wpb=521913, bsz=8847.8, num_updates=21120, lr=0.000214495, gnorm=0.121, clip=95, loss_scale=2, train_wall=75[2022-11-17 06:56:51,660][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  84%|â–Š| 4682/5551 [25:09:45<4:38:41, 19.24s/it, loss=1.09, ppl=2.13, wps=27017.2, ups=0.05, wpb=521913, bsz=8847.8, num_updates=21120, lr=0.000214495, gnorm=0.121, clip=95, loss_scale=2, train_wall=75[2022-11-17 06:57:11,100][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 004:  84%|â–Š| 4686/5551 [25:11:02<4:39:06, 19.36s/it, loss=1.09, ppl=2.13, wps=27017.2, ups=0.05, wpb=521913, bsz=8847.8, num_updates=21120, lr=0.000214495, gnorm=0.121, clip=95, loss_scale=2, train_wall=75[2022-11-17 06:58:29,013][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 004:  86%|â–Š| 4754/5551 [25:32:53<4:16:06, 19.28s/it, loss=1.096, ppl=2.14, wps=25173, ups=0.05, wpb=522090, bsz=8607, num_updates=21160, lr=0.000214128, gnorm=0.217, clip=100, loss_scale=0.25, train_wall=8[2022-11-17 07:20:18,760][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 07:20:20,801][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.757 | ppl 3.38 | wps 167406 | wpb 10521.6 | bsz 178.1 | num_updates 21200 | best_loss 1.419                                   
[2022-11-17 07:20:20,802][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 21200 updates
[2022-11-17 07:20:20,802][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_21200.pt
[2022-11-17 07:20:25,287][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_21200.pt
[2022-11-17 07:20:28,543][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_21200.pt (epoch 4 @ 21200 updates, score 1.757) (writing took 7.741175326518714 seconds)
epoch 004:  89%|â–‰| 4954/5551 [26:37:19<3:12:43, 19.37s/it, loss=1.088, ppl=2.13, wps=27077, ups=0.05, wpb=522622, bsz=8716.6, num_updates=21360, lr=0.000212294, gnorm=0.12, clip=95, loss_scale=1, train_wall=757,[2022-11-17 08:24:45,490][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 08:24:47,516][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.62 | ppl 3.07 | wps 167438 | wpb 10521.6 | bsz 178.1 | num_updates 21400 | best_loss 1.419                                    
[2022-11-17 08:24:47,517][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 21400 updates
[2022-11-17 08:24:47,517][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_21400.pt
[2022-11-17 08:24:51,982][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_21400.pt
[2022-11-17 08:24:55,046][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_21400.pt (epoch 4 @ 21400 updates, score 1.62) (writing took 7.528864004649222 seconds)
epoch 004:  91%|â–‰| 5033/5551 [27:02:52<2:46:21, 19.27s/it, loss=1.089, ppl=2.13, wps=26774.2, ups=0.05, wpb=523218, bsz=8934.1, num_updates=21440, lr=0.00021156, gnorm=0.124, clip=92.5, loss_scale=2, train_wall=[2022-11-17 08:50:17,854][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:  92%|â–‰| 5130/5551 [27:34:04<2:16:01, 19.39s/it, loss=1.085, ppl=2.12, wps=27110.5, ups=0.05, wpb=523799, bsz=8835.3, num_updates=21560, lr=0.000210459, gnorm=0.123, clip=82.5, loss_scale=2, train_wall[2022-11-17 09:21:30,848][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:  93%|â–‰| 5156/5551 [27:42:25<2:05:53, 19.12s/it, loss=1.085, ppl=2.12, wps=27110.5, ups=0.05, wpb=523799, bsz=8835.3, num_updates=21560, lr=0.000210459, gnorm=0.123, clip=82.5, loss_scale=2, train_wall[2022-11-17 09:29:51,739][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 09:29:53,775][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.666 | ppl 3.17 | wps 166419 | wpb 10521.6 | bsz 178.1 | num_updates 21600 | best_loss 1.419                                   
[2022-11-17 09:29:53,776][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 21600 updates
[2022-11-17 09:29:53,776][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_21600.pt
[2022-11-17 09:29:58,237][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_21600.pt
[2022-11-17 09:30:02,343][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_21600.pt (epoch 4 @ 21600 updates, score 1.666) (writing took 8.567541067488492 seconds)
epoch 004:  95%|â–‰| 5277/5551 [28:21:28<1:27:56, 19.26s/it, loss=1.084, ppl=2.12, wps=27090.6, ups=0.05, wpb=522484, bsz=9002.1, num_updates=21720, lr=0.000208991, gnorm=0.121, clip=92.5, loss_scale=4, train_wall[2022-11-17 10:08:54,600][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 004:  95%|â–‰| 5287/5551 [28:24:40<1:24:11, 19.14s/it, loss=1.084, ppl=2.12, wps=27090.6, ups=0.05, wpb=522484, bsz=9002.1, num_updates=21720, lr=0.000208991, gnorm=0.121, clip=92.5, loss_scale=4, train_wall[2022-11-17 10:12:06,145][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 004:  95%|â–‰| 5289/5551 [28:25:18<1:23:31, 19.13s/it, loss=1.084, ppl=2.12, wps=27090.6, ups=0.05, wpb=522484, bsz=9002.1, num_updates=21720, lr=0.000208991, gnorm=0.121, clip=92.5, loss_scale=4, train_wall[2022-11-17 10:12:44,460][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 004:  95%|â–‰| 5290/5551 [28:25:37<1:23:15, 19.14s/it, loss=1.084, ppl=2.12, wps=27090.6, ups=0.05, wpb=522484, bsz=9002.1, num_updates=21720, lr=0.000208991, gnorm=0.121, clip=92.5, loss_scale=4, train_wall[2022-11-17 10:13:03,641][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 004:  95%|â–‰| 5291/5551 [28:25:57<1:22:59, 19.15s/it, loss=1.084, ppl=2.12, wps=27090.6, ups=0.05, wpb=522484, bsz=9002.1, num_updates=21720, lr=0.000208991, gnorm=0.121, clip=92.5, loss_scale=4, train_wall[2022-11-17 10:13:22,664][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 004:  95%|â–‰| 5293/5551 [28:26:35<1:22:35, 19.21s/it, loss=1.084, ppl=2.12, wps=27090.6, ups=0.05, wpb=522484, bsz=9002.1, num_updates=21720, lr=0.000208991, gnorm=0.121, clip=92.5, loss_scale=4, train_wall[2022-11-17 10:14:01,226][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 004:  97%|â–‰| 5362/5551 [28:48:40<1:00:19, 19.15s/it, loss=1.109, ppl=2.16, wps=23602.7, ups=0.05, wpb=520844, bsz=8813.5, num_updates=21760, lr=0.000208624, gnorm=0.342, clip=100, loss_scale=0.0625, train_[2022-11-17 10:36:06,358][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 10:36:08,393][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.603 | ppl 3.04 | wps 167628 | wpb 10521.6 | bsz 178.1 | num_updates 21800 | best_loss 1.419                                   
[2022-11-17 10:36:08,393][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 21800 updates
[2022-11-17 10:36:08,394][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_21800.pt
[2022-11-17 10:36:13,852][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_4_21800.pt
[2022-11-17 10:36:18,305][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_4_21800.pt (epoch 4 @ 21800 updates, score 1.603) (writing took 9.911644804291427 seconds)
epoch 004: 100%|â–‰| 5550/5551 [29:49:26<00:19, 19.41s/it, loss=1.084, ppl=2.12, wps=27105.5, ups=0.05, wpb=521092, bsz=8744.2, num_updates=21960, lr=0.000206789, gnorm=0.116, clip=87.5, loss_scale=0.25, train_wal[2022-11-17 11:36:49,976][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 11:36:52,004][valid][INFO] - epoch 004 | valid on 'valid' subset | loss 1.637 | ppl 3.11 | wps 166578 | wpb 10521.6 | bsz 178.1 | num_updates 21988 | best_loss 1.419                                   
[2022-11-17 11:36:52,005][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 4 @ 21988 updates
[2022-11-17 11:36:52,005][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint4.pt
[2022-11-17 11:36:56,487][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint4.pt
[2022-11-17 11:37:00,419][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint4.pt (epoch 4 @ 21988 updates, score 1.637) (writing took 8.414374129846692 seconds)
[2022-11-17 11:37:00,420][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)                                                                                                                    
[2022-11-17 11:37:00,422][train][INFO] - epoch 004 | loss 1.099 | ppl 2.14 | wps 26740.8 | ups 0.05 | wpb 522624 | bsz 8744.7 | num_updates 21988 | lr 0.000206532 | gnorm 0.133 | clip 95.4 | loss_scale 0.5 | train_wall 104987 | gb_free 6.7 | wall 429187
[2022-11-17 11:37:00,940][fairseq.data.iterators][INFO] - grouped total_num_itrs = 5551
epoch 005:   0%|                                                                                                                                                                          | 0/5551 [00:00<?, ?it/s][2022-11-17 11:37:01,032][fairseq.trainer][INFO] - begin training epoch 5
[2022-11-17 11:37:01,032][fairseq_cli.train][INFO] - Start iterating over samples
epoch 005:   0%|â–Ž                                                                                                                                                             | 11/5551 [03:32<29:42:12, 19.30s/it][2022-11-17 11:40:52,180][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 11:40:54,200][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.867 | ppl 3.65 | wps 168483 | wpb 10521.6 | bsz 178.1 | num_updates 22000 | best_loss 1.419                                   
[2022-11-17 11:40:54,201][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 22000 updates
[2022-11-17 11:40:54,201][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_22000.pt
[2022-11-17 11:40:58,777][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_22000.pt
[2022-11-17 11:41:02,698][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_22000.pt (epoch 5 @ 22000 updates, score 1.867) (writing took 8.497025587596 seconds)
epoch 005:   4%| | 211/5551 [1:07:50<28:32:36, 19.24s/it, loss=1.081, ppl=2.12, wps=27132.9, ups=0.05, wpb=521274, bsz=8520.5, num_updates=22160, lr=0.000204954, gnorm=0.108, clip=77.5, loss_scale=2, train_wall=[2022-11-17 12:45:10,936][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 12:45:12,942][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.675 | ppl 3.19 | wps 168034 | wpb 10521.6 | bsz 178.1 | num_updates 22200 | best_loss 1.419                                   
[2022-11-17 12:45:12,943][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 22200 updates
[2022-11-17 12:45:12,943][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_22200.pt
[2022-11-17 12:45:17,476][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_22200.pt
[2022-11-17 12:45:20,404][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_22200.pt (epoch 5 @ 22200 updates, score 1.675) (writing took 7.461034335196018 seconds)
epoch 005:   6%| | 358/5551 [1:55:11<27:50:00, 19.30s/it, loss=1.08, ppl=2.11, wps=27089.2, ups=0.05, wpb=520894, bsz=8510.1, num_updates=22320, lr=0.000203486, gnorm=0.109, clip=60, loss_scale=4, train_wall=756[2022-11-17 13:32:31,404][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 005:   7%| | 412/5551 [2:12:30<27:42:14, 19.41s/it, loss=1.08, ppl=2.11, wps=26488.3, ups=0.05, wpb=522682, bsz=8766.2, num_updates=22360, lr=0.000203119, gnorm=0.118, clip=87.5, loss_scale=4, train_wall=7[2022-11-17 13:49:50,911][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 13:49:52,929][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.74 | ppl 3.34 | wps 167673 | wpb 10521.6 | bsz 178.1 | num_updates 22400 | best_loss 1.419                                    
[2022-11-17 13:49:52,930][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 22400 updates
[2022-11-17 13:49:52,931][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_22400.pt
[2022-11-17 13:49:57,481][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_22400.pt
[2022-11-17 13:50:02,216][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_22400.pt (epoch 5 @ 22400 updates, score 1.74) (writing took 9.285772074013948 seconds)
epoch 005:   8%| | 462/5551 [2:28:42<27:16:59, 19.30s/it, loss=1.079, ppl=2.11, wps=26852, ups=0.05, wpb=523231, bsz=8525.8, num_updates=22440, lr=0.000202385, gnorm=0.113, clip=90, loss_scale=8, train_wall=754,[2022-11-17 14:06:03,151][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 005:  10%| | 550/5551 [3:21:07<53:29:18, 38.50s/it, loss=1.077, ppl=2.11, wps=18836.1, ups=0.04, wpb=523325, bsz=8972.7, num_updates=22520, lr=0.000201651, gnorm=0.114, clip=92.5, loss_scale=4, train_wall=[2022-11-17 14:58:27,346][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 005:  11%| | 614/5551 [3:41:36<26:20:16, 19.21s/it, loss=1.078, ppl=2.11, wps=11031.6, ups=0.02, wpb=523373, bsz=8780.3, num_updates=22560, lr=0.000201284, gnorm=0.133, clip=100, loss_scale=4, train_wall=1[2022-11-17 15:18:57,336][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 15:18:59,358][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.725 | ppl 3.31 | wps 166483 | wpb 10521.6 | bsz 178.1 | num_updates 22600 | best_loss 1.419                                   
[2022-11-17 15:18:59,359][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 22600 updates
[2022-11-17 15:18:59,359][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_22600.pt
[2022-11-17 15:19:03,813][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_22600.pt
[2022-11-17 15:19:06,875][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_22600.pt (epoch 5 @ 22600 updates, score 1.725) (writing took 7.516434269957244 seconds)
epoch 005:  12%| | 652/5551 [3:53:57<26:11:02, 19.24s/it, loss=1.076, ppl=2.11, wps=27226.5, ups=0.05, wpb=523343, bsz=8782.8, num_updates=22600, lr=0.000200917, gnorm=0.128, clip=95, loss_scale=4, train_wall=75[2022-11-17 15:31:18,008][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 005:  14%|â–| 787/5551 [4:37:16<25:26:49, 19.23s/it, loss=1.077, ppl=2.11, wps=27178.3, ups=0.05, wpb=523271, bsz=8973.2, num_updates=22760, lr=0.00019945, gnorm=0.119, clip=87.5, loss_scale=8, train_wall=7[2022-11-17 16:14:36,829][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 005:  15%|â–| 816/5551 [4:46:34<25:18:47, 19.25s/it, loss=1.077, ppl=2.11, wps=27178.3, ups=0.05, wpb=523271, bsz=8973.2, num_updates=22760, lr=0.00019945, gnorm=0.119, clip=87.5, loss_scale=8, train_wall=7[2022-11-17 16:23:54,872][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 16:23:56,886][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.644 | ppl 3.13 | wps 168186 | wpb 10521.6 | bsz 178.1 | num_updates 22800 | best_loss 1.419                                   
[2022-11-17 16:23:56,887][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 22800 updates
[2022-11-17 16:23:56,887][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_22800.pt
[2022-11-17 16:24:01,432][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_22800.pt
[2022-11-17 16:24:04,622][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_22800.pt (epoch 5 @ 22800 updates, score 1.644) (writing took 7.734979146160185 seconds)
epoch 005:  16%|â–| 878/5551 [5:06:41<25:02:49, 19.30s/it, loss=1.076, ppl=2.11, wps=26767.6, ups=0.05, wpb=523718, bsz=8771.6, num_updates=22840, lr=0.000198716, gnorm=0.116, clip=87.5, loss_scale=4, train_wall=[2022-11-17 16:44:01,962][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 005:  18%|â–| 999/5551 [5:45:32<24:26:44, 19.33s/it, loss=1.078, ppl=2.11, wps=27147.3, ups=0.05, wpb=522981, bsz=8656.4, num_updates=22960, lr=0.000197615, gnorm=0.122, clip=90, loss_scale=8, train_wall=75[2022-11-17 17:22:52,990][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 005:  18%|â–| 1007/5551 [5:48:05<24:06:20, 19.10s/it, loss=1.078, ppl=2.11, wps=27147.3, ups=0.05, wpb=522981, bsz=8656.4, num_updates=22960, lr=0.000197615, gnorm=0.122, clip=90, loss_scale=8, train_wall=7[2022-11-17 17:25:25,990][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  18%|â–| 1019/5551 [5:51:57<24:17:07, 19.29s/it, loss=1.078, ppl=2.11, wps=27147.3, ups=0.05, wpb=522981, bsz=8656.4, num_updates=22960, lr=0.000197615, gnorm=0.122, clip=90, loss_scale=8, train_wall=7[2022-11-17 17:29:18,566][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 17:29:20,610][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.707 | ppl 3.26 | wps 167143 | wpb 10521.6 | bsz 178.1 | num_updates 23000 | best_loss 1.419                                   
[2022-11-17 17:29:20,610][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 23000 updates
[2022-11-17 17:29:20,611][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23000.pt
[2022-11-17 17:29:25,078][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23000.pt
[2022-11-17 17:29:28,016][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_23000.pt (epoch 5 @ 23000 updates, score 1.707) (writing took 7.405931328423321 seconds)
epoch 005:  18%|â–| 1020/5551 [5:52:27<28:10:43, 22.39s/it, loss=1.08, ppl=2.11, wps=25813.3, ups=0.05, wpb=523144, bsz=8622.4, num_updates=23000, lr=0.000197248, gnorm=0.116, clip=80, loss_scale=2, train_wall=79[2022-11-17 17:29:47,211][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2022-11-17 17:29:47,212][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 17:29:49,234][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.701 | ppl 3.25 | wps 168550 | wpb 10521.6 | bsz 178.1 | num_updates 23000 | best_loss 1.419                                   
[2022-11-17 17:29:49,235][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 23000 updates
[2022-11-17 17:29:49,235][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23000.pt
[2022-11-17 17:29:55,953][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23000.pt
[2022-11-17 17:29:58,948][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_23000.pt (epoch 5 @ 23000 updates, score 1.701) (writing took 9.71319874189794 seconds)
epoch 005:  18%|â–| 1021/5551 [5:52:58<31:14:02, 24.82s/it, loss=1.08, ppl=2.11, wps=25813.3, ups=0.05, wpb=523144, bsz=8622.4, num_updates=23000, lr=0.000197248, gnorm=0.116, clip=80, loss_scale=2, train_wall=79[2022-11-17 17:30:18,013][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2022-11-17 17:30:18,014][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 17:30:20,048][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.701 | ppl 3.25 | wps 167851 | wpb 10521.6 | bsz 178.1 | num_updates 23000 | best_loss 1.419                                   
[2022-11-17 17:30:20,049][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 23000 updates
[2022-11-17 17:30:20,050][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23000.pt
[2022-11-17 17:30:25,235][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23000.pt
[2022-11-17 17:30:30,327][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_23000.pt (epoch 5 @ 23000 updates, score 1.701) (writing took 10.277577224187553 seconds)
epoch 005:  18%|â–| 1022/5551 [5:53:29<33:42:07, 26.79s/it, loss=1.08, ppl=2.11, wps=25813.3, ups=0.05, wpb=523144, bsz=8622.4, num_updates=23000, lr=0.000197248, gnorm=0.116, clip=80, loss_scale=2, train_wall=79[2022-11-17 17:30:49,135][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2022-11-17 17:30:49,136][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 17:30:51,138][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.701 | ppl 3.25 | wps 168759 | wpb 10521.6 | bsz 178.1 | num_updates 23000 | best_loss 1.419                                   
[2022-11-17 17:30:51,139][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 23000 updates
[2022-11-17 17:30:51,139][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23000.pt
[2022-11-17 17:30:57,772][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23000.pt
[2022-11-17 17:33:09,878][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_23000.pt (epoch 5 @ 23000 updates, score 1.701) (writing took 138.73939797934145 seconds)
epoch 005:  18%|â–| 1023/5551 [5:56:08<83:47:25, 66.62s/it, loss=1.08, ppl=2.11, wps=25813.3, ups=0.05, wpb=523144, bsz=8622.4, num_updates=23000, lr=0.000197248, gnorm=0.116, clip=80, loss_scale=2, train_wall=79[2022-11-17 17:33:28,637][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2022-11-17 17:34:33,593][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 17:34:36,908][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.701 | ppl 3.25 | wps 170310 | wpb 10521.6 | bsz 178.1 | num_updates 23000 | best_loss 1.419                                   
[2022-11-17 17:34:36,909][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 23000 updates
[2022-11-17 17:34:36,909][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23000.pt
[2022-11-17 17:35:03,172][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23000.pt
[2022-11-17 17:37:26,464][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_23000.pt (epoch 5 @ 23000 updates, score 1.701) (writing took 169.55566931981593 seconds)
epoch 005:  18%|â–| 1025/5551 [6:00:44<115:55:46, 92.21s/it, loss=1.08, ppl=2.11, wps=25813.3, ups=0.05, wpb=523144, bsz=8622.4, num_updates=23000, lr=0.000197248, gnorm=0.116, clip=80, loss_scale=2, train_wall=7[2022-11-17 17:38:04,748][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 005:  18%|â–| 1026/5551 [6:01:03<88:25:23, 70.35s/it, loss=1.08, ppl=2.11, wps=25813.3, ups=0.05, wpb=523144, bsz=8622.4, num_updates=23000, lr=0.000197248, gnorm=0.116, clip=80, loss_scale=2, train_wall=79[2022-11-17 17:38:23,909][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 005:  22%|â–| 1225/5551 [7:04:53<23:03:49, 19.19s/it, loss=1.075, ppl=2.11, wps=27150.7, ups=0.05, wpb=522518, bsz=8623.6, num_updates=23160, lr=0.00019578, gnorm=0.115, clip=90, loss_scale=0.0625, train_wa[2022-11-17 18:42:13,098][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 18:42:15,127][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.772 | ppl 3.41 | wps 167227 | wpb 10521.6 | bsz 178.1 | num_updates 23200 | best_loss 1.419                                   
[2022-11-17 18:42:15,127][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 23200 updates
[2022-11-17 18:42:15,128][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23200.pt
[2022-11-17 18:42:19,684][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23200.pt
[2022-11-17 18:42:24,544][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_23200.pt (epoch 5 @ 23200 updates, score 1.772) (writing took 9.416400474496186 seconds)
epoch 005:  26%|â–Ž| 1425/5551 [8:09:17<22:07:41, 19.31s/it, loss=1.076, ppl=2.11, wps=27152.9, ups=0.05, wpb=522638, bsz=8555.6, num_updates=23360, lr=0.000193945, gnorm=0.114, clip=90, loss_scale=0.5, train_wall[2022-11-17 19:46:37,409][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 19:46:39,463][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.622 | ppl 3.08 | wps 165931 | wpb 10521.6 | bsz 178.1 | num_updates 23400 | best_loss 1.419                                   
[2022-11-17 19:46:39,463][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 23400 updates
[2022-11-17 19:46:39,464][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23400.pt
[2022-11-17 19:46:43,985][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23400.pt
[2022-11-17 19:46:48,858][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_23400.pt (epoch 5 @ 23400 updates, score 1.622) (writing took 9.394344503991306 seconds)
epoch 005:  29%|â–Ž| 1625/5551 [9:13:44<20:58:19, 19.23s/it, loss=1.073, ppl=2.1, wps=27089.4, ups=0.05, wpb=523746, bsz=8638.8, num_updates=23560, lr=0.00019211, gnorm=0.14, clip=97.5, loss_scale=2, train_wall=76[2022-11-17 20:51:05,031][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 20:51:07,061][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.682 | ppl 3.21 | wps 167894 | wpb 10521.6 | bsz 178.1 | num_updates 23600 | best_loss 1.419                                   
[2022-11-17 20:51:07,063][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 23600 updates
[2022-11-17 20:51:07,063][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23600.pt
[2022-11-17 20:51:11,534][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23600.pt
[2022-11-17 20:51:15,109][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_23600.pt (epoch 5 @ 23600 updates, score 1.682) (writing took 8.045593997463584 seconds)
epoch 005:  31%|â–Ž| 1705/5551 [9:39:38<20:38:27, 19.32s/it, loss=1.072, ppl=2.1, wps=26756.8, ups=0.05, wpb=522944, bsz=8509.5, num_updates=23640, lr=0.000191376, gnorm=0.118, clip=92.5, loss_scale=4, train_wall=[2022-11-17 21:16:58,215][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  33%|â–Ž| 1826/5551 [10:18:31<19:55:46, 19.26s/it, loss=1.074, ppl=2.11, wps=27070.5, ups=0.05, wpb=521306, bsz=8842.1, num_updates=23760, lr=0.000190275, gnorm=0.114, clip=90, loss_scale=2, train_wall=[2022-11-17 21:55:51,585][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 21:55:53,639][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.756 | ppl 3.38 | wps 165974 | wpb 10521.6 | bsz 178.1 | num_updates 23800 | best_loss 1.419                                   
[2022-11-17 21:55:53,640][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 23800 updates
[2022-11-17 21:55:53,640][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23800.pt
[2022-11-17 21:55:58,155][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_23800.pt
[2022-11-17 21:56:01,840][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_23800.pt (epoch 5 @ 23800 updates, score 1.756) (writing took 8.200635865330696 seconds)
epoch 005:  33%|â–Ž| 1846/5551 [10:25:08<19:53:11, 19.32s/it, loss=1.074, ppl=2.11, wps=27010.1, ups=0.05, wpb=520831, bsz=8476.9, num_updates=23800, lr=0.000189908, gnorm=0.107, clip=82.5, loss_scale=4, train_wal[2022-11-17 22:02:28,763][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  35%|â–Ž| 1938/5551 [10:54:42<19:18:36, 19.24s/it, loss=1.075, ppl=2.11, wps=27143.4, ups=0.05, wpb=523176, bsz=8855.9, num_updates=23880, lr=0.000189174, gnorm=0.118, clip=82.5, loss_scale=2, train_wal[2022-11-17 22:32:02,079][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  37%|â–Ž| 2028/5551 [11:23:37<18:47:59, 19.21s/it, loss=1.073, ppl=2.1, wps=27135.4, ups=0.05, wpb=523512, bsz=8893.2, num_updates=23960, lr=0.00018844, gnorm=0.12, clip=92.5, loss_scale=2, train_wall=7[2022-11-17 23:00:57,851][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-17 23:00:59,907][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.728 | ppl 3.31 | wps 166420 | wpb 10521.6 | bsz 178.1 | num_updates 24000 | best_loss 1.419                                   
[2022-11-17 23:00:59,908][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 24000 updates
[2022-11-17 23:00:59,908][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_24000.pt
[2022-11-17 23:01:04,430][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_24000.pt
[2022-11-17 23:01:08,558][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_24000.pt (epoch 5 @ 24000 updates, score 1.728) (writing took 8.650187847204506 seconds)
epoch 005:  37%|â–Ž| 2035/5551 [11:26:02<19:09:49, 19.62s/it, loss=1.075, ppl=2.11, wps=27030.1, ups=0.05, wpb=521281, bsz=8677, num_updates=24000, lr=0.000188073, gnorm=0.11, clip=90, loss_scale=4, train_wall=757[2022-11-17 23:03:23,348][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  39%|â–| 2152/5551 [12:03:37<18:14:23, 19.32s/it, loss=1.07, ppl=2.1, wps=27154.1, ups=0.05, wpb=523169, bsz=8750.1, num_updates=24120, lr=0.000186972, gnorm=0.112, clip=75, loss_scale=4, train_wall=75[2022-11-17 23:40:57,653][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  40%|â–| 2230/5551 [12:28:39<17:50:31, 19.34s/it, loss=1.072, ppl=2.1, wps=26425.8, ups=0.05, wpb=521016, bsz=8840.8, num_updates=24160, lr=0.000186606, gnorm=0.122, clip=95, loss_scale=2, train_wall=7[2022-11-18 00:05:59,554][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 00:06:01,592][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.691 | ppl 3.23 | wps 166613 | wpb 10521.6 | bsz 178.1 | num_updates 24200 | best_loss 1.419                                   
[2022-11-18 00:06:01,593][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 24200 updates
[2022-11-18 00:06:01,593][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_24200.pt
[2022-11-18 00:06:06,062][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_24200.pt
[2022-11-18 00:06:08,914][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_24200.pt (epoch 5 @ 24200 updates, score 1.691) (writing took 7.32081354316324 seconds)
epoch 005:  41%|â–| 2265/5551 [12:40:03<17:36:09, 19.28s/it, loss=1.07, ppl=2.1, wps=27085.3, ups=0.05, wpb=522297, bsz=8772.4, num_updates=24200, lr=0.000186239, gnorm=0.107, clip=70, loss_scale=2, train_wall=75[2022-11-18 00:17:23,872][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  43%|â–| 2390/5551 [13:20:16<16:58:27, 19.33s/it, loss=1.073, ppl=2.1, wps=27071, ups=0.05, wpb=522364, bsz=8728.4, num_updates=24320, lr=0.000185138, gnorm=0.108, clip=77.5, loss_scale=4, train_wall=7[2022-11-18 00:57:36,491][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  44%|â–| 2432/5551 [13:33:46<16:38:38, 19.21s/it, loss=1.073, ppl=2.1, wps=26433.3, ups=0.05, wpb=522970, bsz=8940, num_updates=24360, lr=0.000184771, gnorm=0.112, clip=87.5, loss_scale=2, train_wall=7[2022-11-18 01:11:06,376][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 01:11:08,416][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.6 | ppl 3.03 | wps 167410 | wpb 10521.6 | bsz 178.1 | num_updates 24400 | best_loss 1.419                                     
[2022-11-18 01:11:08,417][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 24400 updates
[2022-11-18 01:11:08,417][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_24400.pt
[2022-11-18 01:11:12,872][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_24400.pt
[2022-11-18 01:11:16,472][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_24400.pt (epoch 5 @ 24400 updates, score 1.6) (writing took 8.0558554623276 seconds)
epoch 005:  44%|â–| 2446/5551 [13:38:25<16:37:57, 19.28s/it, loss=1.071, ppl=2.1, wps=27135.1, ups=0.05, wpb=523247, bsz=8597.5, num_updates=24400, lr=0.000184404, gnorm=0.116, clip=80, loss_scale=2, train_wall=7[2022-11-18 01:15:45,947][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 005:  45%|â–| 2472/5551 [13:46:46<16:26:38, 19.23s/it, loss=1.071, ppl=2.1, wps=27135.1, ups=0.05, wpb=523247, bsz=8597.5, num_updates=24400, lr=0.000184404, gnorm=0.116, clip=80, loss_scale=2, train_wall=7[2022-11-18 01:24:06,887][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 005:  45%|â–| 2480/5551 [13:49:20<16:25:42, 19.26s/it, loss=1.07, ppl=2.1, wps=25571.1, ups=0.05, wpb=523428, bsz=8780.8, num_updates=24440, lr=0.000184037, gnorm=0.121, clip=90, loss_scale=0.5, train_wall=[2022-11-18 01:26:40,917][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 005:  45%|â–| 2483/5551 [13:50:18<16:26:04, 19.28s/it, loss=1.07, ppl=2.1, wps=25571.1, ups=0.05, wpb=523428, bsz=8780.8, num_updates=24440, lr=0.000184037, gnorm=0.121, clip=90, loss_scale=0.5, train_wall=[2022-11-18 01:27:38,633][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 005:  45%|â–| 2486/5551 [13:51:16<16:22:12, 19.23s/it, loss=1.07, ppl=2.1, wps=25571.1, ups=0.05, wpb=523428, bsz=8780.8, num_updates=24440, lr=0.000184037, gnorm=0.121, clip=90, loss_scale=0.5, train_wall=[2022-11-18 01:28:36,103][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 005:  48%|â–| 2637/5551 [14:39:42<15:33:35, 19.22s/it, loss=1.069, ppl=2.1, wps=27202.1, ups=0.05, wpb=523161, bsz=8584.1, num_updates=24560, lr=0.000182936, gnorm=0.123, clip=90, loss_scale=0.125, train_wa[2022-11-18 02:17:02,278][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 02:17:04,306][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.741 | ppl 3.34 | wps 167663 | wpb 10521.6 | bsz 178.1 | num_updates 24600 | best_loss 1.419                                   
[2022-11-18 02:17:04,306][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 24600 updates
[2022-11-18 02:17:04,307][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_24600.pt
[2022-11-18 02:17:08,778][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_24600.pt
[2022-11-18 02:17:12,547][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_24600.pt (epoch 5 @ 24600 updates, score 1.741) (writing took 8.240786569193006 seconds)
epoch 005:  51%|â–Œ| 2837/5551 [15:44:06<14:36:18, 19.37s/it, loss=1.068, ppl=2.1, wps=27084.4, ups=0.05, wpb=522744, bsz=8806.7, num_updates=24760, lr=0.000181101, gnorm=0.115, clip=77.5, loss_scale=0.5, train_wa[2022-11-18 03:21:27,028][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 03:21:29,048][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.611 | ppl 3.06 | wps 167210 | wpb 10521.6 | bsz 178.1 | num_updates 24800 | best_loss 1.419                                   
[2022-11-18 03:21:29,049][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 24800 updates
[2022-11-18 03:21:29,050][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_24800.pt
[2022-11-18 03:21:33,481][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_24800.pt
[2022-11-18 03:21:39,097][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_24800.pt (epoch 5 @ 24800 updates, score 1.611) (writing took 10.048341537825763 seconds)
epoch 005:  54%|â–Œ| 2984/5551 [16:31:30<13:45:57, 19.31s/it, loss=1.068, ppl=2.1, wps=27046.7, ups=0.05, wpb=520708, bsz=8429.6, num_updates=24920, lr=0.000179633, gnorm=0.118, clip=90, loss_scale=2, train_wall=7[2022-11-18 04:08:50,134][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 005:  55%|â–Œ| 3038/5551 [16:48:51<13:26:10, 19.25s/it, loss=1.069, ppl=2.1, wps=26511.6, ups=0.05, wpb=523624, bsz=8769.5, num_updates=24960, lr=0.000179266, gnorm=0.109, clip=75, loss_scale=1, train_wall=7[2022-11-18 04:26:12,009][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 04:26:14,033][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.673 | ppl 3.19 | wps 167381 | wpb 10521.6 | bsz 178.1 | num_updates 25000 | best_loss 1.419                                   
[2022-11-18 04:26:14,033][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 25000 updates
[2022-11-18 04:26:14,034][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_25000.pt
[2022-11-18 04:26:18,490][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_25000.pt
[2022-11-18 04:26:21,458][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_25000.pt (epoch 5 @ 25000 updates, score 1.673) (writing took 7.4243233148008585 seconds)
epoch 005:  57%|â–Œ| 3161/5551 [17:28:32<12:40:42, 19.10s/it, loss=1.069, ppl=2.1, wps=27070.1, ups=0.05, wpb=521836, bsz=8873.9, num_updates=25120, lr=0.000177798, gnorm=0.118, clip=92.5, loss_scale=4, train_wall[2022-11-18 05:05:53,399][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  58%|â–Œ| 3239/5551 [17:53:38<12:22:14, 19.26s/it, loss=1.069, ppl=2.1, wps=26424, ups=0.05, wpb=522522, bsz=8845.8, num_updates=25160, lr=0.000177431, gnorm=0.119, clip=87.5, loss_scale=2, train_wall=7[2022-11-18 05:30:58,141][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 05:31:00,199][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.722 | ppl 3.3 | wps 166059 | wpb 10521.6 | bsz 178.1 | num_updates 25200 | best_loss 1.419                                    
[2022-11-18 05:31:00,200][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 25200 updates
[2022-11-18 05:31:00,200][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_25200.pt
[2022-11-18 05:31:04,654][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_25200.pt
[2022-11-18 05:31:09,612][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_25200.pt (epoch 5 @ 25200 updates, score 1.722) (writing took 9.412491782568395 seconds)
epoch 005:  60%|â–Œ| 3316/5551 [18:18:33<11:57:29, 19.26s/it, loss=1.066, ppl=2.09, wps=26728.5, ups=0.05, wpb=522169, bsz=8525.1, num_updates=25240, lr=0.000176697, gnorm=0.123, clip=85, loss_scale=4, train_wall=[2022-11-18 05:55:53,235][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  62%|â–Œ| 3434/5551 [18:56:28<11:20:09, 19.28s/it, loss=1.069, ppl=2.1, wps=27195.9, ups=0.05, wpb=524120, bsz=8758.1, num_updates=25360, lr=0.000175596, gnorm=0.12, clip=75, loss_scale=2, train_wall=75[2022-11-18 06:33:48,570][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  62%|â–Œ| 3439/5551 [18:58:05<11:21:56, 19.37s/it, loss=1.069, ppl=2.1, wps=27195.9, ups=0.05, wpb=524120, bsz=8758.1, num_updates=25360, lr=0.000175596, gnorm=0.12, clip=75, loss_scale=2, train_wall=75[2022-11-18 06:35:25,673][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 005:  62%|â–Œ| 3440/5551 [18:58:24<11:24:10, 19.45s/it, loss=1.069, ppl=2.1, wps=27195.9, ups=0.05, wpb=524120, bsz=8758.1, num_updates=25360, lr=0.000175596, gnorm=0.12, clip=75, loss_scale=2, train_wall=75[2022-11-18 06:35:44,941][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 005:  62%|â–Œ| 3442/5551 [18:59:03<11:18:52, 19.31s/it, loss=1.069, ppl=2.1, wps=27195.9, ups=0.05, wpb=524120, bsz=8758.1, num_updates=25360, lr=0.000175596, gnorm=0.12, clip=75, loss_scale=2, train_wall=75[2022-11-18 06:36:23,496][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 005:  62%|â–Œ| 3443/5551 [18:59:22<11:19:44, 19.35s/it, loss=1.069, ppl=2.1, wps=27195.9, ups=0.05, wpb=524120, bsz=8758.1, num_updates=25360, lr=0.000175596, gnorm=0.12, clip=75, loss_scale=2, train_wall=75[2022-11-18 06:36:42,917][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 005:  62%|â–Œ| 3445/5551 [19:00:01<11:17:28, 19.30s/it, loss=1.069, ppl=2.1, wps=27195.9, ups=0.05, wpb=524120, bsz=8758.1, num_updates=25360, lr=0.000175596, gnorm=0.12, clip=75, loss_scale=2, train_wall=75[2022-11-18 06:37:21,542][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 06:37:23,581][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.62 | ppl 3.07 | wps 167460 | wpb 10521.6 | bsz 178.1 | num_updates 25400 | best_loss 1.419                                    
[2022-11-18 06:37:23,582][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 25400 updates
[2022-11-18 06:37:23,582][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_25400.pt
[2022-11-18 06:37:28,034][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_25400.pt
[2022-11-18 06:37:31,572][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_25400.pt (epoch 5 @ 25400 updates, score 1.62) (writing took 7.990341288037598 seconds)
epoch 005:  64%|â–‹| 3557/5551 [19:36:09<10:37:15, 19.18s/it, loss=1.068, ppl=2.1, wps=27020.7, ups=0.05, wpb=521372, bsz=9034.5, num_updates=25480, lr=0.000174495, gnorm=0.127, clip=87.5, loss_scale=0.125, train_[2022-11-18 07:13:29,525][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 005:  65%|â–‹| 3612/5551 [19:53:48<10:25:52, 19.37s/it, loss=1.075, ppl=2.11, wps=27130.1, ups=0.05, wpb=522806, bsz=8968.9, num_updates=25560, lr=0.000173761, gnorm=0.264, clip=100, loss_scale=0.125, train_[2022-11-18 07:31:08,759][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 005:  66%|â–‹| 3647/5551 [20:05:04<10:10:53, 19.25s/it, loss=1.075, ppl=2.11, wps=27130.1, ups=0.05, wpb=522806, bsz=8968.9, num_updates=25560, lr=0.000173761, gnorm=0.264, clip=100, loss_scale=0.125, train_[2022-11-18 07:42:24,435][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 07:42:26,525][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.646 | ppl 3.13 | wps 166222 | wpb 10521.6 | bsz 178.1 | num_updates 25600 | best_loss 1.419                                   
[2022-11-18 07:42:26,526][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 25600 updates
[2022-11-18 07:42:26,526][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_25600.pt
[2022-11-18 07:42:30,970][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_25600.pt
[2022-11-18 07:42:33,952][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_25600.pt (epoch 5 @ 25600 updates, score 1.646) (writing took 7.426209124736488 seconds)
epoch 005:  69%|â–‹| 3847/5551 [21:09:28<9:05:08, 19.20s/it, loss=1.066, ppl=2.09, wps=27089, ups=0.05, wpb=523036, bsz=8843.7, num_updates=25760, lr=0.000171927, gnorm=0.128, clip=87.5, loss_scale=0.25, train_wal[2022-11-18 08:46:48,277][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 08:46:50,349][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.751 | ppl 3.37 | wps 165802 | wpb 10521.6 | bsz 178.1 | num_updates 25800 | best_loss 1.419                                   
[2022-11-18 08:46:50,350][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 25800 updates
[2022-11-18 08:46:50,350][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_25800.pt
[2022-11-18 08:46:54,759][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_25800.pt
[2022-11-18 08:46:58,898][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_25800.pt (epoch 5 @ 25800 updates, score 1.751) (writing took 8.548069559969008 seconds)
epoch 005:  71%|â–‹| 3959/5551 [21:45:38<8:32:44, 19.32s/it, loss=1.068, ppl=2.1, wps=27116.2, ups=0.05, wpb=522691, bsz=8787.1, num_updates=25880, lr=0.000170826, gnorm=0.119, clip=87.5, loss_scale=0.5, train_wal[2022-11-18 09:22:59,226][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 005:  73%|â–‹| 4048/5551 [22:14:14<8:03:19, 19.29s/it, loss=1.064, ppl=2.09, wps=27107.4, ups=0.05, wpb=522335, bsz=8773, num_updates=25960, lr=0.000170092, gnorm=0.124, clip=90, loss_scale=0.5, train_wall=7[2022-11-18 09:51:34,022][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 09:51:36,083][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.725 | ppl 3.31 | wps 167071 | wpb 10521.6 | bsz 178.1 | num_updates 26000 | best_loss 1.419                                   
[2022-11-18 09:51:36,084][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 26000 updates
[2022-11-18 09:51:36,084][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_26000.pt
[2022-11-18 09:51:40,535][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_26000.pt
[2022-11-18 09:51:43,477][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_26000.pt (epoch 5 @ 26000 updates, score 1.725) (writing took 7.393555572256446 seconds)
epoch 005:  76%|â–Š| 4214/5551 [23:07:46<7:09:40, 19.28s/it, loss=1.064, ppl=2.09, wps=27174.6, ups=0.05, wpb=524303, bsz=8781.1, num_updates=26160, lr=0.000168257, gnorm=0.102, clip=50, loss_scale=2, train_wall=7[2022-11-18 10:45:06,512][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 005:  77%|â–Š| 4249/5551 [23:19:01<6:58:56, 19.31s/it, loss=1.064, ppl=2.09, wps=27174.6, ups=0.05, wpb=524303, bsz=8781.1, num_updates=26160, lr=0.000168257, gnorm=0.102, clip=50, loss_scale=2, train_wall=7[2022-11-18 10:56:22,066][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 10:56:24,124][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.621 | ppl 3.08 | wps 167145 | wpb 10521.6 | bsz 178.1 | num_updates 26200 | best_loss 1.419                                   
[2022-11-18 10:56:24,125][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 26200 updates
[2022-11-18 10:56:24,126][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_26200.pt
[2022-11-18 10:56:28,573][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_26200.pt
[2022-11-18 10:56:32,546][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_26200.pt (epoch 5 @ 26200 updates, score 1.621) (writing took 8.420832549221814 seconds)
epoch 005:  80%|â–Š| 4449/5551 [24:23:30<5:57:33, 19.47s/it, loss=1.063, ppl=2.09, wps=27099.4, ups=0.05, wpb=522852, bsz=8941.8, num_updates=26360, lr=0.000166422, gnorm=0.11, clip=62.5, loss_scale=4, train_wall=[2022-11-18 12:00:50,675][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 12:00:52,751][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.667 | ppl 3.17 | wps 165790 | wpb 10521.6 | bsz 178.1 | num_updates 26400 | best_loss 1.419                                   
[2022-11-18 12:00:52,752][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 26400 updates
[2022-11-18 12:00:52,752][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_26400.pt
[2022-11-18 12:00:57,218][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_26400.pt
[2022-11-18 12:01:00,085][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_26400.pt (epoch 5 @ 26400 updates, score 1.667) (writing took 7.332714129239321 seconds)
epoch 005:  80%|â–Š| 4453/5551 [24:24:57<6:11:25, 20.30s/it, loss=1.065, ppl=2.09, wps=27057.6, ups=0.05, wpb=522486, bsz=9016.7, num_updates=26400, lr=0.000166055, gnorm=0.109, clip=80, loss_scale=4, train_wall=7[2022-11-18 12:02:17,355][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  82%|â–Š| 4553/5551 [24:57:11<5:20:16, 19.26s/it, loss=1.063, ppl=2.09, wps=27019.7, ups=0.05, wpb=522947, bsz=8631.8, num_updates=26480, lr=0.000165321, gnorm=0.109, clip=62.5, loss_scale=2, train_wall[2022-11-18 12:34:31,224][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  83%|â–Š| 4593/5551 [25:10:05<5:08:33, 19.32s/it, loss=1.063, ppl=2.09, wps=26431.4, ups=0.05, wpb=523482, bsz=8846.3, num_updates=26520, lr=0.000164954, gnorm=0.109, clip=67.5, loss_scale=2, train_wall[2022-11-18 12:47:25,194][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 005:  84%|â–Š| 4652/5551 [25:29:05<4:50:29, 19.39s/it, loss=1.063, ppl=2.09, wps=26415.6, ups=0.05, wpb=523935, bsz=8884.6, num_updates=26560, lr=0.000164587, gnorm=0.11, clip=65, loss_scale=1, train_wall=77[2022-11-18 13:06:25,687][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 13:06:27,764][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.68 | ppl 3.2 | wps 165554 | wpb 10521.6 | bsz 178.1 | num_updates 26600 | best_loss 1.419                                     
[2022-11-18 13:06:27,765][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 26600 updates
[2022-11-18 13:06:27,765][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_26600.pt
[2022-11-18 13:06:32,206][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_26600.pt
[2022-11-18 13:06:37,900][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_26600.pt (epoch 5 @ 26600 updates, score 1.68) (writing took 10.135383101180196 seconds)
epoch 005:  85%|â–Š| 4718/5551 [25:50:29<4:28:03, 19.31s/it, loss=1.063, ppl=2.09, wps=26670, ups=0.05, wpb=522131, bsz=8570.1, num_updates=26640, lr=0.000163853, gnorm=0.112, clip=77.5, loss_scale=2, train_wall=7[2022-11-18 13:27:50,293][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 005:  87%|â–Š| 4853/5551 [26:33:52<3:44:33, 19.30s/it, loss=1.06, ppl=2.09, wps=27108.9, ups=0.05, wpb=522859, bsz=8712.4, num_updates=26760, lr=0.000162752, gnorm=0.11, clip=62.5, loss_scale=2, train_wall=7[2022-11-18 14:11:12,431][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 14:11:14,510][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.765 | ppl 3.4 | wps 165881 | wpb 10521.6 | bsz 178.1 | num_updates 26800 | best_loss 1.419                                    
[2022-11-18 14:11:14,511][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 26800 updates
[2022-11-18 14:11:14,511][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_26800.pt
[2022-11-18 14:11:18,966][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_26800.pt
[2022-11-18 14:11:22,040][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_26800.pt (epoch 5 @ 26800 updates, score 1.765) (writing took 7.528739707544446 seconds)
epoch 005:  90%|â–‰| 5017/5551 [27:26:48<2:50:36, 19.17s/it, loss=1.061, ppl=2.09, wps=27124.1, ups=0.05, wpb=523113, bsz=8557.9, num_updates=26960, lr=0.000160917, gnorm=0.105, clip=55, loss_scale=8, train_wall=7[2022-11-18 15:04:08,276][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 005:  91%|â–‰| 5054/5551 [27:38:42<2:38:56, 19.19s/it, loss=1.061, ppl=2.09, wps=27124.1, ups=0.05, wpb=523113, bsz=8557.9, num_updates=26960, lr=0.000160917, gnorm=0.105, clip=55, loss_scale=8, train_wall=7[2022-11-18 15:16:02,589][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 15:16:04,654][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.592 | ppl 3.02 | wps 165959 | wpb 10521.6 | bsz 178.1 | num_updates 27000 | best_loss 1.419                                   
[2022-11-18 15:16:04,654][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 27000 updates
[2022-11-18 15:16:04,655][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_27000.pt
[2022-11-18 15:16:09,107][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_27000.pt
[2022-11-18 15:16:12,262][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_27000.pt (epoch 5 @ 27000 updates, score 1.592) (writing took 7.607456658966839 seconds)
epoch 005:  92%|â–‰| 5082/5551 [27:47:52<2:31:33, 19.39s/it, loss=1.061, ppl=2.09, wps=26370, ups=0.05, wpb=521408, bsz=8672.1, num_updates=27000, lr=0.00016055, gnorm=0.103, clip=42.5, loss_scale=4, train_wall=77[2022-11-18 15:25:12,467][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  94%|â–‰| 5208/5551 [28:28:21<1:49:49, 19.21s/it, loss=1.06, ppl=2.09, wps=27131.1, ups=0.05, wpb=522728, bsz=8555.6, num_updates=27120, lr=0.00015945, gnorm=0.11, clip=92.5, loss_scale=4, train_wall=75[2022-11-18 16:05:42,156][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  95%|â–‰| 5256/5551 [28:43:48<1:34:59, 19.32s/it, loss=1.06, ppl=2.09, wps=26469.9, ups=0.05, wpb=522385, bsz=8800.9, num_updates=27160, lr=0.000159083, gnorm=0.106, clip=65, loss_scale=2, train_wall=77[2022-11-18 16:21:08,180][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 16:21:10,243][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.65 | ppl 3.14 | wps 167598 | wpb 10521.6 | bsz 178.1 | num_updates 27200 | best_loss 1.419                                    
[2022-11-18 16:21:10,243][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 27200 updates
[2022-11-18 16:21:10,244][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_27200.pt
[2022-11-18 16:21:14,698][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_27200.pt
[2022-11-18 16:21:19,791][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_27200.pt (epoch 5 @ 27200 updates, score 1.65) (writing took 9.547381921671331 seconds)
epoch 005:  95%|â–‰| 5300/5551 [28:58:09<1:21:20, 19.45s/it, loss=1.059, ppl=2.08, wps=26729.7, ups=0.05, wpb=524041, bsz=8767.8, num_updates=27240, lr=0.000158349, gnorm=0.116, clip=72.5, loss_scale=4, train_wall[2022-11-18 16:35:30,107][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 005:  96%|â–‰| 5303/5551 [28:59:07<1:20:07, 19.39s/it, loss=1.059, ppl=2.08, wps=26729.7, ups=0.05, wpb=524041, bsz=8767.8, num_updates=27240, lr=0.000158349, gnorm=0.116, clip=72.5, loss_scale=4, train_wall[2022-11-18 16:36:28,060][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 005:  96%|â–‰| 5306/5551 [29:00:05<1:18:36, 19.25s/it, loss=1.059, ppl=2.08, wps=26729.7, ups=0.05, wpb=524041, bsz=8767.8, num_updates=27240, lr=0.000158349, gnorm=0.116, clip=72.5, loss_scale=4, train_wall[2022-11-18 16:37:25,696][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 005:  98%|â–‰| 5459/5551 [29:49:15<29:29, 19.24s/it, loss=1.061, ppl=2.09, wps=27099.1, ups=0.05, wpb=522842, bsz=8755.3, num_updates=27360, lr=0.000157248, gnorm=0.125, clip=77.5, loss_scale=1, train_wall=7[2022-11-18 17:26:35,859][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 17:26:37,932][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.76 | ppl 3.39 | wps 166566 | wpb 10521.6 | bsz 178.1 | num_updates 27400 | best_loss 1.419                                    
[2022-11-18 17:26:37,933][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 27400 updates
[2022-11-18 17:26:37,933][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_27400.pt
[2022-11-18 17:26:42,394][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_5_27400.pt
[2022-11-18 17:26:45,750][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_5_27400.pt (epoch 5 @ 27400 updates, score 1.76) (writing took 7.8171948324888945 seconds)
epoch 005: 100%|â–‰| 5550/5551 [30:18:44<00:19, 19.24s/it, loss=1.059, ppl=2.08, wps=27067, ups=0.05, wpb=522920, bsz=8627, num_updates=27480, lr=0.000156147, gnorm=0.108, clip=60, loss_scale=2, train_wall=758, gb[2022-11-18 17:56:02,003][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 17:56:04,029][valid][INFO] - epoch 005 | valid on 'valid' subset | loss 1.599 | ppl 3.03 | wps 168222 | wpb 10521.6 | bsz 178.1 | num_updates 27491 | best_loss 1.419                                   
[2022-11-18 17:56:04,029][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 27491 updates
[2022-11-18 17:56:04,030][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint5.pt
[2022-11-18 17:56:08,502][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint5.pt
[2022-11-18 17:56:12,553][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint5.pt (epoch 5 @ 27491 updates, score 1.599) (writing took 8.523745028302073 seconds)
[2022-11-18 17:56:12,554][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)                                                                                                                    
[2022-11-18 17:56:12,556][train][INFO] - epoch 005 | loss 1.071 | ppl 2.1 | wps 26347.9 | ups 0.05 | wpb 522612 | bsz 8745.2 | num_updates 27491 | lr 0.000156046 | gnorm 0.135 | clip 82.4 | loss_scale 2 | train_wall 106421 | gb_free 6.6 | wall 538339
[2022-11-18 17:56:13,056][fairseq.data.iterators][INFO] - grouped total_num_itrs = 5551
epoch 006:   0%|                                                                                                                                                                          | 0/5551 [00:00<?, ?it/s][2022-11-18 17:56:13,629][fairseq.trainer][INFO] - begin training epoch 6
[2022-11-18 17:56:13,629][fairseq_cli.train][INFO] - Start iterating over samples
epoch 006:   0%|â–Œ                                                                                                                                                             | 18/5551 [05:48<29:38:18, 19.28s/it][2022-11-18 18:02:21,543][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:   1%| | 34/5551 [10:58<29:31:33, 19.27s/it, loss=1.058, ppl=2.08, wps=25709.5, ups=0.05, wpb=515268, bsz=9028.6, num_updates=27520, lr=0.00015578, gnorm=0.131, clip=80, loss_scale=2, train_wall=774, g[2022-11-18 18:07:30,967][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 006:   2%| | 110/5551 [35:23<28:58:27, 19.17s/it, loss=1.057, ppl=2.08, wps=26412.6, ups=0.05, wpb=522941, bsz=8883.2, num_updates=27560, lr=0.000155413, gnorm=0.112, clip=80, loss_scale=1, train_wall=776,[2022-11-18 18:31:56,762][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 18:31:58,789][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.52 | ppl 2.87 | wps 166587 | wpb 10521.6 | bsz 178.1 | num_updates 27600 | best_loss 1.419                                    
[2022-11-18 18:31:58,790][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 27600 updates
[2022-11-18 18:31:58,790][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_27600.pt
[2022-11-18 18:32:03,361][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_27600.pt
[2022-11-18 18:32:06,149][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_27600.pt (epoch 6 @ 27600 updates, score 1.52) (writing took 7.359273976646364 seconds)
epoch 006:   2%| | 118/5551 [38:08<29:29:01, 19.54s/it, loss=1.055, ppl=2.08, wps=27153.1, ups=0.05, wpb=522857, bsz=8660.8, num_updates=27600, lr=0.000155046, gnorm=0.127, clip=85, loss_scale=1, train_wall=755,[2022-11-18 18:34:40,983][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 006:   4%| | 220/5551 [1:10:52<28:32:44, 19.28s/it, loss=1.055, ppl=2.08, wps=27076.6, ups=0.05, wpb=522298, bsz=8622.5, num_updates=27680, lr=0.000154312, gnorm=0.115, clip=70, loss_scale=0.5, train_wall=[2022-11-18 19:07:25,341][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 006:   4%| | 222/5551 [1:11:31<28:32:11, 19.28s/it, loss=1.055, ppl=2.08, wps=27076.6, ups=0.05, wpb=522298, bsz=8622.5, num_updates=27680, lr=0.000154312, gnorm=0.115, clip=70, loss_scale=0.5, train_wall=[2022-11-18 19:08:03,944][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 006:   4%| | 223/5551 [1:11:50<28:32:35, 19.29s/it, loss=1.055, ppl=2.08, wps=27076.6, ups=0.05, wpb=522298, bsz=8622.5, num_updates=27680, lr=0.000154312, gnorm=0.115, clip=70, loss_scale=0.5, train_wall=[2022-11-18 19:08:23,071][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
epoch 006:   4%| | 224/5551 [1:12:09<28:28:02, 19.24s/it, loss=1.055, ppl=2.08, wps=27076.6, ups=0.05, wpb=522298, bsz=8622.5, num_updates=27680, lr=0.000154312, gnorm=0.115, clip=70, loss_scale=0.5, train_wall=[2022-11-18 19:08:42,243][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
epoch 006:   4%| | 226/5551 [1:12:47<28:22:18, 19.18s/it, loss=1.055, ppl=2.08, wps=27076.6, ups=0.05, wpb=522298, bsz=8622.5, num_updates=27680, lr=0.000154312, gnorm=0.115, clip=70, loss_scale=0.5, train_wall=[2022-11-18 19:09:20,693][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
epoch 006:   6%| | 316/5551 [1:41:41<27:58:22, 19.24s/it, loss=1.054, ppl=2.08, wps=27134.4, ups=0.05, wpb=523213, bsz=8556.2, num_updates=27760, lr=0.000153578, gnorm=0.113, clip=80, loss_scale=0.0312, train_wa[2022-11-18 19:38:14,798][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 19:38:16,809][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.786 | ppl 3.45 | wps 167424 | wpb 10521.6 | bsz 178.1 | num_updates 27800 | best_loss 1.419                                   
[2022-11-18 19:38:16,810][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 27800 updates
[2022-11-18 19:38:16,810][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_27800.pt
[2022-11-18 19:38:21,305][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_27800.pt
[2022-11-18 19:38:25,429][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_27800.pt (epoch 6 @ 27800 updates, score 1.786) (writing took 8.618815057910979 seconds)
epoch 006:   9%| | 516/5551 [2:46:08<26:55:16, 19.25s/it, loss=1.055, ppl=2.08, wps=27108.1, ups=0.05, wpb=522772, bsz=8899, num_updates=27960, lr=0.000151743, gnorm=0.11, clip=77.5, loss_scale=0.125, train_wall[2022-11-18 20:42:41,948][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 20:42:43,975][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.814 | ppl 3.52 | wps 167406 | wpb 10521.6 | bsz 178.1 | num_updates 28000 | best_loss 1.419                                   
[2022-11-18 20:42:43,976][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 28000 updates
[2022-11-18 20:42:43,976][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_28000.pt
[2022-11-18 20:42:48,427][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_28000.pt
[2022-11-18 20:42:53,194][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_28000.pt (epoch 6 @ 28000 updates, score 1.814) (writing took 9.217647779732943 seconds)
epoch 006:  10%| | 567/5551 [3:02:45<26:40:48, 19.27s/it, loss=1.054, ppl=2.08, wps=26659.9, ups=0.05, wpb=523010, bsz=8811.8, num_updates=28040, lr=0.000151009, gnorm=0.108, clip=72.5, loss_scale=0.25, train_wa[2022-11-18 20:59:18,264][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 006:  12%| | 679/5551 [3:38:43<26:18:14, 19.44s/it, loss=1.054, ppl=2.08, wps=27107, ups=0.05, wpb=523016, bsz=8653, num_updates=28160, lr=0.000149908, gnorm=0.117, clip=82.5, loss_scale=0.5, train_wall=75[2022-11-18 21:35:17,423][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 006:  13%|â–| 718/5551 [3:51:17<25:54:09, 19.29s/it, loss=1.054, ppl=2.08, wps=27107, ups=0.05, wpb=523016, bsz=8653, num_updates=28160, lr=0.000149908, gnorm=0.117, clip=82.5, loss_scale=0.5, train_wall=75[2022-11-18 21:47:50,517][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 21:47:52,531][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.728 | ppl 3.31 | wps 167968 | wpb 10521.6 | bsz 178.1 | num_updates 28200 | best_loss 1.419                                   
[2022-11-18 21:47:52,531][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 28200 updates
[2022-11-18 21:47:52,532][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_28200.pt
[2022-11-18 21:47:56,985][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_28200.pt
[2022-11-18 21:48:01,848][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_28200.pt (epoch 6 @ 28200 updates, score 1.728) (writing took 9.317053262144327 seconds)
epoch 006:  17%|â–| 918/5551 [4:55:46<24:44:29, 19.23s/it, loss=1.051, ppl=2.07, wps=27177.4, ups=0.05, wpb=524537, bsz=8894.5, num_updates=28360, lr=0.000148073, gnorm=0.11, clip=72.5, loss_scale=1, train_wall=7[2022-11-18 22:52:19,138][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 22:52:21,179][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.714 | ppl 3.28 | wps 165389 | wpb 10521.6 | bsz 178.1 | num_updates 28400 | best_loss 1.419                                   
[2022-11-18 22:52:21,180][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 28400 updates
[2022-11-18 22:52:21,180][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_28400.pt
[2022-11-18 22:52:25,587][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_28400.pt
[2022-11-18 22:52:28,331][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_28400.pt (epoch 6 @ 28400 updates, score 1.714) (writing took 7.150684087537229 seconds)
epoch 006:  17%|â–| 935/5551 [5:01:22<24:44:07, 19.29s/it, loss=1.053, ppl=2.07, wps=27132.3, ups=0.05, wpb=523034, bsz=8765.1, num_updates=28400, lr=0.000147706, gnorm=0.109, clip=67.5, loss_scale=1, train_wall=[2022-11-18 22:57:55,895][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 006:  17%|â–| 953/5551 [5:07:11<24:46:48, 19.40s/it, loss=1.053, ppl=2.07, wps=27132.3, ups=0.05, wpb=523034, bsz=8765.1, num_updates=28400, lr=0.000147706, gnorm=0.109, clip=67.5, loss_scale=1, train_wall=[2022-11-18 23:03:44,057][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 006:  20%|â–| 1120/5551 [6:00:51<23:37:52, 19.20s/it, loss=1.052, ppl=2.07, wps=27145, ups=0.05, wpb=524108, bsz=8911.5, num_updates=28560, lr=0.000146239, gnorm=0.112, clip=72.5, loss_scale=1, train_wall=7[2022-11-18 23:57:24,650][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-18 23:57:26,667][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.6 | ppl 3.03 | wps 166802 | wpb 10521.6 | bsz 178.1 | num_updates 28600 | best_loss 1.419                                     
[2022-11-18 23:57:26,668][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 28600 updates
[2022-11-18 23:57:26,668][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_28600.pt
[2022-11-18 23:57:31,124][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_28600.pt
[2022-11-18 23:57:34,124][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_28600.pt (epoch 6 @ 28600 updates, score 1.6) (writing took 7.456399594433606 seconds)
epoch 006:  22%|â–| 1227/5551 [6:35:24<23:07:43, 19.26s/it, loss=1.052, ppl=2.07, wps=27060, ups=0.05, wpb=522486, bsz=8545.1, num_updates=28680, lr=0.000145138, gnorm=0.115, clip=77.5, loss_scale=2, train_wall=7[2022-11-19 00:31:57,176][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  24%|â–| 1321/5551 [7:05:37<22:38:53, 19.27s/it, loss=1.051, ppl=2.07, wps=27150, ups=0.05, wpb=524195, bsz=8760.7, num_updates=28760, lr=0.000144404, gnorm=0.102, clip=37.5, loss_scale=2, train_wall=7[2022-11-19 01:02:09,731][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 01:02:11,767][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.617 | ppl 3.07 | wps 165823 | wpb 10521.6 | bsz 178.1 | num_updates 28800 | best_loss 1.419                                   
[2022-11-19 01:02:11,768][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 28800 updates
[2022-11-19 01:02:11,768][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_28800.pt
[2022-11-19 01:02:16,225][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_28800.pt
[2022-11-19 01:02:19,676][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_28800.pt (epoch 6 @ 28800 updates, score 1.617) (writing took 7.907804544083774 seconds)
epoch 006:  25%|â–Ž| 1390/5551 [7:27:57<22:14:33, 19.24s/it, loss=1.051, ppl=2.07, wps=26678.6, ups=0.05, wpb=522237, bsz=8783.6, num_updates=28840, lr=0.00014367, gnorm=0.108, clip=65, loss_scale=4, train_wall=75[2022-11-19 01:24:30,865][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  27%|â–Ž| 1522/5551 [8:10:22<21:43:54, 19.42s/it, loss=1.049, ppl=2.07, wps=27097.7, ups=0.05, wpb=522455, bsz=8591.4, num_updates=28960, lr=0.000142569, gnorm=0.108, clip=60, loss_scale=4, train_wall=7[2022-11-19 02:06:54,980][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 02:06:57,011][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.583 | ppl 3 | wps 166827 | wpb 10521.6 | bsz 178.1 | num_updates 29000 | best_loss 1.419                                      
[2022-11-19 02:06:57,012][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 29000 updates
[2022-11-19 02:06:57,012][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_29000.pt
[2022-11-19 02:07:01,481][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_29000.pt
[2022-11-19 02:07:04,500][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_29000.pt (epoch 6 @ 29000 updates, score 1.583) (writing took 7.488525825552642 seconds)
epoch 006:  28%|â–Ž| 1573/5551 [8:26:56<21:19:47, 19.30s/it, loss=1.05, ppl=2.07, wps=26739.7, ups=0.05, wpb=522251, bsz=8780.7, num_updates=29040, lr=0.000141835, gnorm=0.111, clip=67.5, loss_scale=8, train_wall=[2022-11-19 02:23:28,883][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  30%|â–Ž| 1679/5551 [9:01:00<20:41:36, 19.24s/it, loss=1.05, ppl=2.07, wps=27190.4, ups=0.05, wpb=523975, bsz=8707.8, num_updates=29120, lr=0.000141101, gnorm=0.106, clip=75, loss_scale=4, train_wall=75[2022-11-19 02:57:32,849][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  31%|â–Ž| 1724/5551 [9:15:28<20:29:09, 19.27s/it, loss=1.051, ppl=2.07, wps=26436.2, ups=0.05, wpb=523057, bsz=8817.4, num_updates=29160, lr=0.000140734, gnorm=0.108, clip=67.5, loss_scale=4, train_wall[2022-11-19 03:12:01,730][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 03:12:03,751][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.686 | ppl 3.22 | wps 167060 | wpb 10521.6 | bsz 178.1 | num_updates 29200 | best_loss 1.419                                   
[2022-11-19 03:12:03,752][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 29200 updates
[2022-11-19 03:12:03,753][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_29200.pt
[2022-11-19 03:12:08,267][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_29200.pt
[2022-11-19 03:12:11,695][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_29200.pt (epoch 6 @ 29200 updates, score 1.686) (writing took 7.943200350739062 seconds)
epoch 006:  31%|â–Ž| 1735/5551 [9:19:12<20:35:17, 19.42s/it, loss=1.051, ppl=2.07, wps=27115.7, ups=0.05, wpb=523642, bsz=8771.6, num_updates=29200, lr=0.000140367, gnorm=0.112, clip=70, loss_scale=4, train_wall=7[2022-11-19 03:15:45,622][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  33%|â–Ž| 1857/5551 [9:58:24<19:49:30, 19.32s/it, loss=1.048, ppl=2.07, wps=27115.3, ups=0.05, wpb=522595, bsz=8706.2, num_updates=29320, lr=0.000139266, gnorm=0.099, clip=32.5, loss_scale=4, train_wall[2022-11-19 03:54:57,092][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  35%|â–Ž| 1926/5551 [10:20:35<19:23:57, 19.27s/it, loss=1.05, ppl=2.07, wps=26419.7, ups=0.05, wpb=522247, bsz=8818.6, num_updates=29360, lr=0.000138899, gnorm=0.098, clip=35, loss_scale=2, train_wall=7[2022-11-19 04:17:08,782][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 04:17:10,798][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.788 | ppl 3.45 | wps 166756 | wpb 10521.6 | bsz 178.1 | num_updates 29400 | best_loss 1.419                                   
[2022-11-19 04:17:10,798][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 29400 updates
[2022-11-19 04:17:10,799][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_29400.pt
[2022-11-19 04:17:15,250][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_29400.pt
[2022-11-19 04:17:19,612][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_29400.pt (epoch 6 @ 29400 updates, score 1.788) (writing took 8.813376327045262 seconds)
epoch 006:  35%|â–Ž| 1950/5551 [10:28:28<19:13:03, 19.21s/it, loss=1.052, ppl=2.07, wps=27143.6, ups=0.05, wpb=524307, bsz=8843.6, num_updates=29400, lr=0.000138532, gnorm=0.104, clip=52.5, loss_scale=2, train_wal[2022-11-19 04:25:01,647][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  35%|â–Ž| 1951/5551 [10:28:48<19:16:40, 19.28s/it, loss=1.052, ppl=2.07, wps=27143.6, ups=0.05, wpb=524307, bsz=8843.6, num_updates=29400, lr=0.000138532, gnorm=0.104, clip=52.5, loss_scale=2, train_wal[2022-11-19 04:25:20,909][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 006:  38%|â–| 2128/5551 [11:25:39<18:23:14, 19.34s/it, loss=1.049, ppl=2.07, wps=27087.6, ups=0.05, wpb=522376, bsz=8817.2, num_updates=29560, lr=0.000137064, gnorm=0.107, clip=62.5, loss_scale=2, train_wal[2022-11-19 05:22:12,750][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 05:22:14,775][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.678 | ppl 3.2 | wps 166728 | wpb 10521.6 | bsz 178.1 | num_updates 29600 | best_loss 1.419                                    
[2022-11-19 05:22:14,775][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 29600 updates
[2022-11-19 05:22:14,776][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_29600.pt
[2022-11-19 05:22:19,233][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_29600.pt
[2022-11-19 05:22:22,185][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_29600.pt (epoch 6 @ 29600 updates, score 1.678) (writing took 7.409706647507846 seconds)
epoch 006:  40%|â–| 2233/5551 [11:59:35<17:46:52, 19.29s/it, loss=1.049, ppl=2.07, wps=27092.3, ups=0.05, wpb=524150, bsz=8894.2, num_updates=29680, lr=0.000135963, gnorm=0.103, clip=42.5, loss_scale=8, train_wal[2022-11-19 05:56:08,250][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  41%|â–| 2285/5551 [12:16:17<17:29:47, 19.29s/it, loss=1.047, ppl=2.07, wps=26441.4, ups=0.05, wpb=521664, bsz=8123.8, num_updates=29720, lr=0.000135596, gnorm=0.116, clip=82.5, loss_scale=4, train_wal[2022-11-19 06:12:50,553][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  42%|â–| 2330/5551 [12:30:45<17:07:21, 19.14s/it, loss=1.048, ppl=2.07, wps=26423, ups=0.05, wpb=522694, bsz=8686.9, num_updates=29760, lr=0.000135229, gnorm=0.103, clip=55, loss_scale=2, train_wall=77[2022-11-19 06:27:18,361][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 06:27:20,385][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.682 | ppl 3.21 | wps 167003 | wpb 10521.6 | bsz 178.1 | num_updates 29800 | best_loss 1.419                                   
[2022-11-19 06:27:20,386][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 29800 updates
[2022-11-19 06:27:20,387][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_29800.pt
[2022-11-19 06:27:24,833][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_29800.pt
[2022-11-19 06:27:27,819][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_29800.pt (epoch 6 @ 29800 updates, score 1.682) (writing took 7.43319380376488 seconds)
epoch 006:  45%|â–| 2473/5551 [13:16:52<16:27:46, 19.25s/it, loss=1.047, ppl=2.07, wps=27128.5, ups=0.05, wpb=522994, bsz=8928.8, num_updates=29920, lr=0.000133761, gnorm=0.108, clip=55, loss_scale=4, train_wall=[2022-11-19 07:13:25,242][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  46%|â–| 2531/5551 [13:35:31<16:06:08, 19.19s/it, loss=1.048, ppl=2.07, wps=26498.6, ups=0.05, wpb=523954, bsz=8943, num_updates=29960, lr=0.000133394, gnorm=0.099, clip=35, loss_scale=4, train_wall=77[2022-11-19 07:32:03,975][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 07:32:06,020][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.543 | ppl 2.91 | wps 166268 | wpb 10521.6 | bsz 178.1 | num_updates 30000 | best_loss 1.419                                   
[2022-11-19 07:32:06,021][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 30000 updates
[2022-11-19 07:32:06,021][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_30000.pt
[2022-11-19 07:32:10,486][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_30000.pt
[2022-11-19 07:32:13,404][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_30000.pt (epoch 6 @ 30000 updates, score 1.543) (writing took 7.383262787014246 seconds)
epoch 006:  47%|â–| 2585/5551 [13:53:00<15:50:09, 19.22s/it, loss=1.047, ppl=2.07, wps=26782.1, ups=0.05, wpb=522520, bsz=8723.8, num_updates=30040, lr=0.000132661, gnorm=0.107, clip=60, loss_scale=8, train_wall=[2022-11-19 07:49:33,622][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  49%|â–| 2707/5551 [14:32:11<15:15:36, 19.32s/it, loss=1.049, ppl=2.07, wps=27132.3, ups=0.05, wpb=523131, bsz=8637, num_updates=30160, lr=0.00013156, gnorm=0.105, clip=50, loss_scale=8, train_wall=756[2022-11-19 08:28:45,148][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  49%|â–| 2733/5551 [14:40:33<15:02:51, 19.22s/it, loss=1.049, ppl=2.07, wps=27132.3, ups=0.05, wpb=523131, bsz=8637, num_updates=30160, lr=0.00013156, gnorm=0.105, clip=50, loss_scale=8, train_wall=756[2022-11-19 08:37:06,428][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 08:37:08,471][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.65 | ppl 3.14 | wps 166542 | wpb 10521.6 | bsz 178.1 | num_updates 30200 | best_loss 1.419                                    
[2022-11-19 08:37:08,472][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 30200 updates
[2022-11-19 08:37:08,472][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_30200.pt
[2022-11-19 08:37:12,925][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_30200.pt
[2022-11-19 08:37:15,663][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_30200.pt (epoch 6 @ 30200 updates, score 1.65) (writing took 7.191146783530712 seconds)
epoch 006:  50%|â–Œ| 2790/5551 [14:59:01<14:43:59, 19.21s/it, loss=1.047, ppl=2.07, wps=26730.6, ups=0.05, wpb=522521, bsz=9016, num_updates=30240, lr=0.000130826, gnorm=0.103, clip=57.5, loss_scale=4, train_wall=[2022-11-19 08:55:34,630][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  53%|â–Œ| 2934/5551 [15:45:18<13:59:46, 19.25s/it, loss=1.046, ppl=2.07, wps=27048.8, ups=0.05, wpb=521923, bsz=8861.3, num_updates=30360, lr=0.000129725, gnorm=0.108, clip=50, loss_scale=4, train_wall=[2022-11-19 09:41:51,157][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 09:41:53,171][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.68 | ppl 3.21 | wps 167409 | wpb 10521.6 | bsz 178.1 | num_updates 30400 | best_loss 1.419                                    
[2022-11-19 09:41:53,172][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 30400 updates
[2022-11-19 09:41:53,172][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_30400.pt
[2022-11-19 09:41:57,624][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_30400.pt
[2022-11-19 09:42:00,527][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_30400.pt (epoch 6 @ 30400 updates, score 1.68) (writing took 7.355464898049831 seconds)
epoch 006:  54%|â–Œ| 2999/5551 [16:06:20<13:39:33, 19.27s/it, loss=1.047, ppl=2.07, wps=26792.6, ups=0.05, wpb=522824, bsz=8857.1, num_updates=30440, lr=0.000128991, gnorm=0.108, clip=60, loss_scale=8, train_wall=[2022-11-19 10:02:53,298][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  55%|â–Œ| 3046/5551 [16:21:25<13:21:34, 19.20s/it, loss=1.043, ppl=2.06, wps=26438.4, ups=0.05, wpb=521987, bsz=8492.9, num_updates=30480, lr=0.000128624, gnorm=0.109, clip=57.5, loss_scale=4, train_wal[2022-11-19 10:17:57,937][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  56%|â–Œ| 3136/5551 [16:50:22<12:58:26, 19.34s/it, loss=1.046, ppl=2.07, wps=27086.5, ups=0.05, wpb=523485, bsz=8974.4, num_updates=30560, lr=0.00012789, gnorm=0.102, clip=42.5, loss_scale=2, train_wall[2022-11-19 10:46:55,112][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 10:46:57,119][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.753 | ppl 3.37 | wps 168016 | wpb 10521.6 | bsz 178.1 | num_updates 30600 | best_loss 1.419                                   
[2022-11-19 10:46:57,120][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 30600 updates
[2022-11-19 10:46:57,121][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_30600.pt
[2022-11-19 10:47:01,563][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_30600.pt
[2022-11-19 10:47:04,462][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_30600.pt (epoch 6 @ 30600 updates, score 1.753) (writing took 7.341566831804812 seconds)
epoch 006:  59%|â–Œ| 3274/5551 [17:34:50<12:12:04, 19.29s/it, loss=1.044, ppl=2.06, wps=27108.4, ups=0.05, wpb=521461, bsz=8728.6, num_updates=30720, lr=0.000126422, gnorm=0.114, clip=52.5, loss_scale=8, train_wal[2022-11-19 11:31:23,687][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  60%|â–Œ| 3337/5551 [17:55:05<11:50:57, 19.27s/it, loss=1.048, ppl=2.07, wps=26413.2, ups=0.05, wpb=522376, bsz=8867.8, num_updates=30760, lr=0.000126055, gnorm=0.106, clip=62.5, loss_scale=4, train_wal[2022-11-19 11:51:38,263][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 11:51:40,278][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.662 | ppl 3.16 | wps 167758 | wpb 10521.6 | bsz 178.1 | num_updates 30800 | best_loss 1.419                                   
[2022-11-19 11:51:40,278][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 30800 updates
[2022-11-19 11:51:40,279][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_30800.pt
[2022-11-19 11:51:44,737][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_30800.pt
[2022-11-19 11:51:48,258][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_30800.pt (epoch 6 @ 30800 updates, score 1.662) (writing took 7.979835138656199 seconds)
epoch 006:  61%|â–Œ| 3362/5551 [18:03:17<11:42:54, 19.27s/it, loss=1.044, ppl=2.06, wps=27069.2, ups=0.05, wpb=521534, bsz=8355.4, num_updates=30800, lr=0.000125688, gnorm=0.105, clip=45, loss_scale=4, train_wall=[2022-11-19 11:59:50,090][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  64%|â–‹| 3536/5551 [18:59:14<10:49:26, 19.34s/it, loss=1.044, ppl=2.06, wps=27104.8, ups=0.05, wpb=523107, bsz=8564, num_updates=30960, lr=0.00012422, gnorm=0.104, clip=52.5, loss_scale=8, train_wall=7[2022-11-19 12:55:47,028][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 006:  64%|â–‹| 3539/5551 [19:00:12<10:48:52, 19.35s/it, loss=1.044, ppl=2.06, wps=27104.8, ups=0.05, wpb=523107, bsz=8564, num_updates=30960, lr=0.00012422, gnorm=0.104, clip=52.5, loss_scale=8, train_wall=7[2022-11-19 12:56:44,900][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 12:56:46,920][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.646 | ppl 3.13 | wps 167217 | wpb 10521.6 | bsz 178.1 | num_updates 31000 | best_loss 1.419                                   
[2022-11-19 12:56:46,921][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 31000 updates
[2022-11-19 12:56:46,921][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_31000.pt
[2022-11-19 12:56:51,370][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_31000.pt
[2022-11-19 12:56:54,361][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_31000.pt (epoch 6 @ 31000 updates, score 1.646) (writing took 7.439962326548994 seconds)
epoch 006:  64%|â–‹| 3543/5551 [19:01:38<11:14:19, 20.15s/it, loss=1.044, ppl=2.06, wps=26491.8, ups=0.05, wpb=523902, bsz=8668.5, num_updates=31000, lr=0.000123853, gnorm=0.102, clip=45, loss_scale=8, train_wall=[2022-11-19 12:58:10,840][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  64%|â–‹| 3573/5551 [19:11:17<10:37:13, 19.33s/it, loss=1.044, ppl=2.06, wps=26491.8, ups=0.05, wpb=523902, bsz=8668.5, num_updates=31000, lr=0.000123853, gnorm=0.102, clip=45, loss_scale=8, train_wall=[2022-11-19 13:07:50,492][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  67%|â–‹| 3716/5551 [19:57:13<9:48:47, 19.25s/it, loss=1.044, ppl=2.06, wps=27141.1, ups=0.05, wpb=522473, bsz=8542.1, num_updates=31160, lr=0.000122385, gnorm=0.109, clip=62.5, loss_scale=4, train_wall[2022-11-19 13:53:46,041][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  67%|â–‹| 3742/5551 [20:05:35<9:44:43, 19.39s/it, loss=1.044, ppl=2.06, wps=27141.1, ups=0.05, wpb=522473, bsz=8542.1, num_updates=31160, lr=0.000122385, gnorm=0.109, clip=62.5, loss_scale=4, train_wall[2022-11-19 14:02:08,490][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 14:02:10,508][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.696 | ppl 3.24 | wps 167978 | wpb 10521.6 | bsz 178.1 | num_updates 31200 | best_loss 1.419                                   
[2022-11-19 14:02:10,508][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 31200 updates
[2022-11-19 14:02:10,509][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_31200.pt
[2022-11-19 14:02:14,960][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_31200.pt
[2022-11-19 14:02:17,991][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_31200.pt (epoch 6 @ 31200 updates, score 1.696) (writing took 7.482417523860931 seconds)
epoch 006:  69%|â–‹| 3850/5551 [20:40:29<9:06:23, 19.27s/it, loss=1.043, ppl=2.06, wps=27115.5, ups=0.05, wpb=522262, bsz=8543.3, num_updates=31280, lr=0.000121284, gnorm=0.102, clip=42.5, loss_scale=4, train_wall[2022-11-19 14:37:01,995][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  71%|â–‹| 3916/5551 [21:01:43<8:46:27, 19.32s/it, loss=1.044, ppl=2.06, wps=27117, ups=0.05, wpb=523509, bsz=8701.6, num_updates=31360, lr=0.00012055, gnorm=0.11, clip=67.5, loss_scale=2, train_wall=757[2022-11-19 14:58:16,144][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 006:  71%|â–‹| 3917/5551 [21:02:02<8:46:34, 19.34s/it, loss=1.044, ppl=2.06, wps=27117, ups=0.05, wpb=523509, bsz=8701.6, num_updates=31360, lr=0.00012055, gnorm=0.11, clip=67.5, loss_scale=2, train_wall=757[2022-11-19 14:58:35,467][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 006:  71%|â–‹| 3919/5551 [21:02:40<8:43:57, 19.26s/it, loss=1.044, ppl=2.06, wps=27117, ups=0.05, wpb=523509, bsz=8701.6, num_updates=31360, lr=0.00012055, gnorm=0.11, clip=67.5, loss_scale=2, train_wall=757[2022-11-19 14:59:13,511][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 006:  71%|â–‹| 3946/5551 [21:11:22<8:36:49, 19.32s/it, loss=1.044, ppl=2.06, wps=27117, ups=0.05, wpb=523509, bsz=8701.6, num_updates=31360, lr=0.00012055, gnorm=0.11, clip=67.5, loss_scale=2, train_wall=757[2022-11-19 15:07:55,291][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 15:07:57,312][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.6 | ppl 3.03 | wps 166628 | wpb 10521.6 | bsz 178.1 | num_updates 31400 | best_loss 1.419                                     
[2022-11-19 15:07:57,313][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 31400 updates
[2022-11-19 15:07:57,313][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_31400.pt
[2022-11-19 15:08:01,772][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_31400.pt
[2022-11-19 15:08:04,746][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_31400.pt (epoch 6 @ 31400 updates, score 1.6) (writing took 7.432934281416237 seconds)
epoch 006:  75%|â–‹| 4142/5551 [22:14:33<7:33:10, 19.30s/it, loss=1.042, ppl=2.06, wps=27033.9, ups=0.05, wpb=520895, bsz=8498.1, num_updates=31560, lr=0.000118716, gnorm=0.104, clip=52.5, loss_scale=1, train_wall[2022-11-19 16:11:06,547][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
epoch 006:  75%|â–‹| 4147/5551 [22:16:10<7:32:03, 19.32s/it, loss=1.042, ppl=2.06, wps=27033.9, ups=0.05, wpb=520895, bsz=8498.1, num_updates=31560, lr=0.000118716, gnorm=0.104, clip=52.5, loss_scale=1, train_wall[2022-11-19 16:12:43,076][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 16:12:45,096][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.665 | ppl 3.17 | wps 166591 | wpb 10521.6 | bsz 178.1 | num_updates 31600 | best_loss 1.419                                   
[2022-11-19 16:12:45,097][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 31600 updates
[2022-11-19 16:12:45,097][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_31600.pt
[2022-11-19 16:12:49,560][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_31600.pt
[2022-11-19 16:12:52,503][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_31600.pt (epoch 6 @ 31600 updates, score 1.665) (writing took 7.405726610682905 seconds)
epoch 006:  75%|â–‹| 4160/5551 [22:20:30<7:28:41, 19.35s/it, loss=1.042, ppl=2.06, wps=26405.8, ups=0.05, wpb=522433, bsz=8601.5, num_updates=31600, lr=0.000118349, gnorm=0.1, clip=40, loss_scale=0.5, train_wall=7[2022-11-19 16:17:03,451][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 006:  77%|â–Š| 4290/5551 [23:02:21<6:47:28, 19.39s/it, loss=1.043, ppl=2.06, wps=27067.3, ups=0.05, wpb=522853, bsz=8968, num_updates=31720, lr=0.000117248, gnorm=0.111, clip=50, loss_scale=0.5, train_wall=7[2022-11-19 16:58:54,284][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
epoch 006:  78%|â–Š| 4349/5551 [23:21:18<6:27:10, 19.33s/it, loss=1.043, ppl=2.06, wps=26446.2, ups=0.05, wpb=523343, bsz=8899.8, num_updates=31760, lr=0.000116881, gnorm=0.103, clip=47.5, loss_scale=0.25, train_w[2022-11-19 17:17:51,818][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 17:17:53,827][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.715 | ppl 3.28 | wps 167324 | wpb 10521.6 | bsz 178.1 | num_updates 31800 | best_loss 1.419                                   
[2022-11-19 17:17:53,828][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 31800 updates
[2022-11-19 17:17:53,828][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_31800.pt
[2022-11-19 17:17:58,273][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_31800.pt
[2022-11-19 17:18:03,162][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_31800.pt (epoch 6 @ 31800 updates, score 1.715) (writing took 9.334407739341259 seconds)
epoch 006:  82%|â–Š| 4549/5551 [24:25:47<5:20:01, 19.16s/it, loss=1.042, ppl=2.06, wps=27133.6, ups=0.05, wpb=523227, bsz=8919.5, num_updates=31960, lr=0.000115046, gnorm=0.117, clip=75, loss_scale=1, train_wall=7[2022-11-19 18:22:19,922][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 18:22:21,935][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.676 | ppl 3.19 | wps 167834 | wpb 10521.6 | bsz 178.1 | num_updates 32000 | best_loss 1.419                                   
[2022-11-19 18:22:21,935][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 32000 updates
[2022-11-19 18:22:21,936][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_32000.pt
[2022-11-19 18:22:26,401][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_32000.pt
[2022-11-19 18:22:29,384][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_32000.pt (epoch 6 @ 32000 updates, score 1.676) (writing took 7.448180473409593 seconds)
epoch 006:  82%|â–Š| 4556/5551 [24:28:12<5:26:52, 19.71s/it, loss=1.041, ppl=2.06, wps=27061.3, ups=0.05, wpb=521964, bsz=8675.7, num_updates=32000, lr=0.000114679, gnorm=0.105, clip=57.5, loss_scale=2, train_wall[2022-11-19 18:24:45,447][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 006:  86%|â–Š| 4750/5551 [25:30:39<4:16:28, 19.21s/it, loss=1.041, ppl=2.06, wps=27078.4, ups=0.05, wpb=523350, bsz=8872.6, num_updates=32160, lr=0.000113211, gnorm=0.104, clip=65, loss_scale=2, train_wall=7[2022-11-19 19:27:12,134][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 19:27:14,154][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.617 | ppl 3.07 | wps 166895 | wpb 10521.6 | bsz 178.1 | num_updates 32200 | best_loss 1.419                                   
[2022-11-19 19:27:14,154][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 32200 updates
[2022-11-19 19:27:14,155][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_32200.pt
[2022-11-19 19:27:18,616][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_32200.pt
[2022-11-19 19:27:21,573][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_32200.pt (epoch 6 @ 32200 updates, score 1.617) (writing took 7.418303327634931 seconds)
epoch 006:  86%|â–Š| 4778/5551 [25:39:49<4:09:35, 19.37s/it, loss=1.042, ppl=2.06, wps=27020.3, ups=0.05, wpb=521829, bsz=9077.9, num_updates=32200, lr=0.000112844, gnorm=0.099, clip=37.5, loss_scale=4, train_wall[2022-11-19 19:36:21,938][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 006:  86%|â–Š| 4798/5551 [25:46:16<4:05:08, 19.53s/it, loss=1.042, ppl=2.06, wps=26026.5, ups=0.05, wpb=521121, bsz=8956.8, num_updates=32240, lr=0.000112477, gnorm=0.112, clip=62.5, loss_scale=2, train_wall[2022-11-19 19:42:49,016][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 006:  89%|â–‰| 4952/5551 [26:35:44<3:11:43, 19.21s/it, loss=1.044, ppl=2.06, wps=27059.5, ups=0.05, wpb=521232, bsz=8802, num_updates=32360, lr=0.000111376, gnorm=0.112, clip=50, loss_scale=2, train_wall=756[2022-11-19 20:32:17,675][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 20:32:19,705][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.762 | ppl 3.39 | wps 165559 | wpb 10521.6 | bsz 178.1 | num_updates 32400 | best_loss 1.419                                   
[2022-11-19 20:32:19,705][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 32400 updates
[2022-11-19 20:32:19,706][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_32400.pt
[2022-11-19 20:32:24,160][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_32400.pt
[2022-11-19 20:32:27,120][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_32400.pt (epoch 6 @ 32400 updates, score 1.762) (writing took 7.414350767619908 seconds)
epoch 006:  91%|â–‰| 5058/5551 [27:09:59<2:37:52, 19.21s/it, loss=1.041, ppl=2.06, wps=27115.5, ups=0.05, wpb=522755, bsz=8694.1, num_updates=32480, lr=0.000110275, gnorm=0.109, clip=72.5, loss_scale=4, train_wall[2022-11-19 21:06:32,322][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  93%|â–‰| 5153/5551 [27:40:31<2:07:12, 19.18s/it, loss=1.04, ppl=2.06, wps=27107.6, ups=0.05, wpb=523775, bsz=8779.2, num_updates=32560, lr=0.000109541, gnorm=0.1, clip=47.5, loss_scale=4, train_wall=75[2022-11-19 21:37:04,320][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 21:37:06,346][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.718 | ppl 3.29 | wps 165751 | wpb 10521.6 | bsz 178.1 | num_updates 32600 | best_loss 1.419                                   
[2022-11-19 21:37:06,347][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 32600 updates
[2022-11-19 21:37:06,348][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_32600.pt
[2022-11-19 21:37:10,817][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_32600.pt
[2022-11-19 21:37:13,669][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_32600.pt (epoch 6 @ 32600 updates, score 1.718) (writing took 7.32152562122792 seconds)
epoch 006:  93%|â–‰| 5172/5551 [27:46:47<2:02:03, 19.32s/it, loss=1.039, ppl=2.06, wps=27078.6, ups=0.05, wpb=521201, bsz=8410.3, num_updates=32600, lr=0.000109174, gnorm=0.102, clip=35, loss_scale=8, train_wall=7[2022-11-19 21:43:20,441][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  95%|â–‰| 5300/5551 [28:27:54<1:20:39, 19.28s/it, loss=1.039, ppl=2.06, wps=27156.9, ups=0.05, wpb=522948, bsz=8705.8, num_updates=32720, lr=0.000108073, gnorm=0.111, clip=62.5, loss_scale=8, train_wall[2022-11-19 22:24:27,233][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  96%|â–‰| 5355/5551 [28:45:34<1:02:55, 19.26s/it, loss=1.038, ppl=2.05, wps=26382.8, ups=0.05, wpb=521516, bsz=8725.1, num_updates=32760, lr=0.000107706, gnorm=0.103, clip=47.5, loss_scale=4, train_wall[2022-11-19 22:42:07,888][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 22:42:09,915][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.761 | ppl 3.39 | wps 166434 | wpb 10521.6 | bsz 178.1 | num_updates 32800 | best_loss 1.419                                   
[2022-11-19 22:42:09,916][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 32800 updates
[2022-11-19 22:42:09,916][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_32800.pt
[2022-11-19 22:42:14,346][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_6_32800.pt
[2022-11-19 22:42:17,385][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_6_32800.pt (epoch 6 @ 32800 updates, score 1.761) (writing took 7.468675329349935 seconds)
epoch 006:  97%|â–‰| 5405/5551 [29:01:47<46:48, 19.24s/it, loss=1.039, ppl=2.05, wps=26799.3, ups=0.05, wpb=522725, bsz=8539.1, num_updates=32840, lr=0.000106972, gnorm=0.103, clip=45, loss_scale=8, train_wall=757[2022-11-19 22:58:20,574][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006:  99%|â–‰| 5504/5551 [29:33:36<15:01, 19.17s/it, loss=1.038, ppl=2.05, wps=27164.2, ups=0.05, wpb=522444, bsz=8658.4, num_updates=32920, lr=0.000106239, gnorm=0.098, clip=30, loss_scale=4, train_wall=755[2022-11-19 23:30:09,904][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 006: 100%|â–‰| 5550/5551 [29:48:26<00:19, 19.35s/it, loss=1.038, ppl=2.05, wps=26397, ups=0.05, wpb=521825, bsz=8804.9, num_updates=32960, lr=0.000105872, gnorm=0.098, clip=37.5, loss_scale=4, train_wall=775[2022-11-19 23:44:55,907][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 23:44:57,939][valid][INFO] - epoch 006 | valid on 'valid' subset | loss 1.703 | ppl 3.26 | wps 165974 | wpb 10521.6 | bsz 178.1 | num_updates 32993 | best_loss 1.419                                   
[2022-11-19 23:44:57,940][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 6 @ 32993 updates
[2022-11-19 23:44:57,941][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint6.pt
[2022-11-19 23:45:02,407][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint6.pt
[2022-11-19 23:45:05,365][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint6.pt (epoch 6 @ 32993 updates, score 1.703) (writing took 7.425118738785386 seconds)
[2022-11-19 23:45:06,793][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)                                                                                                                    
[2022-11-19 23:45:06,795][train][INFO] - epoch 006 | loss 1.047 | ppl 2.07 | wps 26790 | ups 0.05 | wpb 522625 | bsz 8747.2 | num_updates 32993 | lr 0.000105569 | gnorm 0.114 | clip 57.7 | loss_scale 4 | train_wall 104944 | gb_free 7.9 | wall 645673
[2022-11-19 23:45:07,359][fairseq.data.iterators][INFO] - grouped total_num_itrs = 5551
epoch 007:   0%|                                                                                                                                                                          | 0/5551 [00:00<?, ?it/s][2022-11-19 23:45:07,389][fairseq.trainer][INFO] - begin training epoch 7
[2022-11-19 23:45:07,390][fairseq_cli.train][INFO] - Start iterating over samples
epoch 007:   0%|                                                                                                                                                               | 1/5551 [00:19<30:03:33, 19.50s/it][2022-11-19 23:45:46,070][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:   0%|â–                                                                                                                                                              | 7/5551 [02:15<29:47:58, 19.35s/it][2022-11-19 23:47:41,922][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-19 23:47:43,949][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.637 | ppl 3.11 | wps 166745 | wpb 10521.6 | bsz 178.1 | num_updates 33000 | best_loss 1.419                                   
[2022-11-19 23:47:43,950][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 33000 updates
[2022-11-19 23:47:43,950][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_33000.pt
[2022-11-19 23:47:48,455][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_33000.pt
[2022-11-19 23:47:51,377][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_33000.pt (epoch 7 @ 33000 updates, score 1.637) (writing took 7.426636612974107 seconds)
epoch 007:   3%| | 160/5551 [51:36<28:54:26, 19.30s/it, loss=1.036, ppl=2.05, wps=27082.4, ups=0.05, wpb=522460, bsz=8899.8, num_updates=33120, lr=0.000104404, gnorm=0.096, clip=25, loss_scale=4, train_wall=756,[2022-11-20 00:37:03,150][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:   4%| | 208/5551 [1:07:02<28:31:12, 19.22s/it, loss=1.036, ppl=2.05, wps=26523.5, ups=0.05, wpb=524222, bsz=8696.9, num_updates=33160, lr=0.000104037, gnorm=0.098, clip=35, loss_scale=2, train_wall=77[2022-11-20 00:52:28,918][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 00:52:30,952][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.667 | ppl 3.18 | wps 166180 | wpb 10521.6 | bsz 178.1 | num_updates 33200 | best_loss 1.419                                   
[2022-11-20 00:52:30,953][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 33200 updates
[2022-11-20 00:52:30,953][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_33200.pt
[2022-11-20 00:52:35,418][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_33200.pt
[2022-11-20 00:52:38,312][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_33200.pt (epoch 7 @ 33200 updates, score 1.667) (writing took 7.359336226247251 seconds)
epoch 007:   7%| | 408/5551 [2:11:27<27:33:56, 19.30s/it, loss=1.034, ppl=2.05, wps=27089.1, ups=0.05, wpb=522728, bsz=8947.6, num_updates=33360, lr=0.000102202, gnorm=0.094, clip=12.5, loss_scale=8, train_wall=[2022-11-20 01:56:53,888][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 01:56:55,918][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.646 | ppl 3.13 | wps 167073 | wpb 10521.6 | bsz 178.1 | num_updates 33400 | best_loss 1.419                                   
[2022-11-20 01:56:55,919][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 33400 updates
[2022-11-20 01:56:55,919][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_33400.pt
[2022-11-20 01:57:00,333][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_33400.pt
[2022-11-20 01:57:03,286][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_33400.pt (epoch 7 @ 33400 updates, score 1.646) (writing took 7.367035157978535 seconds)
epoch 007:   7%| | 416/5551 [2:14:10<27:48:44, 19.50s/it, loss=1.033, ppl=2.05, wps=27152.4, ups=0.05, wpb=522698, bsz=8507.4, num_updates=33400, lr=0.000101835, gnorm=0.098, clip=37.5, loss_scale=8, train_wall=[2022-11-20 01:59:37,393][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 007:   8%| | 421/5551 [2:15:46<27:26:46, 19.26s/it, loss=1.033, ppl=2.05, wps=27152.4, ups=0.05, wpb=522698, bsz=8507.4, num_updates=33400, lr=0.000101835, gnorm=0.098, clip=37.5, loss_scale=8, train_wall=[2022-11-20 02:01:13,543][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  10%| | 556/5551 [2:59:12<26:38:14, 19.20s/it, loss=1.034, ppl=2.05, wps=27171, ups=0.05, wpb=523763, bsz=8699.9, num_updates=33520, lr=0.000100734, gnorm=0.1, clip=42.5, loss_scale=8, train_wall=755,[2022-11-20 02:44:38,835][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  11%| | 611/5551 [3:16:51<26:23:35, 19.23s/it, loss=1.034, ppl=2.05, wps=26433.7, ups=0.05, wpb=522277, bsz=9056.6, num_updates=33560, lr=0.000100367, gnorm=0.099, clip=37.5, loss_scale=4, train_wall=[2022-11-20 03:02:18,066][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 03:02:20,109][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.664 | ppl 3.17 | wps 165909 | wpb 10521.6 | bsz 178.1 | num_updates 33600 | best_loss 1.419                                   
[2022-11-20 03:02:20,109][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 33600 updates
[2022-11-20 03:02:20,110][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_33600.pt
[2022-11-20 03:02:24,523][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_33600.pt
[2022-11-20 03:02:27,552][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_33600.pt (epoch 7 @ 33600 updates, score 1.664) (writing took 7.442148705013096 seconds)
epoch 007:  11%| | 617/5551 [3:18:56<26:56:25, 19.66s/it, loss=1.033, ppl=2.05, wps=27118.4, ups=0.05, wpb=522323, bsz=8810.5, num_updates=33600, lr=0.0001, gnorm=0.101, clip=40, loss_scale=4, train_wall=755, gb[2022-11-20 03:04:22,862][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  11%| | 621/5551 [3:20:13<26:34:34, 19.41s/it, loss=1.033, ppl=2.05, wps=27118.4, ups=0.05, wpb=522323, bsz=8810.5, num_updates=33600, lr=0.0001, gnorm=0.101, clip=40, loss_scale=4, train_wall=755, gb[2022-11-20 03:05:40,095][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 007:  15%|â–| 813/5551 [4:21:57<25:35:40, 19.45s/it, loss=1.033, ppl=2.05, wps=27108.3, ups=0.05, wpb=521973, bsz=8549.9, num_updates=33760, lr=9.85321e-05, gnorm=0.1, clip=42.5, loss_scale=2, train_wall=75[2022-11-20 04:07:23,958][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 04:07:25,996][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.688 | ppl 3.22 | wps 166556 | wpb 10521.6 | bsz 178.1 | num_updates 33800 | best_loss 1.419                                   
[2022-11-20 04:07:25,996][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 33800 updates
[2022-11-20 04:07:25,997][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_33800.pt
[2022-11-20 04:07:30,467][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_33800.pt
[2022-11-20 04:07:33,383][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_33800.pt (epoch 7 @ 33800 updates, score 1.688) (writing took 7.387072800658643 seconds)
epoch 007:  17%|â–| 962/5551 [5:10:03<24:31:26, 19.24s/it, loss=1.033, ppl=2.05, wps=27096.1, ups=0.05, wpb=522820, bsz=8872.1, num_updates=33920, lr=9.70642e-05, gnorm=0.092, clip=10, loss_scale=8, train_wall=75[2022-11-20 04:55:29,830][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 007:  18%|â–| 998/5551 [5:21:36<24:20:32, 19.25s/it, loss=1.034, ppl=2.05, wps=26453, ups=0.05, wpb=522549, bsz=8935.9, num_updates=33960, lr=9.66972e-05, gnorm=0.101, clip=37.5, loss_scale=8, train_wall=77[2022-11-20 05:07:03,117][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  18%|â–| 1015/5551 [5:27:04<24:20:02, 19.31s/it, loss=1.034, ppl=2.05, wps=26453, ups=0.05, wpb=522549, bsz=8935.9, num_updates=33960, lr=9.66972e-05, gnorm=0.101, clip=37.5, loss_scale=8, train_wall=7[2022-11-20 05:12:31,341][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 05:12:33,386][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.712 | ppl 3.28 | wps 166267 | wpb 10521.6 | bsz 178.1 | num_updates 34000 | best_loss 1.419                                   
[2022-11-20 05:12:33,386][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 34000 updates
[2022-11-20 05:12:33,387][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_34000.pt
[2022-11-20 05:12:37,845][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_34000.pt
[2022-11-20 05:12:40,833][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_34000.pt (epoch 7 @ 34000 updates, score 1.712) (writing took 7.44695015065372 seconds)
epoch 007:  20%|â–| 1094/5551 [5:52:37<23:48:55, 19.24s/it, loss=1.031, ppl=2.04, wps=26835.1, ups=0.05, wpb=523170, bsz=8509.7, num_updates=34040, lr=9.59633e-05, gnorm=0.093, clip=10, loss_scale=4, train_wall=7[2022-11-20 05:38:04,060][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  20%|â–| 1128/5551 [6:03:33<23:40:53, 19.27s/it, loss=1.032, ppl=2.04, wps=26462.8, ups=0.05, wpb=523555, bsz=8875.9, num_updates=34080, lr=9.55963e-05, gnorm=0.103, clip=47.5, loss_scale=4, train_wall[2022-11-20 05:49:00,359][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  21%|â–| 1149/5551 [6:10:18<23:39:47, 19.35s/it, loss=1.032, ppl=2.05, wps=26456.8, ups=0.05, wpb=523218, bsz=8839.2, num_updates=34120, lr=9.52294e-05, gnorm=0.096, clip=20, loss_scale=2, train_wall=7[2022-11-20 05:55:45,274][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 007:  22%|â–| 1218/5551 [6:32:30<23:14:47, 19.31s/it, loss=1.033, ppl=2.05, wps=26472.6, ups=0.05, wpb=523705, bsz=8861, num_updates=34160, lr=9.48624e-05, gnorm=0.099, clip=32.5, loss_scale=1, train_wall=7[2022-11-20 06:17:57,022][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 06:17:59,053][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.689 | ppl 3.22 | wps 167341 | wpb 10521.6 | bsz 178.1 | num_updates 34200 | best_loss 1.419                                   
[2022-11-20 06:17:59,054][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 34200 updates
[2022-11-20 06:17:59,054][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_34200.pt
[2022-11-20 06:18:03,508][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_34200.pt
[2022-11-20 06:18:06,475][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_34200.pt (epoch 7 @ 34200 updates, score 1.689) (writing took 7.421005128882825 seconds)
epoch 007:  25%|â–Ž| 1413/5551 [7:35:20<22:13:33, 19.34s/it, loss=1.033, ppl=2.05, wps=27113.4, ups=0.05, wpb=522421, bsz=8788.9, num_updates=34360, lr=9.30275e-05, gnorm=0.096, clip=22.5, loss_scale=4, train_wall[2022-11-20 07:20:47,514][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  26%|â–Ž| 1419/5551 [7:37:16<22:08:37, 19.29s/it, loss=1.033, ppl=2.05, wps=27113.4, ups=0.05, wpb=522421, bsz=8788.9, num_updates=34360, lr=9.30275e-05, gnorm=0.096, clip=22.5, loss_scale=4, train_wall[2022-11-20 07:22:43,634][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 07:22:45,671][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.734 | ppl 3.33 | wps 166430 | wpb 10521.6 | bsz 178.1 | num_updates 34400 | best_loss 1.419                                   
[2022-11-20 07:22:45,672][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 34400 updates
[2022-11-20 07:22:45,672][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_34400.pt
[2022-11-20 07:22:50,117][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_34400.pt
[2022-11-20 07:22:53,010][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_34400.pt (epoch 7 @ 34400 updates, score 1.734) (writing took 7.338618776760995 seconds)
epoch 007:  26%|â–Ž| 1467/5551 [7:52:52<21:58:17, 19.37s/it, loss=1.032, ppl=2.05, wps=26757.1, ups=0.05, wpb=522074, bsz=8608.6, num_updates=34440, lr=9.22936e-05, gnorm=0.097, clip=22.5, loss_scale=4, train_wall[2022-11-20 07:38:18,938][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  29%|â–Ž| 1620/5551 [8:41:56<20:57:00, 19.19s/it, loss=1.031, ppl=2.04, wps=27130.9, ups=0.05, wpb=522252, bsz=8816.5, num_updates=34560, lr=9.11927e-05, gnorm=0.101, clip=45, loss_scale=4, train_wall=7[2022-11-20 08:27:23,296][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 08:27:25,398][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.693 | ppl 3.23 | wps 159050 | wpb 10521.6 | bsz 178.1 | num_updates 34600 | best_loss 1.419                                   
[2022-11-20 08:27:25,398][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 34600 updates
[2022-11-20 08:27:25,399][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_34600.pt
[2022-11-20 08:27:29,852][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_34600.pt
[2022-11-20 08:27:34,158][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_34600.pt (epoch 7 @ 34600 updates, score 1.693) (writing took 8.76023046951741 seconds)
epoch 007:  30%|â–Ž| 1676/5551 [9:00:07<20:39:49, 19.20s/it, loss=1.031, ppl=2.04, wps=26816.2, ups=0.05, wpb=524429, bsz=8793, num_updates=34640, lr=9.04587e-05, gnorm=0.093, clip=2.5, loss_scale=8, train_wall=75[2022-11-20 08:45:34,004][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  30%|â–Ž| 1693/5551 [9:05:36<20:42:06, 19.32s/it, loss=1.031, ppl=2.04, wps=26816.2, ups=0.05, wpb=524429, bsz=8793, num_updates=34640, lr=9.04587e-05, gnorm=0.093, clip=2.5, loss_scale=8, train_wall=75[2022-11-20 08:51:03,070][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  33%|â–Ž| 1822/5551 [9:47:05<20:06:39, 19.42s/it, loss=1.032, ppl=2.04, wps=27114.7, ups=0.05, wpb=522493, bsz=8752.8, num_updates=34760, lr=8.93578e-05, gnorm=0.094, clip=17.5, loss_scale=4, train_wall[2022-11-20 09:32:31,756][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 09:32:33,787][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.754 | ppl 3.37 | wps 166858 | wpb 10521.6 | bsz 178.1 | num_updates 34800 | best_loss 1.419                                   
[2022-11-20 09:32:33,787][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 34800 updates
[2022-11-20 09:32:33,788][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_34800.pt
[2022-11-20 09:32:38,240][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_34800.pt
[2022-11-20 09:32:41,190][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_34800.pt (epoch 7 @ 34800 updates, score 1.754) (writing took 7.402591083198786 seconds)
epoch 007:  35%|â–Ž| 1949/5551 [10:28:00<19:20:21, 19.33s/it, loss=1.03, ppl=2.04, wps=27135.2, ups=0.05, wpb=522970, bsz=8884.2, num_updates=34920, lr=8.78899e-05, gnorm=0.096, clip=27.5, loss_scale=8, train_wall[2022-11-20 10:13:27,442][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 007:  36%|â–Ž| 2018/5551 [10:50:09<18:53:44, 19.25s/it, loss=1.029, ppl=2.04, wps=26419.3, ups=0.05, wpb=521211, bsz=8640.4, num_updates=34960, lr=8.75229e-05, gnorm=0.098, clip=37.5, loss_scale=8, train_wal[2022-11-20 10:35:35,560][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  36%|â–Ž| 2024/5551 [10:52:04<18:51:02, 19.24s/it, loss=1.029, ppl=2.04, wps=26419.3, ups=0.05, wpb=521211, bsz=8640.4, num_updates=34960, lr=8.75229e-05, gnorm=0.098, clip=37.5, loss_scale=8, train_wal[2022-11-20 10:37:30,785][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 10:37:32,830][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.621 | ppl 3.08 | wps 166141 | wpb 10521.6 | bsz 178.1 | num_updates 35000 | best_loss 1.419                                   
[2022-11-20 10:37:32,831][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 35000 updates
[2022-11-20 10:37:32,831][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_35000.pt
[2022-11-20 10:37:37,285][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_35000.pt
[2022-11-20 10:37:40,123][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_35000.pt (epoch 7 @ 35000 updates, score 1.621) (writing took 7.291869495995343 seconds)
epoch 007:  39%|â–| 2147/5551 [11:31:45<18:12:48, 19.26s/it, loss=1.029, ppl=2.04, wps=27099.1, ups=0.05, wpb=521612, bsz=8666.2, num_updates=35120, lr=8.6055e-05, gnorm=0.093, clip=15, loss_scale=8, train_wall=7[2022-11-20 11:17:11,930][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  40%|â–| 2220/5551 [11:55:12<17:52:43, 19.32s/it, loss=1.031, ppl=2.04, wps=26395.1, ups=0.05, wpb=521440, bsz=8460.1, num_updates=35160, lr=8.56881e-05, gnorm=0.093, clip=10, loss_scale=4, train_wall=[2022-11-20 11:40:39,416][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  40%|â–| 2226/5551 [11:57:08<17:50:09, 19.31s/it, loss=1.031, ppl=2.04, wps=26395.1, ups=0.05, wpb=521440, bsz=8460.1, num_updates=35160, lr=8.56881e-05, gnorm=0.093, clip=10, loss_scale=4, train_wall=[2022-11-20 11:42:34,794][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 11:42:36,834][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.815 | ppl 3.52 | wps 166931 | wpb 10521.6 | bsz 178.1 | num_updates 35200 | best_loss 1.419                                   
[2022-11-20 11:42:36,834][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 35200 updates
[2022-11-20 11:42:36,835][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_35200.pt
[2022-11-20 11:42:41,288][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_35200.pt
[2022-11-20 11:42:44,300][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_35200.pt (epoch 7 @ 35200 updates, score 1.815) (writing took 7.465047115460038 seconds)
epoch 007:  43%|â–| 2407/5551 [12:55:27<16:48:15, 19.24s/it, loss=1.03, ppl=2.04, wps=27107, ups=0.05, wpb=522560, bsz=8564.3, num_updates=35360, lr=8.38532e-05, gnorm=0.099, clip=27.5, loss_scale=4, train_wall=7[2022-11-20 12:40:53,909][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  44%|â–| 2427/5551 [13:01:52<16:42:12, 19.25s/it, loss=1.03, ppl=2.04, wps=27107, ups=0.05, wpb=522560, bsz=8564.3, num_updates=35360, lr=8.38532e-05, gnorm=0.099, clip=27.5, loss_scale=4, train_wall=7[2022-11-20 12:47:19,889][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 12:47:21,934][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.689 | ppl 3.22 | wps 165709 | wpb 10521.6 | bsz 178.1 | num_updates 35400 | best_loss 1.419                                   
[2022-11-20 12:47:21,934][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 35400 updates
[2022-11-20 12:47:21,935][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_35400.pt
[2022-11-20 12:47:26,395][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_35400.pt
[2022-11-20 12:47:29,230][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_35400.pt (epoch 7 @ 35400 updates, score 1.689) (writing took 7.296095337718725 seconds)
epoch 007:  44%|â–| 2466/5551 [13:14:34<16:27:24, 19.20s/it, loss=1.029, ppl=2.04, wps=26445.6, ups=0.05, wpb=522968, bsz=8688.5, num_updates=35400, lr=8.34862e-05, gnorm=0.113, clip=65, loss_scale=4, train_wall=[2022-11-20 13:00:00,849][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  47%|â–| 2628/5551 [14:06:40<15:38:57, 19.27s/it, loss=1.029, ppl=2.04, wps=27117.5, ups=0.05, wpb=522483, bsz=8750.4, num_updates=35560, lr=8.20183e-05, gnorm=0.099, clip=45, loss_scale=4, train_wall=[2022-11-20 13:52:07,965][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 13:52:09,994][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.74 | ppl 3.34 | wps 167534 | wpb 10521.6 | bsz 178.1 | num_updates 35600 | best_loss 1.419                                    
[2022-11-20 13:52:09,995][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 35600 updates
[2022-11-20 13:52:09,996][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_35600.pt
[2022-11-20 13:52:14,454][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_35600.pt
[2022-11-20 13:52:17,399][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_35600.pt (epoch 7 @ 35600 updates, score 1.74) (writing took 7.404168645851314 seconds)
epoch 007:  48%|â–| 2679/5551 [14:23:15<15:24:02, 19.30s/it, loss=1.028, ppl=2.04, wps=26761.3, ups=0.05, wpb=522878, bsz=8634.8, num_updates=35640, lr=8.12844e-05, gnorm=0.097, clip=25, loss_scale=8, train_wall=[2022-11-20 14:08:41,693][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  50%|â–Œ| 2791/5551 [14:59:15<14:41:31, 19.16s/it, loss=1.027, ppl=2.04, wps=27121.5, ups=0.05, wpb=522569, bsz=8635.9, num_updates=35760, lr=8.01835e-05, gnorm=0.098, clip=32.5, loss_scale=8, train_wal[2022-11-20 14:44:42,788][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  51%|â–Œ| 2830/5551 [15:11:48<14:37:02, 19.34s/it, loss=1.027, ppl=2.04, wps=27121.5, ups=0.05, wpb=522569, bsz=8635.9, num_updates=35760, lr=8.01835e-05, gnorm=0.098, clip=32.5, loss_scale=8, train_wal[2022-11-20 14:57:15,234][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 14:57:17,270][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.619 | ppl 3.07 | wps 166421 | wpb 10521.6 | bsz 178.1 | num_updates 35800 | best_loss 1.419                                   
[2022-11-20 14:57:17,271][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 35800 updates
[2022-11-20 14:57:17,271][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_35800.pt
[2022-11-20 14:57:21,723][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_35800.pt
[2022-11-20 14:57:24,688][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_35800.pt (epoch 7 @ 35800 updates, score 1.619) (writing took 7.417650862596929 seconds)
epoch 007:  51%|â–Œ| 2845/5551 [15:16:46<14:34:28, 19.39s/it, loss=1.028, ppl=2.04, wps=26437.4, ups=0.05, wpb=522738, bsz=8895.5, num_updates=35800, lr=7.98165e-05, gnorm=0.099, clip=30, loss_scale=4, train_wall=[2022-11-20 15:02:13,622][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  52%|â–Œ| 2866/5551 [15:23:31<14:25:24, 19.34s/it, loss=1.028, ppl=2.04, wps=26437.4, ups=0.05, wpb=522738, bsz=8895.5, num_updates=35800, lr=7.98165e-05, gnorm=0.099, clip=30, loss_scale=4, train_wall=[2022-11-20 15:08:58,823][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
epoch 007:  55%|â–Œ| 3032/5551 [16:16:54<13:31:26, 19.33s/it, loss=1.028, ppl=2.04, wps=27073.3, ups=0.05, wpb=522196, bsz=8683, num_updates=35960, lr=7.83486e-05, gnorm=0.094, clip=10, loss_scale=2, train_wall=75[2022-11-20 16:02:21,480][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 16:02:23,504][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.682 | ppl 3.21 | wps 167615 | wpb 10521.6 | bsz 178.1 | num_updates 36000 | best_loss 1.419                                   
[2022-11-20 16:02:23,505][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 36000 updates
[2022-11-20 16:02:23,505][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_36000.pt
[2022-11-20 16:02:27,961][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_36000.pt
[2022-11-20 16:02:30,870][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_36000.pt (epoch 7 @ 36000 updates, score 1.682) (writing took 7.364923866465688 seconds)
epoch 007:  56%|â–Œ| 3128/5551 [16:47:56<12:58:38, 19.28s/it, loss=1.027, ppl=2.04, wps=27126.2, ups=0.05, wpb=522637, bsz=8867.9, num_updates=36080, lr=7.72477e-05, gnorm=0.098, clip=27.5, loss_scale=4, train_wal[2022-11-20 16:33:23,408][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  58%|â–Œ| 3226/5551 [17:19:28<12:31:02, 19.38s/it, loss=1.028, ppl=2.04, wps=27088.3, ups=0.05, wpb=523115, bsz=8883.6, num_updates=36160, lr=7.65138e-05, gnorm=0.1, clip=40, loss_scale=4, train_wall=75[2022-11-20 17:04:55,226][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  58%|â–Œ| 3234/5551 [17:22:02<12:22:57, 19.24s/it, loss=1.028, ppl=2.04, wps=27088.3, ups=0.05, wpb=523115, bsz=8883.6, num_updates=36160, lr=7.65138e-05, gnorm=0.1, clip=40, loss_scale=4, train_wall=75[2022-11-20 17:07:29,569][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 17:07:31,600][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.767 | ppl 3.4 | wps 167661 | wpb 10521.6 | bsz 178.1 | num_updates 36200 | best_loss 1.419                                    
[2022-11-20 17:07:31,600][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 36200 updates
[2022-11-20 17:07:31,601][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_36200.pt
[2022-11-20 17:07:36,048][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_36200.pt
[2022-11-20 17:07:38,958][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_36200.pt (epoch 7 @ 36200 updates, score 1.767) (writing took 7.357817434705794 seconds)
epoch 007:  60%|â–Œ| 3348/5551 [17:58:49<11:47:07, 19.26s/it, loss=1.028, ppl=2.04, wps=27162.8, ups=0.05, wpb=523293, bsz=8714.1, num_updates=36280, lr=7.54128e-05, gnorm=0.11, clip=57.5, loss_scale=8, train_wall[2022-11-20 17:44:16,332][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  61%|â–Œ| 3382/5551 [18:09:45<11:37:11, 19.29s/it, loss=1.027, ppl=2.04, wps=26392.4, ups=0.05, wpb=521032, bsz=8627.7, num_updates=36320, lr=7.50459e-05, gnorm=0.097, clip=27.5, loss_scale=4, train_wal[2022-11-20 17:55:11,912][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  62%|â–Œ| 3436/5551 [18:27:07<11:19:13, 19.27s/it, loss=1.027, ppl=2.04, wps=26435.9, ups=0.05, wpb=522590, bsz=8842.3, num_updates=36360, lr=7.46789e-05, gnorm=0.091, clip=2.5, loss_scale=2, train_wall[2022-11-20 18:12:34,001][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 18:12:36,029][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.738 | ppl 3.34 | wps 167114 | wpb 10521.6 | bsz 178.1 | num_updates 36400 | best_loss 1.419                                   
[2022-11-20 18:12:36,029][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 36400 updates
[2022-11-20 18:12:36,030][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_36400.pt
[2022-11-20 18:12:40,459][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_36400.pt
[2022-11-20 18:12:43,293][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_36400.pt (epoch 7 @ 36400 updates, score 1.738) (writing took 7.263089912012219 seconds)
epoch 007:  64%|â–‹| 3562/5551 [19:07:48<10:42:41, 19.39s/it, loss=1.027, ppl=2.04, wps=27058.5, ups=0.05, wpb=521981, bsz=8994.2, num_updates=36520, lr=7.3211e-05, gnorm=0.103, clip=55, loss_scale=8, train_wall=7[2022-11-20 18:53:14,787][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  66%|â–‹| 3637/5551 [19:31:55<10:15:10, 19.28s/it, loss=1.026, ppl=2.04, wps=26470.9, ups=0.05, wpb=524176, bsz=8937.8, num_updates=36560, lr=7.2844e-05, gnorm=0.09, clip=5, loss_scale=4, train_wall=776[2022-11-20 19:17:22,017][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 19:17:24,071][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.754 | ppl 3.37 | wps 165248 | wpb 10521.6 | bsz 178.1 | num_updates 36600 | best_loss 1.419                                   
[2022-11-20 19:17:24,072][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 36600 updates
[2022-11-20 19:17:24,072][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_36600.pt
[2022-11-20 19:17:28,533][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_36600.pt
[2022-11-20 19:17:32,576][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_36600.pt (epoch 7 @ 36600 updates, score 1.754) (writing took 8.504582823254168 seconds)
epoch 007:  66%|â–‹| 3682/5551 [19:46:34<10:01:53, 19.32s/it, loss=1.026, ppl=2.04, wps=26737.1, ups=0.05, wpb=522992, bsz=8917.4, num_updates=36640, lr=7.21101e-05, gnorm=0.097, clip=37.5, loss_scale=8, train_wal[2022-11-20 19:32:01,470][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  69%|â–‹| 3823/5551 [20:31:54<9:16:29, 19.32s/it, loss=1.025, ppl=2.04, wps=27078.6, ups=0.05, wpb=522153, bsz=8748.7, num_updates=36760, lr=7.10092e-05, gnorm=0.093, clip=12.5, loss_scale=8, train_wall[2022-11-20 20:17:21,114][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  69%|â–‹| 3839/5551 [20:37:03<9:10:27, 19.29s/it, loss=1.025, ppl=2.04, wps=27078.6, ups=0.05, wpb=522153, bsz=8748.7, num_updates=36760, lr=7.10092e-05, gnorm=0.093, clip=12.5, loss_scale=8, train_wall[2022-11-20 20:22:30,111][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 20:22:32,136][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.632 | ppl 3.1 | wps 167683 | wpb 10521.6 | bsz 178.1 | num_updates 36800 | best_loss 1.419                                    
[2022-11-20 20:22:32,137][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 36800 updates
[2022-11-20 20:22:32,137][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_36800.pt
[2022-11-20 20:22:36,603][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_36800.pt
[2022-11-20 20:22:39,430][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_36800.pt (epoch 7 @ 36800 updates, score 1.632) (writing took 7.293243369087577 seconds)
epoch 007:  71%|â–‹| 3916/5551 [21:01:59<8:43:23, 19.21s/it, loss=1.024, ppl=2.03, wps=26677.9, ups=0.05, wpb=521911, bsz=8889.5, num_updates=36840, lr=7.02752e-05, gnorm=0.101, clip=30, loss_scale=4, train_wall=7[2022-11-20 20:47:25,842][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  73%|â–‹| 4040/5551 [21:41:49<8:07:18, 19.35s/it, loss=1.028, ppl=2.04, wps=27129.8, ups=0.05, wpb=522785, bsz=8901.7, num_updates=36960, lr=6.91743e-05, gnorm=0.096, clip=20, loss_scale=4, train_wall=7[2022-11-20 21:27:15,986][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 21:27:18,016][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.727 | ppl 3.31 | wps 167104 | wpb 10521.6 | bsz 178.1 | num_updates 37000 | best_loss 1.419                                   
[2022-11-20 21:27:18,016][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 37000 updates
[2022-11-20 21:27:18,017][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_37000.pt
[2022-11-20 21:27:22,447][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_37000.pt
[2022-11-20 21:27:25,373][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_37000.pt (epoch 7 @ 37000 updates, score 1.727) (writing took 7.356652255170047 seconds)
epoch 007:  73%|â–‹| 4046/5551 [21:43:54<8:17:09, 19.82s/it, loss=1.024, ppl=2.03, wps=27097.9, ups=0.05, wpb=522719, bsz=8659, num_updates=37000, lr=6.88073e-05, gnorm=0.096, clip=22.5, loss_scale=8, train_wall=7[2022-11-20 21:29:21,229][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  73%|â–‹| 4049/5551 [21:44:52<8:06:18, 19.43s/it, loss=1.024, ppl=2.03, wps=27097.9, ups=0.05, wpb=522719, bsz=8659, num_updates=37000, lr=6.88073e-05, gnorm=0.096, clip=22.5, loss_scale=8, train_wall=7[2022-11-20 21:30:19,270][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  76%|â–Š| 4242/5551 [22:46:56<7:02:23, 19.36s/it, loss=1.025, ppl=2.03, wps=27067.6, ups=0.05, wpb=521360, bsz=8531, num_updates=37160, lr=6.73394e-05, gnorm=0.096, clip=32.5, loss_scale=4, train_wall=7[2022-11-20 22:32:22,579][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 22:32:24,620][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.719 | ppl 3.29 | wps 166583 | wpb 10521.6 | bsz 178.1 | num_updates 37200 | best_loss 1.419                                   
[2022-11-20 22:32:24,620][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 37200 updates
[2022-11-20 22:32:24,621][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_37200.pt
[2022-11-20 22:32:29,071][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_37200.pt
[2022-11-20 22:32:31,962][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_37200.pt (epoch 7 @ 37200 updates, score 1.719) (writing took 7.341605969704688 seconds)
epoch 007:  77%|â–Š| 4263/5551 [22:53:50<6:53:33, 19.27s/it, loss=1.024, ppl=2.03, wps=27121.1, ups=0.05, wpb=523489, bsz=8824.5, num_updates=37200, lr=6.69725e-05, gnorm=0.091, clip=15, loss_scale=8, train_wall=7[2022-11-20 22:39:17,533][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  77%|â–Š| 4277/5551 [22:58:22<6:51:49, 19.39s/it, loss=1.024, ppl=2.03, wps=27121.1, ups=0.05, wpb=523489, bsz=8824.5, num_updates=37200, lr=6.69725e-05, gnorm=0.091, clip=15, loss_scale=8, train_wall=7[2022-11-20 22:43:48,599][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  80%|â–Š| 4444/5551 [23:52:03<5:56:02, 19.30s/it, loss=1.025, ppl=2.04, wps=27066.8, ups=0.05, wpb=522814, bsz=8823.7, num_updates=37360, lr=6.55046e-05, gnorm=0.092, clip=12.5, loss_scale=4, train_wall[2022-11-20 23:37:30,205][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-20 23:37:32,241][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.889 | ppl 3.7 | wps 166755 | wpb 10521.6 | bsz 178.1 | num_updates 37400 | best_loss 1.419                                    
[2022-11-20 23:37:32,242][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 37400 updates
[2022-11-20 23:37:32,242][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_37400.pt
[2022-11-20 23:37:36,712][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_37400.pt
[2022-11-20 23:37:39,703][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_37400.pt (epoch 7 @ 37400 updates, score 1.889) (writing took 7.461029103025794 seconds)
epoch 007:  80%|â–Š| 4454/5551 [23:55:25<5:52:53, 19.30s/it, loss=1.024, ppl=2.03, wps=27058.6, ups=0.05, wpb=522456, bsz=8766.4, num_updates=37400, lr=6.51376e-05, gnorm=0.092, clip=10, loss_scale=4, train_wall=7[2022-11-20 23:40:51,766][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  83%|â–Š| 4624/5551 [24:50:02<4:58:10, 19.30s/it, loss=1.022, ppl=2.03, wps=27151.6, ups=0.05, wpb=523460, bsz=8525.8, num_updates=37560, lr=6.36697e-05, gnorm=0.096, clip=27.5, loss_scale=8, train_wall[2022-11-21 00:35:29,165][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  84%|â–Š| 4646/5551 [24:57:06<4:51:28, 19.32s/it, loss=1.022, ppl=2.03, wps=27151.6, ups=0.05, wpb=523460, bsz=8525.8, num_updates=37560, lr=6.36697e-05, gnorm=0.096, clip=27.5, loss_scale=8, train_wall[2022-11-21 00:42:33,084][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 00:42:35,117][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.711 | ppl 3.27 | wps 167501 | wpb 10521.6 | bsz 178.1 | num_updates 37600 | best_loss 1.419                                   
[2022-11-21 00:42:35,117][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 37600 updates
[2022-11-21 00:42:35,118][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_37600.pt
[2022-11-21 00:42:39,630][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_37600.pt
[2022-11-21 00:42:42,582][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_37600.pt (epoch 7 @ 37600 updates, score 1.711) (writing took 7.465196553617716 seconds)
epoch 007:  85%|â–Š| 4722/5551 [25:21:42<4:26:16, 19.27s/it, loss=1.024, ppl=2.03, wps=26776.6, ups=0.05, wpb=522869, bsz=8706.6, num_updates=37640, lr=6.29358e-05, gnorm=0.091, clip=10, loss_scale=4, train_wall=7[2022-11-21 01:07:09,038][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  87%|â–Š| 4828/5551 [25:55:44<3:53:03, 19.34s/it, loss=1.023, ppl=2.03, wps=27101.7, ups=0.05, wpb=521364, bsz=8755.7, num_updates=37760, lr=6.18349e-05, gnorm=0.096, clip=22.5, loss_scale=8, train_wall[2022-11-21 01:41:10,764][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  87%|â–Š| 4848/5551 [26:02:10<3:46:04, 19.30s/it, loss=1.023, ppl=2.03, wps=27101.7, ups=0.05, wpb=521364, bsz=8755.7, num_updates=37760, lr=6.18349e-05, gnorm=0.096, clip=22.5, loss_scale=8, train_wall[2022-11-21 01:47:37,470][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 01:47:39,496][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.651 | ppl 3.14 | wps 166405 | wpb 10521.6 | bsz 178.1 | num_updates 37800 | best_loss 1.419                                   
[2022-11-21 01:47:39,496][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 37800 updates
[2022-11-21 01:47:39,496][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_37800.pt
[2022-11-21 01:47:43,954][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_37800.pt
[2022-11-21 01:47:46,889][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_37800.pt (epoch 7 @ 37800 updates, score 1.651) (writing took 7.393032619729638 seconds)
epoch 007:  88%|â–‰| 4901/5551 [26:19:22<3:29:32, 19.34s/it, loss=1.024, ppl=2.03, wps=26803.2, ups=0.05, wpb=523175, bsz=8652.8, num_updates=37840, lr=6.11009e-05, gnorm=0.097, clip=22.5, loss_scale=4, train_wall[2022-11-21 02:04:49,117][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  91%|â–‰| 5049/5551 [27:06:56<2:40:52, 19.23s/it, loss=1.023, ppl=2.03, wps=27175.7, ups=0.05, wpb=524094, bsz=8670.7, num_updates=37960, lr=6e-05, gnorm=0.094, clip=20, loss_scale=4, train_wall=756, gb[2022-11-21 02:52:23,333][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 02:52:25,403][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.704 | ppl 3.26 | wps 167876 | wpb 10521.6 | bsz 178.1 | num_updates 38000 | best_loss 1.419                                   
[2022-11-21 02:52:25,404][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 38000 updates
[2022-11-21 02:52:25,404][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_38000.pt
[2022-11-21 02:52:29,826][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_38000.pt
[2022-11-21 02:52:32,787][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_38000.pt (epoch 7 @ 38000 updates, score 1.704) (writing took 7.382965959608555 seconds)
epoch 007:  92%|â–‰| 5108/5551 [27:26:05<2:23:28, 19.43s/it, loss=1.023, ppl=2.03, wps=26784.9, ups=0.05, wpb=523551, bsz=8823.2, num_updates=38040, lr=5.92661e-05, gnorm=0.094, clip=25, loss_scale=8, train_wall=7[2022-11-21 03:11:31,691][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  94%|â–‰| 5207/5551 [27:57:53<1:50:54, 19.35s/it, loss=1.023, ppl=2.03, wps=27083.1, ups=0.05, wpb=521403, bsz=8526.8, num_updates=38120, lr=5.85321e-05, gnorm=0.089, clip=0, loss_scale=4, train_wall=75[2022-11-21 03:43:19,372][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 007:  95%|â–‰| 5251/5551 [28:12:02<1:36:06, 19.22s/it, loss=1.023, ppl=2.03, wps=26481.2, ups=0.05, wpb=523537, bsz=8886.5, num_updates=38160, lr=5.81651e-05, gnorm=0.092, clip=15, loss_scale=4, train_wall=7[2022-11-21 03:57:28,969][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 03:57:30,999][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.746 | ppl 3.35 | wps 167115 | wpb 10521.6 | bsz 178.1 | num_updates 38200 | best_loss 1.419                                   
[2022-11-21 03:57:30,999][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 38200 updates
[2022-11-21 03:57:31,000][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_38200.pt
[2022-11-21 03:57:35,407][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_38200.pt
[2022-11-21 03:57:38,267][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_38200.pt (epoch 7 @ 38200 updates, score 1.746) (writing took 7.267155337147415 seconds)
epoch 007:  95%|â–‰| 5267/5551 [28:17:22<1:31:20, 19.30s/it, loss=1.022, ppl=2.03, wps=27115.6, ups=0.05, wpb=523200, bsz=8743.2, num_updates=38200, lr=5.77982e-05, gnorm=0.096, clip=25, loss_scale=4, train_wall=7[2022-11-21 04:02:49,043][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  97%|â–‰| 5389/5551 [28:56:32<52:13, 19.34s/it, loss=1.024, ppl=2.03, wps=27148.4, ups=0.05, wpb=523336, bsz=8569.1, num_updates=38320, lr=5.66972e-05, gnorm=0.092, clip=12.5, loss_scale=4, train_wall=7[2022-11-21 04:41:59,331][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007:  98%|â–‰| 5453/5551 [29:17:07<31:23, 19.22s/it, loss=1.023, ppl=2.03, wps=26400.9, ups=0.05, wpb=522644, bsz=9118.4, num_updates=38360, lr=5.63303e-05, gnorm=0.092, clip=15, loss_scale=2, train_wall=776[2022-11-21 05:02:34,716][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 05:02:36,753][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.855 | ppl 3.62 | wps 166857 | wpb 10521.6 | bsz 178.1 | num_updates 38400 | best_loss 1.419                                   
[2022-11-21 05:02:36,754][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 38400 updates
[2022-11-21 05:02:36,754][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_38400.pt
[2022-11-21 05:02:41,203][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_7_38400.pt
[2022-11-21 05:02:44,109][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_7_38400.pt (epoch 7 @ 38400 updates, score 1.855) (writing took 7.355063003487885 seconds)
epoch 007:  99%|â–‰| 5494/5551 [29:30:27<18:20, 19.30s/it, loss=1.022, ppl=2.03, wps=26718.4, ups=0.05, wpb=521342, bsz=8545.6, num_updates=38440, lr=5.55963e-05, gnorm=0.092, clip=15, loss_scale=4, train_wall=754[2022-11-21 05:15:54,676][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 007: 100%|â–‰| 5550/5551 [29:48:26<00:19, 19.15s/it, loss=1.022, ppl=2.03, wps=26423.8, ups=0.05, wpb=522337, bsz=8571.9, num_updates=38480, lr=5.52294e-05, gnorm=0.091, clip=12.5, loss_scale=2, train_wall=7[2022-11-21 05:33:50,164][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 05:33:52,213][valid][INFO] - epoch 007 | valid on 'valid' subset | loss 1.648 | ppl 3.13 | wps 166149 | wpb 10521.6 | bsz 178.1 | num_updates 38496 | best_loss 1.419                                   
[2022-11-21 05:33:52,214][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 7 @ 38496 updates
[2022-11-21 05:33:52,214][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint7.pt
[2022-11-21 05:33:56,687][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint7.pt
[2022-11-21 05:33:59,595][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint7.pt (epoch 7 @ 38496 updates, score 1.648) (writing took 7.380831231363118 seconds)
[2022-11-21 05:33:59,801][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)                                                                                                                    
[2022-11-21 05:33:59,803][train][INFO] - epoch 007 | loss 1.029 | ppl 2.04 | wps 26794.5 | ups 0.05 | wpb 522611 | bsz 8747 | num_updates 38496 | lr 5.50826e-05 | gnorm 0.097 | clip 27.3 | loss_scale 2 | train_wall 104966 | gb_free 6.7 | wall 753006
[2022-11-21 05:34:00,331][fairseq.data.iterators][INFO] - grouped total_num_itrs = 5551
epoch 008:   0%|                                                                                                                                                                          | 0/5551 [00:00<?, ?it/s][2022-11-21 05:34:01,803][fairseq.trainer][INFO] - begin training epoch 8
[2022-11-21 05:34:01,804][fairseq_cli.train][INFO] - Start iterating over samples
epoch 008:   2%| | 103/5551 [33:04<29:14:21, 19.32s/it, loss=1.019, ppl=2.03, wps=27060.8, ups=0.05, wpb=521573, bsz=8438, num_updates=38560, lr=5.44954e-05, gnorm=0.091, clip=10, loss_scale=4, train_wall=757, g[2022-11-21 06:07:25,497][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 06:07:27,535][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.773 | ppl 3.42 | wps 166512 | wpb 10521.6 | bsz 178.1 | num_updates 38600 | best_loss 1.419                                   
[2022-11-21 06:07:27,536][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 38600 updates
[2022-11-21 06:07:27,536][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_38600.pt
[2022-11-21 06:07:32,034][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_38600.pt
[2022-11-21 06:07:34,997][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_38600.pt (epoch 8 @ 38600 updates, score 1.773) (writing took 7.461587635800242 seconds)
epoch 008:   3%| | 173/5551 [55:42<28:58:08, 19.39s/it, loss=1.019, ppl=2.03, wps=26789, ups=0.05, wpb=521559, bsz=8654.6, num_updates=38640, lr=5.37615e-05, gnorm=0.093, clip=22.5, loss_scale=8, train_wall=753,[2022-11-21 06:30:03,464][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:   5%| | 283/5551 [1:31:05<28:18:12, 19.34s/it, loss=1.019, ppl=2.03, wps=27116.7, ups=0.05, wpb=523818, bsz=8716.3, num_updates=38760, lr=5.26606e-05, gnorm=0.093, clip=22.5, loss_scale=8, train_wall=[2022-11-21 07:05:26,751][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:   5%| | 305/5551 [1:38:11<28:15:25, 19.39s/it, loss=1.019, ppl=2.03, wps=27116.7, ups=0.05, wpb=523818, bsz=8716.3, num_updates=38760, lr=5.26606e-05, gnorm=0.093, clip=22.5, loss_scale=8, train_wall=[2022-11-21 07:12:32,337][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 07:12:34,385][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.724 | ppl 3.3 | wps 165887 | wpb 10521.6 | bsz 178.1 | num_updates 38800 | best_loss 1.419                                    
[2022-11-21 07:12:34,386][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 38800 updates
[2022-11-21 07:12:34,386][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_38800.pt
[2022-11-21 07:12:38,810][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_38800.pt
[2022-11-21 07:12:41,665][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_38800.pt (epoch 8 @ 38800 updates, score 1.724) (writing took 7.279391065239906 seconds)
epoch 008:   8%| | 417/5551 [2:14:19<27:32:48, 19.32s/it, loss=1.019, ppl=2.03, wps=27179, ups=0.05, wpb=523700, bsz=8909.3, num_updates=38880, lr=5.15596e-05, gnorm=0.091, clip=15, loss_scale=8, train_wall=755,[2022-11-21 07:48:41,020][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:   9%| | 506/5551 [2:42:55<27:03:35, 19.31s/it, loss=1.019, ppl=2.03, wps=27093.2, ups=0.05, wpb=522531, bsz=8913.5, num_updates=38960, lr=5.08257e-05, gnorm=0.088, clip=7.5, loss_scale=4, train_wall=7[2022-11-21 08:17:16,746][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 08:17:18,783][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.68 | ppl 3.2 | wps 167438 | wpb 10521.6 | bsz 178.1 | num_updates 39000 | best_loss 1.419                                     
[2022-11-21 08:17:18,783][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 39000 updates
[2022-11-21 08:17:18,784][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_39000.pt
[2022-11-21 08:17:23,233][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_39000.pt
[2022-11-21 08:17:26,166][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_39000.pt (epoch 8 @ 39000 updates, score 1.68) (writing took 7.382523552514613 seconds)
epoch 008:  10%| | 538/5551 [2:53:21<26:49:09, 19.26s/it, loss=1.02, ppl=2.03, wps=27083.8, ups=0.05, wpb=522008, bsz=8942, num_updates=39000, lr=5.04587e-05, gnorm=0.092, clip=20, loss_scale=8, train_wall=756, [2022-11-21 08:27:42,320][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  10%| | 557/5551 [2:59:27<26:35:47, 19.17s/it, loss=1.019, ppl=2.03, wps=26165.2, ups=0.05, wpb=522819, bsz=8666.6, num_updates=39040, lr=5.00917e-05, gnorm=0.089, clip=7.5, loss_scale=4, train_wall=7[2022-11-21 08:33:49,186][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 008:  13%|â–| 708/5551 [3:48:03<26:01:58, 19.35s/it, loss=1.018, ppl=2.02, wps=27077.6, ups=0.05, wpb=521558, bsz=8605.6, num_updates=39160, lr=4.89908e-05, gnorm=0.096, clip=15, loss_scale=4, train_wall=75[2022-11-21 09:22:24,937][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 09:22:26,975][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.672 | ppl 3.19 | wps 165901 | wpb 10521.6 | bsz 178.1 | num_updates 39200 | best_loss 1.419                                   
[2022-11-21 09:22:26,975][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 39200 updates
[2022-11-21 09:22:26,976][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_39200.pt
[2022-11-21 09:22:31,433][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_39200.pt
[2022-11-21 09:22:34,229][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_39200.pt (epoch 8 @ 39200 updates, score 1.672) (writing took 7.253984468989074 seconds)
epoch 008:  13%|â–| 748/5551 [4:01:05<25:40:48, 19.25s/it, loss=1.019, ppl=2.03, wps=27035.3, ups=0.05, wpb=522068, bsz=8950.3, num_updates=39200, lr=4.86239e-05, gnorm=0.101, clip=45, loss_scale=4, train_wall=75[2022-11-21 09:35:26,666][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  16%|â–| 909/5551 [4:52:51<24:50:10, 19.26s/it, loss=1.019, ppl=2.03, wps=27042.5, ups=0.05, wpb=522180, bsz=8779.1, num_updates=39360, lr=4.7156e-05, gnorm=0.089, clip=10, loss_scale=8, train_wall=758[2022-11-21 10:27:12,861][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 10:27:14,913][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.767 | ppl 3.4 | wps 166218 | wpb 10521.6 | bsz 178.1 | num_updates 39400 | best_loss 1.419                                    
[2022-11-21 10:27:14,914][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 39400 updates
[2022-11-21 10:27:14,914][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_39400.pt
[2022-11-21 10:27:19,450][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_39400.pt
[2022-11-21 10:27:22,413][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_39400.pt (epoch 8 @ 39400 updates, score 1.767) (writing took 7.499382335692644 seconds)
epoch 008:  17%|â–| 922/5551 [4:57:12<24:53:08, 19.35s/it, loss=1.018, ppl=2.03, wps=27072.5, ups=0.05, wpb=522692, bsz=8591.7, num_updates=39400, lr=4.6789e-05, gnorm=0.09, clip=10, loss_scale=8, train_wall=757,[2022-11-21 10:31:33,260][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 008:  17%|â–| 944/5551 [5:04:17<24:36:45, 19.23s/it, loss=1.018, ppl=2.03, wps=27072.5, ups=0.05, wpb=522692, bsz=8591.7, num_updates=39400, lr=4.6789e-05, gnorm=0.09, clip=10, loss_scale=8, train_wall=757,[2022-11-21 10:38:38,979][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  19%|â–| 1041/5551 [5:35:30<24:12:39, 19.33s/it, loss=1.018, ppl=2.03, wps=27040, ups=0.05, wpb=522831, bsz=8794.1, num_updates=39520, lr=4.56881e-05, gnorm=0.087, clip=5, loss_scale=8, train_wall=759,[2022-11-21 11:09:51,570][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  20%|â–| 1112/5551 [5:58:21<23:53:02, 19.37s/it, loss=1.017, ppl=2.02, wps=26475.6, ups=0.05, wpb=523514, bsz=8491.9, num_updates=39560, lr=4.53211e-05, gnorm=0.091, clip=15, loss_scale=4, train_wall=7[2022-11-21 11:32:42,296][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 11:32:44,342][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.753 | ppl 3.37 | wps 165445 | wpb 10521.6 | bsz 178.1 | num_updates 39600 | best_loss 1.419                                   
[2022-11-21 11:32:44,343][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 39600 updates
[2022-11-21 11:32:44,343][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_39600.pt
[2022-11-21 11:32:48,796][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_39600.pt
[2022-11-21 11:32:51,766][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_39600.pt (epoch 8 @ 39600 updates, score 1.753) (writing took 7.422786084935069 seconds)
epoch 008:  21%|â–| 1139/5551 [6:07:12<23:38:37, 19.29s/it, loss=1.018, ppl=2.03, wps=27103.8, ups=0.05, wpb=523759, bsz=8984.5, num_updates=39600, lr=4.49541e-05, gnorm=0.093, clip=22.5, loss_scale=4, train_wall[2022-11-21 11:41:33,538][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  24%|â–| 1313/5551 [7:03:10<22:34:43, 19.18s/it, loss=1.016, ppl=2.02, wps=27073.1, ups=0.05, wpb=523121, bsz=8991.1, num_updates=39760, lr=4.34862e-05, gnorm=0.086, clip=0, loss_scale=8, train_wall=75[2022-11-21 12:37:31,992][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 008:  24%|â–| 1314/5551 [7:03:30<22:38:03, 19.23s/it, loss=1.016, ppl=2.02, wps=27073.1, ups=0.05, wpb=523121, bsz=8991.1, num_updates=39760, lr=4.34862e-05, gnorm=0.086, clip=0, loss_scale=8, train_wall=75[2022-11-21 12:37:50,976][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 12:37:53,017][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.678 | ppl 3.2 | wps 166767 | wpb 10521.6 | bsz 178.1 | num_updates 39800 | best_loss 1.419                                    
[2022-11-21 12:37:53,018][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 39800 updates
[2022-11-21 12:37:53,018][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_39800.pt
[2022-11-21 12:37:57,500][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_39800.pt
[2022-11-21 12:38:00,544][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_39800.pt (epoch 8 @ 39800 updates, score 1.678) (writing took 7.5262994132936 seconds)
epoch 008:  24%|â–| 1335/5551 [7:10:24<22:32:17, 19.25s/it, loss=1.018, ppl=2.02, wps=26397.7, ups=0.05, wpb=521233, bsz=8855.2, num_updates=39800, lr=4.31193e-05, gnorm=0.086, clip=0, loss_scale=8, train_wall=77[2022-11-21 12:44:45,993][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  26%|â–Ž| 1452/5551 [7:48:02<21:50:11, 19.18s/it, loss=1.015, ppl=2.02, wps=27093.6, ups=0.05, wpb=522514, bsz=8537.9, num_updates=39920, lr=4.20183e-05, gnorm=0.087, clip=5, loss_scale=8, train_wall=75[2022-11-21 13:22:23,139][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  27%|â–Ž| 1516/5551 [8:08:36<21:36:24, 19.28s/it, loss=1.018, ppl=2.02, wps=26461.3, ups=0.05, wpb=523107, bsz=8849, num_updates=39960, lr=4.16514e-05, gnorm=0.088, clip=7.5, loss_scale=4, train_wall=77[2022-11-21 13:42:57,845][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 13:42:59,901][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.769 | ppl 3.41 | wps 165224 | wpb 10521.6 | bsz 178.1 | num_updates 40000 | best_loss 1.419                                   
[2022-11-21 13:42:59,902][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 40000 updates
[2022-11-21 13:42:59,902][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_40000.pt
[2022-11-21 13:43:04,357][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_40000.pt
[2022-11-21 13:43:07,141][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_40000.pt (epoch 8 @ 40000 updates, score 1.769) (writing took 7.238693688996136 seconds)
epoch 008:  29%|â–Ž| 1626/5551 [8:44:10<21:02:15, 19.30s/it, loss=1.017, ppl=2.02, wps=27079.3, ups=0.05, wpb=522980, bsz=8643.7, num_updates=40080, lr=4.05505e-05, gnorm=0.09, clip=15, loss_scale=8, train_wall=75[2022-11-21 14:18:31,477][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 008:  31%|â–Ž| 1703/5551 [9:08:57<20:36:13, 19.28s/it, loss=1.017, ppl=2.02, wps=27132.5, ups=0.05, wpb=524109, bsz=9011.9, num_updates=40160, lr=3.98165e-05, gnorm=0.087, clip=7.5, loss_scale=8, train_wall=[2022-11-21 14:43:18,586][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  31%|â–Ž| 1718/5551 [9:13:46<20:33:18, 19.31s/it, loss=1.017, ppl=2.02, wps=27132.5, ups=0.05, wpb=524109, bsz=9011.9, num_updates=40160, lr=3.98165e-05, gnorm=0.087, clip=7.5, loss_scale=8, train_wall=[2022-11-21 14:48:07,699][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 14:48:09,746][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.768 | ppl 3.41 | wps 166830 | wpb 10521.6 | bsz 178.1 | num_updates 40200 | best_loss 1.419                                   
[2022-11-21 14:48:09,747][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 40200 updates
[2022-11-21 14:48:09,747][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_40200.pt
[2022-11-21 14:48:14,193][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_40200.pt
[2022-11-21 14:48:17,124][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_40200.pt (epoch 8 @ 40200 updates, score 1.768) (writing took 7.377132800407708 seconds)
epoch 008:  33%|â–Ž| 1854/5551 [9:57:41<19:46:47, 19.26s/it, loss=1.015, ppl=2.02, wps=27089.7, ups=0.05, wpb=522431, bsz=8835.3, num_updates=40320, lr=3.83486e-05, gnorm=0.087, clip=2.5, loss_scale=8, train_wall=[2022-11-21 15:32:02,269][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  35%|â–Ž| 1919/5551 [10:18:33<19:28:41, 19.31s/it, loss=1.014, ppl=2.02, wps=26525.7, ups=0.05, wpb=523229, bsz=8736.5, num_updates=40360, lr=3.79817e-05, gnorm=0.094, clip=32.5, loss_scale=4, train_wal[2022-11-21 15:52:55,137][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 15:52:57,171][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.757 | ppl 3.38 | wps 167338 | wpb 10521.6 | bsz 178.1 | num_updates 40400 | best_loss 1.419                                   
[2022-11-21 15:52:57,172][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 40400 updates
[2022-11-21 15:52:57,172][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_40400.pt
[2022-11-21 15:53:01,639][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_40400.pt
[2022-11-21 15:53:04,348][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_40400.pt (epoch 8 @ 40400 updates, score 1.757) (writing took 7.176238523796201 seconds)
epoch 008:  35%|â–Ž| 1950/5551 [10:28:39<19:17:09, 19.28s/it, loss=1.016, ppl=2.02, wps=27057.6, ups=0.05, wpb=522130, bsz=8825.6, num_updates=40400, lr=3.76147e-05, gnorm=0.09, clip=10, loss_scale=4, train_wall=7[2022-11-21 16:03:00,704][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  38%|â–| 2116/5551 [11:21:59<18:28:26, 19.36s/it, loss=1.015, ppl=2.02, wps=27091.1, ups=0.05, wpb=522780, bsz=8997.5, num_updates=40560, lr=3.61468e-05, gnorm=0.087, clip=7.5, loss_scale=8, train_wall[2022-11-21 16:56:20,127][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  38%|â–| 2121/5551 [11:23:35<18:25:42, 19.34s/it, loss=1.015, ppl=2.02, wps=27091.1, ups=0.05, wpb=522780, bsz=8997.5, num_updates=40560, lr=3.61468e-05, gnorm=0.087, clip=7.5, loss_scale=8, train_wall[2022-11-21 16:57:56,530][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 16:57:58,566][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.69 | ppl 3.23 | wps 167084 | wpb 10521.6 | bsz 178.1 | num_updates 40600 | best_loss 1.419                                    
[2022-11-21 16:57:58,566][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 40600 updates
[2022-11-21 16:57:58,567][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_40600.pt
[2022-11-21 16:58:03,022][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_40600.pt
[2022-11-21 16:58:05,975][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_40600.pt (epoch 8 @ 40600 updates, score 1.69) (writing took 7.409056133590639 seconds)
epoch 008:  40%|â–| 2214/5551 [11:53:38<17:51:01, 19.26s/it, loss=1.017, ppl=2.02, wps=27070.5, ups=0.05, wpb=522716, bsz=9137.8, num_updates=40680, lr=3.50459e-05, gnorm=0.087, clip=12.5, loss_scale=8, train_wal[2022-11-21 17:27:59,077][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  42%|â–| 2322/5551 [12:28:18<17:29:26, 19.50s/it, loss=1.015, ppl=2.02, wps=27170.5, ups=0.05, wpb=523044, bsz=8752.2, num_updates=40760, lr=3.43119e-05, gnorm=0.086, clip=2.5, loss_scale=4, train_wall[2022-11-21 18:02:39,834][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 18:02:41,853][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.685 | ppl 3.22 | wps 167197 | wpb 10521.6 | bsz 178.1 | num_updates 40800 | best_loss 1.419                                   
[2022-11-21 18:02:41,854][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 40800 updates
[2022-11-21 18:02:41,854][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_40800.pt
[2022-11-21 18:02:46,324][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_40800.pt
[2022-11-21 18:02:49,340][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_40800.pt (epoch 8 @ 40800 updates, score 1.685) (writing took 7.4856707053259015 seconds)
epoch 008:  42%|â–| 2337/5551 [12:33:18<17:13:57, 19.30s/it, loss=1.016, ppl=2.02, wps=27174.4, ups=0.05, wpb=524102, bsz=8819.6, num_updates=40800, lr=3.3945e-05, gnorm=0.085, clip=0, loss_scale=8, train_wall=75[2022-11-21 18:07:39,340][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  44%|â–| 2423/5551 [13:00:54<16:46:28, 19.31s/it, loss=1.014, ppl=2.02, wps=27147.5, ups=0.05, wpb=521727, bsz=8684.2, num_updates=40880, lr=3.3211e-05, gnorm=0.087, clip=5, loss_scale=4, train_wall=75[2022-11-21 18:35:15,090][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  45%|â–| 2524/5551 [13:33:22<16:06:32, 19.16s/it, loss=1.016, ppl=2.02, wps=27017.1, ups=0.05, wpb=520610, bsz=8819.9, num_updates=40960, lr=3.24771e-05, gnorm=0.09, clip=15, loss_scale=4, train_wall=7[2022-11-21 19:07:44,107][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 19:07:46,141][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.745 | ppl 3.35 | wps 166592 | wpb 10521.6 | bsz 178.1 | num_updates 41000 | best_loss 1.419                                   
[2022-11-21 19:07:46,142][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 41000 updates
[2022-11-21 19:07:46,142][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_41000.pt
[2022-11-21 19:07:50,602][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_41000.pt
[2022-11-21 19:07:53,314][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_41000.pt (epoch 8 @ 41000 updates, score 1.745) (writing took 7.1721195820719 seconds)
epoch 008:  47%|â–| 2596/5551 [13:56:38<15:42:00, 19.13s/it, loss=1.014, ppl=2.02, wps=26768.8, ups=0.05, wpb=521380, bsz=8537.8, num_updates=41040, lr=3.17431e-05, gnorm=0.089, clip=10, loss_scale=8, train_wall=[2022-11-21 19:30:59,393][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 008:  48%|â–| 2683/5551 [14:24:34<15:21:51, 19.29s/it, loss=1.014, ppl=2.02, wps=27144.7, ups=0.05, wpb=523046, bsz=8552.5, num_updates=41120, lr=3.10092e-05, gnorm=0.084, clip=2.5, loss_scale=8, train_wall[2022-11-21 19:58:55,282][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 008:  49%|â–| 2726/5551 [14:38:25<15:09:53, 19.33s/it, loss=1.014, ppl=2.02, wps=26485.7, ups=0.05, wpb=522476, bsz=8529.6, num_updates=41160, lr=3.06422e-05, gnorm=0.09, clip=7.5, loss_scale=8, train_wall=[2022-11-21 20:12:46,900][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 20:12:48,938][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.821 | ppl 3.53 | wps 166930 | wpb 10521.6 | bsz 178.1 | num_updates 41200 | best_loss 1.419                                   
[2022-11-21 20:12:48,939][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 41200 updates
[2022-11-21 20:12:48,939][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_41200.pt
[2022-11-21 20:12:53,383][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_41200.pt
[2022-11-21 20:12:56,290][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_41200.pt (epoch 8 @ 41200 updates, score 1.821) (writing took 7.350759459659457 seconds)
epoch 008:  49%|â–| 2737/5551 [14:42:08<15:12:09, 19.45s/it, loss=1.013, ppl=2.02, wps=27073.1, ups=0.05, wpb=523507, bsz=8859.4, num_updates=41200, lr=3.02752e-05, gnorm=0.085, clip=5, loss_scale=8, train_wall=7[2022-11-21 20:16:29,140][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  53%|â–Œ| 2916/5551 [15:39:38<14:12:27, 19.41s/it, loss=1.014, ppl=2.02, wps=27180.4, ups=0.05, wpb=524020, bsz=8814.9, num_updates=41360, lr=2.88073e-05, gnorm=0.087, clip=5, loss_scale=8, train_wall=7[2022-11-21 21:13:59,994][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 008:  53%|â–Œ| 2928/5551 [15:43:31<14:08:02, 19.40s/it, loss=1.014, ppl=2.02, wps=27180.4, ups=0.05, wpb=524020, bsz=8814.9, num_updates=41360, lr=2.88073e-05, gnorm=0.087, clip=5, loss_scale=8, train_wall=7[2022-11-21 21:17:52,195][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 21:17:54,233][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.749 | ppl 3.36 | wps 167212 | wpb 10521.6 | bsz 178.1 | num_updates 41400 | best_loss 1.419                                   
[2022-11-21 21:17:54,234][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 41400 updates
[2022-11-21 21:17:54,234][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_41400.pt
[2022-11-21 21:17:58,689][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_41400.pt
[2022-11-21 21:18:01,661][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_41400.pt (epoch 8 @ 41400 updates, score 1.749) (writing took 7.426814466714859 seconds)
epoch 008:  54%|â–Œ| 2999/5551 [16:06:26<13:41:16, 19.31s/it, loss=1.014, ppl=2.02, wps=26786.3, ups=0.05, wpb=521663, bsz=8807.6, num_updates=41440, lr=2.80734e-05, gnorm=0.085, clip=0, loss_scale=8, train_wall=7[2022-11-21 21:40:47,074][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  56%|â–Œ| 3129/5551 [16:48:12<12:58:25, 19.28s/it, loss=1.015, ppl=2.02, wps=27147, ups=0.05, wpb=523215, bsz=8661.6, num_updates=41560, lr=2.69725e-05, gnorm=0.088, clip=7.5, loss_scale=8, train_wall=7[2022-11-21 22:22:33,876][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 22:22:35,914][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.805 | ppl 3.49 | wps 166120 | wpb 10521.6 | bsz 178.1 | num_updates 41600 | best_loss 1.419                                   
[2022-11-21 22:22:35,915][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 41600 updates
[2022-11-21 22:22:35,915][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_41600.pt
[2022-11-21 22:22:40,365][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_41600.pt
[2022-11-21 22:22:43,141][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_41600.pt (epoch 8 @ 41600 updates, score 1.805) (writing took 7.226484191603959 seconds)
epoch 008:  56%|â–Œ| 3131/5551 [16:49:00<14:13:41, 21.17s/it, loss=1.013, ppl=2.02, wps=27107, ups=0.05, wpb=521473, bsz=8483, num_updates=41600, lr=2.66055e-05, gnorm=0.085, clip=0, loss_scale=8, train_wall=756, [2022-11-21 22:23:21,522][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  60%|â–Œ| 3304/5551 [17:44:38<12:01:45, 19.27s/it, loss=1.014, ppl=2.02, wps=27119.1, ups=0.05, wpb=523456, bsz=8846.1, num_updates=41760, lr=2.51376e-05, gnorm=0.085, clip=0, loss_scale=8, train_wall=7[2022-11-21 23:18:59,244][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 008:  60%|â–Œ| 3326/5551 [17:51:42<11:56:43, 19.33s/it, loss=1.014, ppl=2.02, wps=27119.1, ups=0.05, wpb=523456, bsz=8846.1, num_updates=41760, lr=2.51376e-05, gnorm=0.085, clip=0, loss_scale=8, train_wall=7[2022-11-21 23:26:03,342][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  60%|â–Œ| 3332/5551 [17:53:37<11:51:33, 19.24s/it, loss=1.014, ppl=2.02, wps=27119.1, ups=0.05, wpb=523456, bsz=8846.1, num_updates=41760, lr=2.51376e-05, gnorm=0.085, clip=0, loss_scale=8, train_wall=7[2022-11-21 23:27:58,939][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-21 23:28:00,975][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.806 | ppl 3.5 | wps 167641 | wpb 10521.6 | bsz 178.1 | num_updates 41800 | best_loss 1.419                                    
[2022-11-21 23:28:00,976][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 41800 updates
[2022-11-21 23:28:00,976][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_41800.pt
[2022-11-21 23:28:05,430][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_41800.pt
[2022-11-21 23:28:08,295][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_41800.pt (epoch 8 @ 41800 updates, score 1.806) (writing took 7.319350883364677 seconds)
epoch 008:  62%|â–Œ| 3432/5551 [18:25:53<11:22:13, 19.32s/it, loss=1.013, ppl=2.02, wps=27117.4, ups=0.05, wpb=522275, bsz=8668.8, num_updates=41880, lr=2.40367e-05, gnorm=0.087, clip=2.5, loss_scale=8, train_wall[2022-11-22 00:00:14,846][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  64%|â–‹| 3533/5551 [18:58:20<10:45:15, 19.18s/it, loss=1.012, ppl=2.02, wps=27110.7, ups=0.05, wpb=522961, bsz=8754.4, num_updates=41960, lr=2.33028e-05, gnorm=0.085, clip=0, loss_scale=4, train_wall=7[2022-11-22 00:32:41,734][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 00:32:43,788][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.693 | ppl 3.23 | wps 165159 | wpb 10521.6 | bsz 178.1 | num_updates 42000 | best_loss 1.419                                   
[2022-11-22 00:32:43,789][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 42000 updates
[2022-11-22 00:32:43,789][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_42000.pt
[2022-11-22 00:32:48,250][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_42000.pt
[2022-11-22 00:32:51,301][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_42000.pt (epoch 8 @ 42000 updates, score 1.693) (writing took 7.512289225123823 seconds)
epoch 008:  64%|â–‹| 3568/5551 [19:09:44<10:32:51, 19.15s/it, loss=1.013, ppl=2.02, wps=27158, ups=0.05, wpb=523310, bsz=8693.9, num_updates=42000, lr=2.29358e-05, gnorm=0.083, clip=0, loss_scale=8, train_wall=755[2022-11-22 00:44:05,810][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  66%|â–‹| 3667/5551 [19:41:30<10:02:40, 19.19s/it, loss=1.012, ppl=2.02, wps=27135.3, ups=0.05, wpb=522567, bsz=8553.1, num_updates=42120, lr=2.18349e-05, gnorm=0.083, clip=0, loss_scale=8, train_wall=7[2022-11-22 01:15:52,011][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  67%|â–‹| 3735/5551 [20:03:23<9:47:23, 19.41s/it, loss=1.012, ppl=2.02, wps=26427.2, ups=0.05, wpb=521768, bsz=8553.9, num_updates=42160, lr=2.14679e-05, gnorm=0.084, clip=0, loss_scale=4, train_wall=77[2022-11-22 01:37:44,326][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 01:37:46,366][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.766 | ppl 3.4 | wps 166015 | wpb 10521.6 | bsz 178.1 | num_updates 42200 | best_loss 1.419                                    
[2022-11-22 01:37:46,367][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 42200 updates
[2022-11-22 01:37:46,367][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_42200.pt
[2022-11-22 01:37:50,813][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_42200.pt
[2022-11-22 01:37:53,783][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_42200.pt (epoch 8 @ 42200 updates, score 1.766) (writing took 7.415570083074272 seconds)
epoch 008:  69%|â–‹| 3825/5551 [20:32:28<9:14:25, 19.27s/it, loss=1.013, ppl=2.02, wps=27082.4, ups=0.05, wpb=522515, bsz=8642.1, num_updates=42280, lr=2.0367e-05, gnorm=0.081, clip=0, loss_scale=8, train_wall=757[2022-11-22 02:06:49,573][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  71%|â–‹| 3928/5551 [21:05:36<8:40:10, 19.23s/it, loss=1.012, ppl=2.02, wps=27076.4, ups=0.05, wpb=521917, bsz=8774.5, num_updates=42360, lr=1.9633e-05, gnorm=0.083, clip=0, loss_scale=4, train_wall=756[2022-11-22 02:39:57,025][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  71%|â–‹| 3937/5551 [21:08:29<8:38:20, 19.27s/it, loss=1.012, ppl=2.02, wps=27076.4, ups=0.05, wpb=521917, bsz=8774.5, num_updates=42360, lr=1.9633e-05, gnorm=0.083, clip=0, loss_scale=4, train_wall=756[2022-11-22 02:42:50,756][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 02:42:52,785][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.756 | ppl 3.38 | wps 166683 | wpb 10521.6 | bsz 178.1 | num_updates 42400 | best_loss 1.419                                   
[2022-11-22 02:42:52,786][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 42400 updates
[2022-11-22 02:42:52,786][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_42400.pt
[2022-11-22 02:42:57,233][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_42400.pt
[2022-11-22 02:43:00,152][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_42400.pt (epoch 8 @ 42400 updates, score 1.756) (writing took 7.3659584652632475 seconds)
epoch 008:  73%|â–‹| 4079/5551 [21:54:14<7:53:12, 19.29s/it, loss=1.011, ppl=2.02, wps=27076.5, ups=0.05, wpb=522343, bsz=8613.8, num_updates=42520, lr=1.81651e-05, gnorm=0.083, clip=0, loss_scale=8, train_wall=75[2022-11-22 03:28:35,107][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  75%|â–‹| 4138/5551 [22:13:12<7:35:05, 19.32s/it, loss=1.012, ppl=2.02, wps=26479.7, ups=0.05, wpb=522770, bsz=8727.4, num_updates=42560, lr=1.77982e-05, gnorm=0.081, clip=0, loss_scale=4, train_wall=77[2022-11-22 03:47:33,603][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 03:47:35,646][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.805 | ppl 3.49 | wps 166914 | wpb 10521.6 | bsz 178.1 | num_updates 42600 | best_loss 1.419                                   
[2022-11-22 03:47:35,647][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 42600 updates
[2022-11-22 03:47:35,647][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_42600.pt
[2022-11-22 03:47:40,110][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_42600.pt
[2022-11-22 03:47:42,986][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_42600.pt (epoch 8 @ 42600 updates, score 1.805) (writing took 7.33924235869199 seconds)
epoch 008:  76%|â–Š| 4207/5551 [22:35:32<7:15:38, 19.45s/it, loss=1.011, ppl=2.02, wps=26757.1, ups=0.05, wpb=522242, bsz=8927.9, num_updates=42640, lr=1.70642e-05, gnorm=0.084, clip=0, loss_scale=8, train_wall=75[2022-11-22 04:09:53,683][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  76%|â–Š| 4227/5551 [22:41:57<7:06:21, 19.32s/it, loss=1.011, ppl=2.02, wps=26546.9, ups=0.05, wpb=524443, bsz=8686.4, num_updates=42680, lr=1.66972e-05, gnorm=0.081, clip=0, loss_scale=4, train_wall=77[2022-11-22 04:16:18,846][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 008:  78%|â–Š| 4340/5551 [23:18:15<6:27:58, 19.22s/it, loss=1.012, ppl=2.02, wps=27177.6, ups=0.05, wpb=523198, bsz=8784.1, num_updates=42760, lr=1.59633e-05, gnorm=0.082, clip=0, loss_scale=2, train_wall=75[2022-11-22 04:52:36,224][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 04:52:38,270][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.746 | ppl 3.36 | wps 166667 | wpb 10521.6 | bsz 178.1 | num_updates 42800 | best_loss 1.419                                   
[2022-11-22 04:52:38,271][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 42800 updates
[2022-11-22 04:52:38,271][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_42800.pt
[2022-11-22 04:52:42,726][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_42800.pt
[2022-11-22 04:52:45,702][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_42800.pt (epoch 8 @ 42800 updates, score 1.746) (writing took 7.43079465534538 seconds)
epoch 008:  81%|â–Š| 4484/5551 [24:04:42<5:43:44, 19.33s/it, loss=1.011, ppl=2.01, wps=27106.4, ups=0.05, wpb=522504, bsz=8686.9, num_updates=42920, lr=1.44954e-05, gnorm=0.081, clip=0, loss_scale=8, train_wall=75[2022-11-22 05:39:03,149][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 008:  82%|â–Š| 4541/5551 [24:22:58<5:23:45, 19.23s/it, loss=1.012, ppl=2.02, wps=26441.9, ups=0.05, wpb=522659, bsz=8907.5, num_updates=42960, lr=1.41284e-05, gnorm=0.081, clip=0, loss_scale=8, train_wall=77[2022-11-22 05:57:19,728][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  82%|â–Š| 4542/5551 [24:23:17<5:24:29, 19.30s/it, loss=1.012, ppl=2.02, wps=26441.9, ups=0.05, wpb=522659, bsz=8907.5, num_updates=42960, lr=1.41284e-05, gnorm=0.081, clip=0, loss_scale=8, train_wall=77[2022-11-22 05:57:38,949][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 05:57:40,998][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.746 | ppl 3.35 | wps 165913 | wpb 10521.6 | bsz 178.1 | num_updates 43000 | best_loss 1.419                                   
[2022-11-22 05:57:40,999][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 43000 updates
[2022-11-22 05:57:40,999][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_43000.pt
[2022-11-22 05:57:45,408][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_43000.pt
[2022-11-22 05:57:48,293][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_43000.pt (epoch 8 @ 43000 updates, score 1.746) (writing took 7.294194410555065 seconds)
epoch 008:  84%|â–Š| 4642/5551 [24:55:35<4:52:42, 19.32s/it, loss=1.012, ppl=2.02, wps=27090.9, ups=0.05, wpb=523774, bsz=8707.8, num_updates=43080, lr=1.30275e-05, gnorm=0.082, clip=2.5, loss_scale=4, train_wall=[2022-11-22 06:29:57,099][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  85%|â–Š| 4743/5551 [25:28:04<4:18:46, 19.22s/it, loss=1.012, ppl=2.02, wps=27045.8, ups=0.05, wpb=522213, bsz=8744.2, num_updates=43160, lr=1.22936e-05, gnorm=0.08, clip=0, loss_scale=4, train_wall=757[2022-11-22 07:02:25,362][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 07:02:27,399][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.788 | ppl 3.45 | wps 167489 | wpb 10521.6 | bsz 178.1 | num_updates 43200 | best_loss 1.419                                   
[2022-11-22 07:02:27,400][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 43200 updates
[2022-11-22 07:02:27,400][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_43200.pt
[2022-11-22 07:02:31,860][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_43200.pt
[2022-11-22 07:02:34,738][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_43200.pt (epoch 8 @ 43200 updates, score 1.788) (writing took 7.33803703263402 seconds)
epoch 008:  87%|â–Š| 4816/5551 [25:51:41<3:55:28, 19.22s/it, loss=1.012, ppl=2.02, wps=26751.5, ups=0.05, wpb=523247, bsz=8995.3, num_updates=43240, lr=1.15596e-05, gnorm=0.079, clip=0, loss_scale=8, train_wall=75[2022-11-22 07:26:02,142][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 008:  87%|â–Š| 4833/5551 [25:57:08<3:50:59, 19.30s/it, loss=1.011, ppl=2.02, wps=26470.7, ups=0.05, wpb=521840, bsz=8617.3, num_updates=43280, lr=1.11927e-05, gnorm=0.081, clip=0, loss_scale=8, train_wall=77[2022-11-22 07:31:29,686][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  89%|â–‰| 4945/5551 [26:33:09<3:15:10, 19.32s/it, loss=1.013, ppl=2.02, wps=27084.3, ups=0.05, wpb=522832, bsz=8667.2, num_updates=43360, lr=1.04587e-05, gnorm=0.081, clip=2.5, loss_scale=4, train_wall=[2022-11-22 08:07:30,540][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 08:07:32,578][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.81 | ppl 3.51 | wps 166768 | wpb 10521.6 | bsz 178.1 | num_updates 43400 | best_loss 1.419                                    
[2022-11-22 08:07:32,578][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 43400 updates
[2022-11-22 08:07:32,579][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_43400.pt
[2022-11-22 08:07:37,033][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_43400.pt
[2022-11-22 08:07:39,954][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_43400.pt (epoch 8 @ 43400 updates, score 1.81) (writing took 7.375979790464044 seconds)
epoch 008:  89%|â–‰| 4965/5551 [26:39:44<3:08:05, 19.26s/it, loss=1.01, ppl=2.01, wps=27079.5, ups=0.05, wpb=521968, bsz=8729.1, num_updates=43400, lr=1.00917e-05, gnorm=0.08, clip=0, loss_scale=8, train_wall=756,[2022-11-22 08:14:05,309][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  90%|â–‰| 5022/5551 [26:58:05<2:49:37, 19.24s/it, loss=1.009, ppl=2.01, wps=26148.4, ups=0.05, wpb=523509, bsz=8779.2, num_updates=43440, lr=9.72477e-06, gnorm=0.082, clip=0, loss_scale=4, train_wall=77[2022-11-22 08:32:25,993][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
epoch 008:  93%|â–‰| 5147/5551 [27:38:17<2:10:25, 19.37s/it, loss=1.01, ppl=2.01, wps=27095, ups=0.05, wpb=522515, bsz=8856.4, num_updates=43560, lr=8.62385e-06, gnorm=0.086, clip=2.5, loss_scale=4, train_wall=756[2022-11-22 09:12:38,981][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 09:12:41,032][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.81 | ppl 3.51 | wps 166467 | wpb 10521.6 | bsz 178.1 | num_updates 43600 | best_loss 1.419                                    
[2022-11-22 09:12:41,033][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 43600 updates
[2022-11-22 09:12:41,033][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_43600.pt
[2022-11-22 09:12:45,497][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_43600.pt
[2022-11-22 09:12:48,218][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_43600.pt (epoch 8 @ 43600 updates, score 1.81) (writing took 7.185747059062123 seconds)
epoch 008:  95%|â–‰| 5279/5551 [28:20:51<1:27:14, 19.25s/it, loss=1.01, ppl=2.01, wps=27144.1, ups=0.05, wpb=522654, bsz=8570.8, num_updates=43720, lr=7.15596e-06, gnorm=0.08, clip=0, loss_scale=8, train_wall=754,[2022-11-22 09:55:11,746][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
epoch 008:  95%|â–‰| 5294/5551 [28:25:40<1:22:04, 19.16s/it, loss=1.01, ppl=2.01, wps=27144.1, ups=0.05, wpb=522654, bsz=8570.8, num_updates=43720, lr=7.15596e-06, gnorm=0.08, clip=0, loss_scale=8, train_wall=754,[2022-11-22 10:00:01,510][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008:  96%|â–‰| 5349/5551 [28:43:20<1:05:00, 19.31s/it, loss=1.009, ppl=2.01, wps=25814.3, ups=0.05, wpb=522134, bsz=8569.8, num_updates=43760, lr=6.78899e-06, gnorm=0.079, clip=0, loss_scale=4, train_wall=79[2022-11-22 10:17:41,593][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 10:17:43,626][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.824 | ppl 3.54 | wps 167842 | wpb 10521.6 | bsz 178.1 | num_updates 43800 | best_loss 1.419                                   
[2022-11-22 10:17:43,627][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 43800 updates
[2022-11-22 10:17:43,627][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_43800.pt
[2022-11-22 10:17:48,081][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_8_43800.pt
[2022-11-22 10:17:51,032][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_8_43800.pt (epoch 8 @ 43800 updates, score 1.824) (writing took 7.405508866533637 seconds)
epoch 008:  98%|â–‰| 5461/5551 [29:19:27<28:59, 19.33s/it, loss=1.011, ppl=2.02, wps=27095.2, ups=0.05, wpb=522217, bsz=8565.9, num_updates=43880, lr=5.68807e-06, gnorm=0.079, clip=0, loss_scale=8, train_wall=756,[2022-11-22 10:53:48,447][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 008: 100%|â–‰| 5550/5551 [29:48:02<00:19, 19.54s/it, loss=1.009, ppl=2.01, wps=27140.7, ups=0.05, wpb=522100, bsz=8414.1, num_updates=43960, lr=4.95413e-06, gnorm=0.079, clip=0, loss_scale=4, train_wall=755,[2022-11-22 11:22:21,045][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 11:22:23,092][valid][INFO] - epoch 008 | valid on 'valid' subset | loss 1.834 | ppl 3.57 | wps 167736 | wpb 10521.6 | bsz 178.1 | num_updates 44000 | best_loss 1.419                                   
[2022-11-22 11:22:23,093][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 44000 updates
[2022-11-22 11:22:23,093][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint8.pt
[2022-11-22 11:22:27,517][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint8.pt
[2022-11-22 11:22:30,574][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint8.pt (epoch 8 @ 44000 updates, score 1.834) (writing took 7.4815151412039995 seconds)
[2022-11-22 11:22:33,286][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)                                                                                                                    
[2022-11-22 11:22:33,766][train][INFO] - epoch 008 | loss 1.014 | ppl 2.02 | wps 26805 | ups 0.05 | wpb 522629 | bsz 8744 | num_updates 44000 | lr 4.58716e-06 | gnorm 0.086 | clip 6.3 | loss_scale 8 | train_wall 104947 | gb_free 7.6 | wall 860320
[2022-11-22 11:22:34,266][fairseq.data.iterators][INFO] - grouped total_num_itrs = 5551
epoch 009:   0%|                                                                                                                                                                          | 0/5551 [00:00<?, ?it/s][2022-11-22 11:22:34,301][fairseq.trainer][INFO] - begin training epoch 9
[2022-11-22 11:22:34,301][fairseq_cli.train][INFO] - Start iterating over samples
epoch 009:   0%|â–Œ                                                                                                                                                             | 18/5551 [05:46<29:33:14, 19.23s/it][2022-11-22 11:28:40,155][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 009:   2%| | 119/5551 [38:13<29:07:11, 19.30s/it, loss=1.01, ppl=2.01, wps=27187.1, ups=0.05, wpb=525363, bsz=8797.6, num_updates=44080, lr=3.85321e-06, gnorm=0.079, clip=0, loss_scale=4, train_wall=758, g[2022-11-22 12:01:07,418][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 009:   4%| | 201/5551 [1:04:38<28:38:55, 19.28s/it, loss=1.011, ppl=2.01, wps=27072, ups=0.05, wpb=523759, bsz=8887.1, num_updates=44160, lr=3.11927e-06, gnorm=0.078, clip=0, loss_scale=4, train_wall=759, [2022-11-22 12:27:31,585][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 12:27:33,632][valid][INFO] - epoch 009 | valid on 'valid' subset | loss 1.828 | ppl 3.55 | wps 167027 | wpb 10521.6 | bsz 178.1 | num_updates 44200 | best_loss 1.419                                   
[2022-11-22 12:27:33,633][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 9 @ 44200 updates
[2022-11-22 12:27:33,634][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_9_44200.pt
[2022-11-22 12:27:38,137][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_9_44200.pt
[2022-11-22 12:27:41,139][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_9_44200.pt (epoch 9 @ 44200 updates, score 1.828) (writing took 7.505283328704536 seconds)
epoch 009:   5%| | 280/5551 [1:30:07<28:09:40, 19.23s/it, loss=1.009, ppl=2.01, wps=26820.8, ups=0.05, wpb=522174, bsz=8621.1, num_updates=44240, lr=2.38532e-06, gnorm=0.077, clip=0, loss_scale=8, train_wall=754[2022-11-22 12:53:00,961][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 009:   7%| | 395/5551 [2:07:05<27:39:59, 19.32s/it, loss=1.009, ppl=2.01, wps=27147.5, ups=0.05, wpb=522766, bsz=8922.3, num_updates=44360, lr=1.2844e-06, gnorm=0.078, clip=0, loss_scale=4, train_wall=754,[2022-11-22 13:29:59,001][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
epoch 009:   7%| | 403/5551 [2:09:40<27:40:09, 19.35s/it, loss=1.009, ppl=2.01, wps=27147.5, ups=0.05, wpb=522766, bsz=8922.3, num_updates=44360, lr=1.2844e-06, gnorm=0.078, clip=0, loss_scale=4, train_wall=754,[2022-11-22 13:32:33,814][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 13:32:35,843][valid][INFO] - epoch 009 | valid on 'valid' subset | loss 1.816 | ppl 3.52 | wps 167558 | wpb 10521.6 | bsz 178.1 | num_updates 44400 | best_loss 1.419                                   
[2022-11-22 13:32:35,843][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 9 @ 44400 updates
[2022-11-22 13:32:35,844][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_9_44400.pt
[2022-11-22 13:32:40,308][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_9_44400.pt
[2022-11-22 13:32:43,205][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_9_44400.pt (epoch 9 @ 44400 updates, score 1.816) (writing took 7.361667711287737 seconds)
epoch 009:   9%| | 503/5551 [2:41:56<26:58:40, 19.24s/it, loss=1.01, ppl=2.01, wps=27122.3, ups=0.05, wpb=523557, bsz=9052.2, num_updates=44480, lr=1.83486e-07, gnorm=0.077, clip=0, loss_scale=8, train_wall=757,[2022-11-22 14:04:50,190][fairseq_cli.train][INFO] - Stopping training due to num_updates: 44500 >= max_update: 44500
[2022-11-22 14:04:50,191][fairseq_cli.train][INFO] - begin validation on "valid" subset
                                                                                                                                                                                                                  [2022-11-22 14:04:52,220][valid][INFO] - epoch 009 | valid on 'valid' subset | loss 1.807 | ppl 3.5 | wps 167524 | wpb 10521.6 | bsz 178.1 | num_updates 44500 | best_loss 1.419                                    
[2022-11-22 14:04:52,221][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 9 @ 44500 updates
[2022-11-22 14:04:52,222][fairseq.trainer][INFO] - Saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_last.pt
[2022-11-22 14:04:59,034][fairseq.trainer][INFO] - Finished saving checkpoint to /home/TCU/erichm/projetos/pretrain-bart-fairseq/bart/outputs/2022-11-12/12-23-46/checkpoints/checkpoint_last.pt
[2022-11-22 14:04:59,189][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_last.pt (epoch 9 @ 44500 updates, score 1.807) (writing took 6.967992781661451 seconds)
[2022-11-22 14:04:59,190][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)                                                                                                                    
[2022-11-22 14:04:59,192][train][INFO] - epoch 009 | loss 1.009 | ppl 2.01 | wps 26832.4 | ups 0.05 | wpb 522986 | bsz 8771.8 | num_updates 44500 | lr 0 | gnorm 0.078 | clip 0 | loss_scale 8 | train_wall 9528 | gb_free 6.6 | wall 870065
[2022-11-22 14:04:59,192][fairseq_cli.train][INFO] - done training in 869873.2 seconds
wandb: Waiting for W&B process to finish... (success).
wandb: | 0.421 MB of 0.421 MB uploaded (0.000 MB deduped)
wandb: Run history:
wandb:              train/bsz â–‚â–‚â–‚â–â–â–‚â–‚â–â–ˆ
wandb:             train/clip â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–ƒâ–â–
wandb:          train/gb_free â–‚â–â–‚â–‚â–â–ˆâ–‚â–†â–
wandb:            train/gnorm â–ˆâ–†â–‚â–‚â–‚â–â–â–â–
wandb:             train/loss â–ˆâ–„â–ƒâ–‚â–‚â–â–â–â–
wandb:       train/loss_scale â–â–ƒâ–„â–â–ƒâ–„â–ƒâ–ˆâ–ˆ
wandb:               train/lr â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–â–
wandb:              train/ppl â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–
wandb:       train/train_wall â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–
wandb:              train/ups â–â–â–â–â–â–â–â–â–
wandb:             train/wall â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆâ–ˆ
wandb:              train/wpb â–â–â–â–â–â–â–â–â–ˆ
wandb:              train/wps â–ˆâ–ˆâ–‡â–†â–â–‡â–‡â–‡â–ˆ
wandb:        train_inner/bsz â–†â–„â–…â–‡â–„â–…â–†â–ƒâ–†â–…â–…â–„â–ƒâ–„â–†â–†â–ˆâ–â–…â–†â–ˆâ–„â–…â–„â–†â–„â–†â–…â–„â–‚â–†â–„â–‚â–…â–…â–…â–†â–‚â–…â–†
wandb:       train_inner/clip â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–†â–†â–‡â–‡â–„â–…â–†â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–â–â–â–â–
wandb:    train_inner/gb_free â–â–ƒâ–â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–ƒâ–â–â–‡
wandb:      train_inner/gnorm â–ˆâ–‡â–ƒâ–„â–‚â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–„â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train_inner/loss â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: train_inner/loss_scale â–â–â–â–â–â–â–â–â–â–â–â–„â–„â–ƒâ–â–â–â–‚â–„â–â–„â–ƒâ–‚â–‚â–„â–â–‚â–ˆâ–ƒâ–„â–ˆâ–ƒâ–‚â–„â–ƒâ–„â–ˆâ–ˆâ–ˆâ–„
wandb:         train_inner/lr â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:        train_inner/ppl â–ˆâ–…â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: train_inner/train_wall â–â–â–‚â–â–â–„â–â–‚â–â–â–â–â–â–â–â–â–ƒâ–â–‚â–ˆâ–â–‚â–‚â–â–â–â–ƒâ–â–â–‚â–â–‚â–„â–â–â–â–â–â–â–
wandb:        train_inner/ups â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       train_inner/wall â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:        train_inner/wpb â–†â–„â–†â–ˆâ–…â–„â–‡â–„â–„â–ƒâ–ˆâ–‡â–…â–…â–‡â–ˆâ–…â–„â–ˆâ–â–…â–†â–ˆâ–ƒâ–ƒâ–†â–ˆâ–‚â–‡â–†â–†â–…â–‚â–‡â–ƒâ–‡â–…â–‚â–ƒâ–ˆ
wandb:        train_inner/wps â–‡â–ˆâ–‡â–‡â–ˆâ–…â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–…â–ˆâ–‡â–â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–…â–ˆâ–ˆâ–†â–ˆâ–‡â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:        valid/best_loss â–ˆâ–„â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              valid/bsz â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             valid/loss â–ˆâ–„â–‚â–ƒâ–ƒâ–â–â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒ
wandb:              valid/ppl â–ˆâ–„â–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒ
wandb:              valid/wpb â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              valid/wps â–‡â–…â–ˆâ–‡â–†â–…â–‡â–„â–…â–…â–â–â–„â–†â–ˆâ–†â–ƒâ–ƒâ–ƒâ–†â–‡â–ƒâ–‚â–â–‡â–„â–„â–‡â–…â–â–‚â–„â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–…
wandb: 
wandb: Run summary:
wandb:              train/bsz 8771.8
wandb:             train/clip 0.0
wandb:          train/gb_free 6.6
wandb:            train/gnorm 0.078
wandb:             train/loss 1.009
wandb:       train/loss_scale 8.0
wandb:               train/lr 0.0
wandb:              train/ppl 2.01
wandb:       train/train_wall 9528.0
wandb:              train/ups 0.05
wandb:             train/wall 870065.0
wandb:              train/wpb 522985.5
wandb:              train/wps 26832.4
wandb:        train_inner/bsz 9052.2
wandb:       train_inner/clip 0.0
wandb:    train_inner/gb_free 6.7
wandb:      train_inner/gnorm 0.077
wandb:       train_inner/loss 1.01
wandb: train_inner/loss_scale 8.0
wandb:         train_inner/lr 0.0
wandb:        train_inner/ppl 2.01
wandb: train_inner/train_wall 757.0
wandb:        train_inner/ups 0.05
wandb:       train_inner/wall 869671.0
wandb:        train_inner/wpb 523557.3
wandb:        train_inner/wps 27122.3
wandb:        valid/best_loss 1.419
wandb:              valid/bsz 178.1
wandb:             valid/loss 1.807
wandb:              valid/ppl 3.5
wandb:              valid/wpb 10521.6
wandb:              valid/wps 167524.4
wandb: 
wandb: Synced checkpoints: https://wandb.ai/sesin/bart_large_pt/runs/rgpbx2sz
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20221112_122707-rgpbx2sz/logs
